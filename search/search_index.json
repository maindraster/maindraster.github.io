{"config":{"lang":["en"],"separator":"[\\s\\u200b\\u3000\\-\u3001\u3002\uff0c\uff0e\uff1f\uff01\uff1b]+","pipeline":["stemmer"]},"docs":[{"location":"","title":"\u9996\u9875","text":"<p>Tarxiv\u65e8\u5728\u63d0\u4f9b\u5b8c\u5168\u514d\u8d39\u3001\u5f00\u6e90\u7684\u786c\u4ef6\u548c\u673a\u5668\u4eba\u5b66\u4e60\u548c\u5b9e\u64cd\u6587\u6863\u3002\u76ee\u524d\u4ecd\u5728\u5efa\u8bbe\u4e2d\uff0c\u5c06\u4e3b\u8981\u5305\u542b\u4ee5\u4e0b\u5185\u5bb9\uff1a\u786c\u4ef6\u8bbe\u8ba1\uff08\u673a\u68b0\u7ed3\u6784\u8bbe\u8ba1\u3001\u5efa\u6a21\u8f6f\u4ef6\u4f7f\u7528\uff09\u3001\u5d4c\u5165\u5f0f\u5f00\u53d1\uff08\u5355\u7247\u673a\u5b66\u4e60\u548c\u4f7f\u7528\u3001\u5916\u56f4\u7535\u8def\u5f00\u53d1\uff09\u3001\u673a\u5668\u4eba\u7406\u8bba\uff08\u673a\u5668\u4eba\u5b66\u57fa\u7840\u3001\u63a7\u5236\u7406\u8bba\u3001\u89c4\u5212\u7b97\u6cd5\uff09\u3001\u673a\u5668\u4eba\u5f00\u53d1\uff08\u73af\u5883\u642d\u5efa\u3001\u4eff\u771f\uff09\u3001\u5f3a\u5316\u5b66\u4e60\uff08\u57fa\u672c\u7406\u8bba\u3001\u4ee3\u7801\u590d\u73b0\uff09\u7b49\u3002</p>"},{"location":"SUMMARY/","title":"SUMMARY","text":"<ul> <li>\u9996\u9875</li> <li>\u7406\u8bba\u4e0d\u6c42\u4eba</li> <li>\u5b66\u4e60\u4e0d\u6c42\u4eba</li> <li>\u5165\u95e8\u4e0d\u6c42\u4eba</li> <li>\u8bbe\u7f6e</li> </ul>"},{"location":"lm/SUMMARY/","title":"SUMMARY","text":"<ul> <li>\u524d\u8a00</li> <li>\u5f3a\u5316\u5b66\u4e60</li> </ul>"},{"location":"lm/shouye/","title":"\u5b66\u4e60\u5f3a\u5316\u5b66\u4e60","text":""},{"location":"lm/shouye/#\u603b\u7684\u6765\u8bf4","title":"\u603b\u7684\u6765\u8bf4","text":"<p>AI \u65f6\u4ee3\u8ba9\u6211\u4eec\u4e0d\u613f\u610f\u81ea\u5df1\u52a8\u624b\u5199\u4ee3\u7801\u4e86\uff0c\u8fd9\u5bf9\u4e8e\u6211\u4eec\u662f\u6781\u5176\u4e0d\u597d\u7684\u3002</p> <ul> <li>\u5982\u679c\u81ea\u5df1\u60f3\u6df1\u5165\u521b\u5efa\u4e0d\u4e00\u6837\u7684\u6846\u67b6\uff0c\u4e0d\u61c2\u4ee3\u7801\uff0c\u5c06\u975e\u5e38\u96be\u53d7</li> <li>\u5982\u679c\u81ea\u5df1\u60f3\u6784\u5efa\u4e00\u4e2a\u5927\u578b\u9879\u76ee\uff0c\u53ea\u9760AI\uff0c\u5c06\u4e3e\u6b65\u7ef4\u8270</li> </ul> <p>\u56e0\u6b64\u672c\u5f3a\u5316\u5b66\u4e60\u7bc7\u7ae0\uff0c\u5728\u52a8\u624b\u5b66\u4e60\u5f3a\u5316\u5b66\u4e60\u57fa\u7840\u4e0a\uff0c\u8fdb\u884c\u7b80\u8981\u548c\u5173\u952e\u6027\u8bc4\u6ce8\uff08\u4e3b\u8981\u5185\u5bb9\u5b66\u4e60\u8bf7\u53c2\u8003\u5b98\u7f51\uff09\uff0c\u968f\u4ee3\u7801\u63d0\u4f9b\u6700\u5c0f\u767d\u5f0f\u7684Python\u5165\u95e8\u5b66\u4e60\uff08\u672a\u6765\u53ef\u80fd\u4f1a\u7528C++\u518d\u5199\u4e00\u904d\uff09\uff0c\u53c2\u8003\u8d44\u6599\uff1a\u300aPython\u7f16\u7a0b\uff1a\u4ece\u5165\u95e8\u5230\u5b9e\u8df5\u300b\u3002</p> <p>\u7531\u4e8e\u672c\u6559\u7a0b\u6709\u91c7\u7528jupyter\u7f16\u5199\uff0c\u53ef\u4ee5\u67e5\u770bVSCode+jupyter+Conda\u73af\u5883\u8fdb\u884c\u76f8\u5173\u914d\u7f6e\u3002</p>"},{"location":"lm/rl/SUMMARY/","title":"SUMMARY","text":"<ul> <li>\u57fa\u7840\u7bc7</li> </ul>"},{"location":"lm/rl/basic/SUMMARY/","title":"SUMMARY","text":"<ul> <li>\u591a\u81c2\u8001\u864e\u673a</li> </ul>"},{"location":"lm/rl/basic/mab-code/","title":"\u591a\u81c2\u8001\u864e\u673a-Code","text":"In\u00a0[2]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n</pre> import numpy as np import matplotlib.pyplot as plt In\u00a0[3]: Copied! <pre>class BernoulliBandit:\n    \"\"\" \u4f2f\u52aa\u5229\u591a\u81c2\u8001\u864e\u673a,\u8f93\u5165K\u8868\u793a\u62c9\u6746\u4e2a\u6570 \"\"\"\n    def __init__(self, K):\n        self.probs = np.random.uniform(size=K)  # \u968f\u673a\u751f\u6210K\u4e2a0\uff5e1\u7684\u6570,\u4f5c\u4e3a\u62c9\u52a8\u6bcf\u6839\u62c9\u6746\u7684\u83b7\u5956\n        # \u6982\u7387\n        self.best_idx = np.argmax(self.probs)  # \u83b7\u5956\u6982\u7387\u6700\u5927\u7684\u62c9\u6746\n        self.best_prob = self.probs[self.best_idx]  # \u6700\u5927\u7684\u83b7\u5956\u6982\u7387\n        self.K = K\n\n    def step(self, k):\n        # \u5f53\u73a9\u5bb6\u9009\u62e9\u4e86k\u53f7\u62c9\u6746\u540e,\u6839\u636e\u62c9\u52a8\u8be5\u8001\u864e\u673a\u7684k\u53f7\u62c9\u6746\u83b7\u5f97\u5956\u52b1\u7684\u6982\u7387\u8fd4\u56de1\uff08\u83b7\u5956\uff09\u62160\uff08\u672a\n        # \u83b7\u5956\uff09\n        if np.random.rand() &lt; self.probs[k]:\n            return 1\n        else:\n            return 0\n\nnp.random.seed(1)  # \u8bbe\u5b9a\u968f\u673a\u79cd\u5b50,\u4f7f\u5b9e\u9a8c\u5177\u6709\u53ef\u91cd\u590d\u6027\nK = 10\nbandit_10_arm = BernoulliBandit(K)\nprint(\"\u968f\u673a\u751f\u6210\u4e86\u4e00\u4e2a%d\u81c2\u4f2f\u52aa\u5229\u8001\u864e\u673a\" % K)\nprint(\"\u83b7\u5956\u6982\u7387\u6700\u5927\u7684\u62c9\u6746\u4e3a%d\u53f7,\u5176\u83b7\u5956\u6982\u7387\u4e3a%.4f\" %\n      (bandit_10_arm.best_idx, bandit_10_arm.best_prob))\n</pre> class BernoulliBandit:     \"\"\" \u4f2f\u52aa\u5229\u591a\u81c2\u8001\u864e\u673a,\u8f93\u5165K\u8868\u793a\u62c9\u6746\u4e2a\u6570 \"\"\"     def __init__(self, K):         self.probs = np.random.uniform(size=K)  # \u968f\u673a\u751f\u6210K\u4e2a0\uff5e1\u7684\u6570,\u4f5c\u4e3a\u62c9\u52a8\u6bcf\u6839\u62c9\u6746\u7684\u83b7\u5956         # \u6982\u7387         self.best_idx = np.argmax(self.probs)  # \u83b7\u5956\u6982\u7387\u6700\u5927\u7684\u62c9\u6746         self.best_prob = self.probs[self.best_idx]  # \u6700\u5927\u7684\u83b7\u5956\u6982\u7387         self.K = K      def step(self, k):         # \u5f53\u73a9\u5bb6\u9009\u62e9\u4e86k\u53f7\u62c9\u6746\u540e,\u6839\u636e\u62c9\u52a8\u8be5\u8001\u864e\u673a\u7684k\u53f7\u62c9\u6746\u83b7\u5f97\u5956\u52b1\u7684\u6982\u7387\u8fd4\u56de1\uff08\u83b7\u5956\uff09\u62160\uff08\u672a         # \u83b7\u5956\uff09         if np.random.rand() &lt; self.probs[k]:             return 1         else:             return 0  np.random.seed(1)  # \u8bbe\u5b9a\u968f\u673a\u79cd\u5b50,\u4f7f\u5b9e\u9a8c\u5177\u6709\u53ef\u91cd\u590d\u6027 K = 10 bandit_10_arm = BernoulliBandit(K) print(\"\u968f\u673a\u751f\u6210\u4e86\u4e00\u4e2a%d\u81c2\u4f2f\u52aa\u5229\u8001\u864e\u673a\" % K) print(\"\u83b7\u5956\u6982\u7387\u6700\u5927\u7684\u62c9\u6746\u4e3a%d\u53f7,\u5176\u83b7\u5956\u6982\u7387\u4e3a%.4f\" %       (bandit_10_arm.best_idx, bandit_10_arm.best_prob)) <pre>\u968f\u673a\u751f\u6210\u4e86\u4e00\u4e2a10\u81c2\u4f2f\u52aa\u5229\u8001\u864e\u673a\n\u83b7\u5956\u6982\u7387\u6700\u5927\u7684\u62c9\u6746\u4e3a1\u53f7,\u5176\u83b7\u5956\u6982\u7387\u4e3a0.7203\n</pre> In\u00a0[4]: Copied! <pre>class Solver:\n    \"\"\" \u591a\u81c2\u8001\u864e\u673a\u7b97\u6cd5\u57fa\u672c\u6846\u67b6 \"\"\"\n    def __init__(self, bandit):\n        self.bandit = bandit\n        self.counts = np.zeros(self.bandit.K)  # \u6bcf\u6839\u62c9\u6746\u7684\u5c1d\u8bd5\u6b21\u6570\n        self.regret = 0.  # \u5f53\u524d\u6b65\u7684\u7d2f\u79ef\u61ca\u6094\n        self.actions = []  # \u7ef4\u62a4\u4e00\u4e2a\u5217\u8868,\u8bb0\u5f55\u6bcf\u4e00\u6b65\u7684\u52a8\u4f5c\n        self.regrets = []  # \u7ef4\u62a4\u4e00\u4e2a\u5217\u8868,\u8bb0\u5f55\u6bcf\u4e00\u6b65\u7684\u7d2f\u79ef\u61ca\u6094\n\n    def update_regret(self, k):\n        # \u8ba1\u7b97\u7d2f\u79ef\u61ca\u6094\u5e76\u4fdd\u5b58,k\u4e3a\u672c\u6b21\u52a8\u4f5c\u9009\u62e9\u7684\u62c9\u6746\u7684\u7f16\u53f7\n        self.regret += self.bandit.best_prob - self.bandit.probs[k]\n        self.regrets.append(self.regret)\n\n    def run_one_step(self):\n        # \u8fd4\u56de\u5f53\u524d\u52a8\u4f5c\u9009\u62e9\u54ea\u4e00\u6839\u62c9\u6746,\u7531\u6bcf\u4e2a\u5177\u4f53\u7684\u7b56\u7565\u5b9e\u73b0\n        raise NotImplementedError\n\n    def run(self, num_steps):\n        # \u8fd0\u884c\u4e00\u5b9a\u6b21\u6570,num_steps\u4e3a\u603b\u8fd0\u884c\u6b21\u6570\n        for _ in range(num_steps):\n            k = self.run_one_step()\n            self.counts[k] += 1\n            self.actions.append(k)\n            self.update_regret(k)\n</pre> class Solver:     \"\"\" \u591a\u81c2\u8001\u864e\u673a\u7b97\u6cd5\u57fa\u672c\u6846\u67b6 \"\"\"     def __init__(self, bandit):         self.bandit = bandit         self.counts = np.zeros(self.bandit.K)  # \u6bcf\u6839\u62c9\u6746\u7684\u5c1d\u8bd5\u6b21\u6570         self.regret = 0.  # \u5f53\u524d\u6b65\u7684\u7d2f\u79ef\u61ca\u6094         self.actions = []  # \u7ef4\u62a4\u4e00\u4e2a\u5217\u8868,\u8bb0\u5f55\u6bcf\u4e00\u6b65\u7684\u52a8\u4f5c         self.regrets = []  # \u7ef4\u62a4\u4e00\u4e2a\u5217\u8868,\u8bb0\u5f55\u6bcf\u4e00\u6b65\u7684\u7d2f\u79ef\u61ca\u6094      def update_regret(self, k):         # \u8ba1\u7b97\u7d2f\u79ef\u61ca\u6094\u5e76\u4fdd\u5b58,k\u4e3a\u672c\u6b21\u52a8\u4f5c\u9009\u62e9\u7684\u62c9\u6746\u7684\u7f16\u53f7         self.regret += self.bandit.best_prob - self.bandit.probs[k]         self.regrets.append(self.regret)      def run_one_step(self):         # \u8fd4\u56de\u5f53\u524d\u52a8\u4f5c\u9009\u62e9\u54ea\u4e00\u6839\u62c9\u6746,\u7531\u6bcf\u4e2a\u5177\u4f53\u7684\u7b56\u7565\u5b9e\u73b0         raise NotImplementedError      def run(self, num_steps):         # \u8fd0\u884c\u4e00\u5b9a\u6b21\u6570,num_steps\u4e3a\u603b\u8fd0\u884c\u6b21\u6570         for _ in range(num_steps):             k = self.run_one_step()             self.counts[k] += 1             self.actions.append(k)             self.update_regret(k) In\u00a0[5]: Copied! <pre>class EpsilonGreedy(Solver):\n    \"\"\" epsilon\u8d2a\u5a6a\u7b97\u6cd5,\u7ee7\u627fSolver\u7c7b \"\"\"\n    def __init__(self, bandit, epsilon=0.01, init_prob=1.0):\n        super().__init__(bandit)\n        self.epsilon = epsilon\n        #\u521d\u59cb\u5316\u62c9\u52a8\u6240\u6709\u62c9\u6746\u7684\u671f\u671b\u5956\u52b1\u4f30\u503c\n        self.estimates = np.array([init_prob] * self.bandit.K)\n\n    def run_one_step(self):\n        if np.random.random() &lt; self.epsilon:\n            k = np.random.randint(0, self.bandit.K)  # \u03b5\u7684\u6982\u7387\uff1a\u968f\u673a\u9009\u62e9\u4e00\u6839\u62c9\u6746\n        else:\n            k = np.argmax(self.estimates)  # \u9009\u62e9\u671f\u671b\u5956\u52b1\u4f30\u503c\u6700\u5927\u7684\u62c9\u6746\n        r = self.bandit.step(k)  # \u5f97\u5230\u672c\u6b21\u52a8\u4f5c\u7684\u5956\u52b1\n        self.estimates[k] += 1. / (self.counts[k] + 1) * (r - self.estimates[k]) \n        return k\n</pre> class EpsilonGreedy(Solver):     \"\"\" epsilon\u8d2a\u5a6a\u7b97\u6cd5,\u7ee7\u627fSolver\u7c7b \"\"\"     def __init__(self, bandit, epsilon=0.01, init_prob=1.0):         super().__init__(bandit)         self.epsilon = epsilon         #\u521d\u59cb\u5316\u62c9\u52a8\u6240\u6709\u62c9\u6746\u7684\u671f\u671b\u5956\u52b1\u4f30\u503c         self.estimates = np.array([init_prob] * self.bandit.K)      def run_one_step(self):         if np.random.random() &lt; self.epsilon:             k = np.random.randint(0, self.bandit.K)  # \u03b5\u7684\u6982\u7387\uff1a\u968f\u673a\u9009\u62e9\u4e00\u6839\u62c9\u6746         else:             k = np.argmax(self.estimates)  # \u9009\u62e9\u671f\u671b\u5956\u52b1\u4f30\u503c\u6700\u5927\u7684\u62c9\u6746         r = self.bandit.step(k)  # \u5f97\u5230\u672c\u6b21\u52a8\u4f5c\u7684\u5956\u52b1         self.estimates[k] += 1. / (self.counts[k] + 1) * (r - self.estimates[k])          return k In\u00a0[6]: Copied! <pre>def plot_results(solvers, solver_names):\n    \"\"\"\u751f\u6210\u7d2f\u79ef\u61ca\u6094\u968f\u65f6\u95f4\u53d8\u5316\u7684\u56fe\u50cf\u3002\u8f93\u5165solvers\u662f\u4e00\u4e2a\u5217\u8868,\u5217\u8868\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u662f\u4e00\u79cd\u7279\u5b9a\u7684\u7b56\u7565\u3002\n    \u800csolver_names\u4e5f\u662f\u4e00\u4e2a\u5217\u8868,\u5b58\u50a8\u6bcf\u4e2a\u7b56\u7565\u7684\u540d\u79f0\"\"\"\n    for idx, solver in enumerate(solvers):\n        time_list = range(len(solver.regrets))\n        plt.plot(time_list, solver.regrets, label=solver_names[idx])\n    plt.xlabel('Time steps')\n    plt.ylabel('Cumulative regrets')\n    plt.title('%d-armed bandit' % solvers[0].bandit.K)\n    plt.legend()\n    plt.show()\n</pre> def plot_results(solvers, solver_names):     \"\"\"\u751f\u6210\u7d2f\u79ef\u61ca\u6094\u968f\u65f6\u95f4\u53d8\u5316\u7684\u56fe\u50cf\u3002\u8f93\u5165solvers\u662f\u4e00\u4e2a\u5217\u8868,\u5217\u8868\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u662f\u4e00\u79cd\u7279\u5b9a\u7684\u7b56\u7565\u3002     \u800csolver_names\u4e5f\u662f\u4e00\u4e2a\u5217\u8868,\u5b58\u50a8\u6bcf\u4e2a\u7b56\u7565\u7684\u540d\u79f0\"\"\"     for idx, solver in enumerate(solvers):         time_list = range(len(solver.regrets))         plt.plot(time_list, solver.regrets, label=solver_names[idx])     plt.xlabel('Time steps')     plt.ylabel('Cumulative regrets')     plt.title('%d-armed bandit' % solvers[0].bandit.K)     plt.legend()     plt.show() In\u00a0[7]: Copied! <pre>np.random.seed(1)\nepsilon_greedy_solver = EpsilonGreedy(bandit_10_arm, epsilon=0.01)\nepsilon_greedy_solver.run(5000)\nprint('epsilon-\u8d2a\u5a6a\u7b97\u6cd5\u7684\u7d2f\u79ef\u61ca\u6094\u4e3a\uff1a', epsilon_greedy_solver.regret)\nplot_results([epsilon_greedy_solver], [\"EpsilonGreedy\"])\n</pre> np.random.seed(1) epsilon_greedy_solver = EpsilonGreedy(bandit_10_arm, epsilon=0.01) epsilon_greedy_solver.run(5000) print('epsilon-\u8d2a\u5a6a\u7b97\u6cd5\u7684\u7d2f\u79ef\u61ca\u6094\u4e3a\uff1a', epsilon_greedy_solver.regret) plot_results([epsilon_greedy_solver], [\"EpsilonGreedy\"]) <pre>epsilon-\u8d2a\u5a6a\u7b97\u6cd5\u7684\u7d2f\u79ef\u61ca\u6094\u4e3a\uff1a 25.526630933945313\n</pre> In\u00a0[8]: Copied! <pre>np.random.seed(0)\nepsilons = [1e-4, 0.01, 0.1, 0.25, 0.5]\nepsilon_greedy_solver_list = [\n    EpsilonGreedy(bandit_10_arm, epsilon=e) for e in epsilons\n]\nepsilon_greedy_solver_names = [\"epsilon={}\".format(e) for e in epsilons]\nfor solver in epsilon_greedy_solver_list:\n    solver.run(5000)\n\nplot_results(epsilon_greedy_solver_list, epsilon_greedy_solver_names)\n</pre> np.random.seed(0) epsilons = [1e-4, 0.01, 0.1, 0.25, 0.5] epsilon_greedy_solver_list = [     EpsilonGreedy(bandit_10_arm, epsilon=e) for e in epsilons ] epsilon_greedy_solver_names = [\"epsilon={}\".format(e) for e in epsilons] for solver in epsilon_greedy_solver_list:     solver.run(5000)  plot_results(epsilon_greedy_solver_list, epsilon_greedy_solver_names) <p>\u03b5\u56fa\u5b9a\u503c\u4e0d\u884c\u7684\u539f\u56e0\u5728\u4e8e\uff0c\u4e00\u5b9a\u4f1a\u968f\u673a\u9009\uff0c\u53ea\u8981\u968f\u673a\u9009\u5c31\u4f1a\u548c\u6700\u6709\u4e4b\u95f4\u6709\u5dee\u8ddd\uff08\u5e73\u5747\u800c\u8a00\uff09\uff0c\u90a3\u5c31\u6ce8\u5b9a\u4f1a\u4e00\u76f4\u589e\uff0c\u53ea\u662f\u5feb\u548c\u6162\u7684\u5173\u7cfb\u3002\u03b5\u7279\u522b\u5c0f\u5c31\u610f\u5473\u7740\u57fa\u672c\u4e0d\u968f\u673a\uff0c\u8bf4\u767d\u4e86\u5c31\u662f\u61d2\u5f97\u52a8\uff0c\u5c31\u57fa\u672c\u4e00\u76f4\u62c9\u4e00\u6839\uff0c\u6240\u4ee5\u589e\u957f\u81ea\u7136\u5c31\u5c0f\uff0c\u53ea\u6709\u968f\u673a\u9009\u624d\u4f1a\u589e\u957f\u61ca\u6094\u503c\u3002</p> <p></p> In\u00a0[9]: Copied! <pre>class DecayingEpsilonGreedy(Solver):\n    \"\"\" epsilon\u503c\u968f\u65f6\u95f4\u8870\u51cf\u7684epsilon-\u8d2a\u5a6a\u7b97\u6cd5,\u7ee7\u627fSolver\u7c7b \"\"\"\n    def __init__(self, bandit, init_prob=1.0):\n        super().__init__(bandit)\n        self.estimates = np.array([init_prob] * self.bandit.K)\n        self.total_count = 0\n\n    def run_one_step(self):\n        self.total_count += 1\n        if np.random.random() &lt; 1 / self.total_count:  # epsilon\u503c\u968f\u65f6\u95f4\u8870\u51cf\n            k = np.random.randint(0, self.bandit.K)\n        else:\n            k = np.argmax(self.estimates)\n\n        r = self.bandit.step(k)\n        self.estimates[k] += 1. / (self.counts[k] + 1) * (r - self.estimates[k])\n\n        return k\n\n\nnp.random.seed(1)\ndecaying_epsilon_greedy_solver = DecayingEpsilonGreedy(bandit_10_arm)\ndecaying_epsilon_greedy_solver.run(5000)\nprint('epsilon\u503c\u8870\u51cf\u7684\u8d2a\u5a6a\u7b97\u6cd5\u7684\u7d2f\u79ef\u61ca\u6094\u4e3a\uff1a', decaying_epsilon_greedy_solver.regret)\nplot_results([decaying_epsilon_greedy_solver], [\"DecayingEpsilonGreedy\"])\n</pre> class DecayingEpsilonGreedy(Solver):     \"\"\" epsilon\u503c\u968f\u65f6\u95f4\u8870\u51cf\u7684epsilon-\u8d2a\u5a6a\u7b97\u6cd5,\u7ee7\u627fSolver\u7c7b \"\"\"     def __init__(self, bandit, init_prob=1.0):         super().__init__(bandit)         self.estimates = np.array([init_prob] * self.bandit.K)         self.total_count = 0      def run_one_step(self):         self.total_count += 1         if np.random.random() &lt; 1 / self.total_count:  # epsilon\u503c\u968f\u65f6\u95f4\u8870\u51cf             k = np.random.randint(0, self.bandit.K)         else:             k = np.argmax(self.estimates)          r = self.bandit.step(k)         self.estimates[k] += 1. / (self.counts[k] + 1) * (r - self.estimates[k])          return k   np.random.seed(1) decaying_epsilon_greedy_solver = DecayingEpsilonGreedy(bandit_10_arm) decaying_epsilon_greedy_solver.run(5000) print('epsilon\u503c\u8870\u51cf\u7684\u8d2a\u5a6a\u7b97\u6cd5\u7684\u7d2f\u79ef\u61ca\u6094\u4e3a\uff1a', decaying_epsilon_greedy_solver.regret) plot_results([decaying_epsilon_greedy_solver], [\"DecayingEpsilonGreedy\"]) <pre>epsilon\u503c\u8870\u51cf\u7684\u8d2a\u5a6a\u7b97\u6cd5\u7684\u7d2f\u79ef\u61ca\u6094\u4e3a\uff1a 10.114334931260183\n</pre> <p></p> In\u00a0[10]: Copied! <pre>class DecayingEpsilonGreedy(Solver):\n    \"\"\" epsilon\u503c\u968f\u65f6\u95f4\u8870\u51cf\u7684epsilon-\u8d2a\u5a6a\u7b97\u6cd5,\u7ee7\u627fSolver\u7c7b \"\"\"\n    def __init__(self, bandit, init_prob=1.0):\n        super().__init__(bandit)\n        self.estimates = np.array([init_prob] * self.bandit.K)\n        self.total_count = 0\n\n    def run_one_step(self):\n        self.total_count += 1\n        if np.random.random() &lt; 1 / np.log(self.total_count+1):  # epsilon\u503c\u968f\u65f6\u95f4\u8870\u51cf\n            k = np.random.randint(0, self.bandit.K)\n        else:\n            k = np.argmax(self.estimates)\n\n        r = self.bandit.step(k)\n        self.estimates[k] += 1. / (self.counts[k] + 1) * (r - self.estimates[k])\n\n        return k\n\nnp.random.seed(1)\ndecaying_epsilon_greedy_solver = DecayingEpsilonGreedy(bandit_10_arm)\ndecaying_epsilon_greedy_solver.run(5000)\nprint('epsilon\u503c\u8870\u51cf\u7684\u8d2a\u5a6a\u7b97\u6cd5\u7684\u7d2f\u79ef\u61ca\u6094\u4e3a\uff1a', decaying_epsilon_greedy_solver.regret)\nplot_results([decaying_epsilon_greedy_solver], [\"DecayingEpsilonGreedy\"])\n</pre> class DecayingEpsilonGreedy(Solver):     \"\"\" epsilon\u503c\u968f\u65f6\u95f4\u8870\u51cf\u7684epsilon-\u8d2a\u5a6a\u7b97\u6cd5,\u7ee7\u627fSolver\u7c7b \"\"\"     def __init__(self, bandit, init_prob=1.0):         super().__init__(bandit)         self.estimates = np.array([init_prob] * self.bandit.K)         self.total_count = 0      def run_one_step(self):         self.total_count += 1         if np.random.random() &lt; 1 / np.log(self.total_count+1):  # epsilon\u503c\u968f\u65f6\u95f4\u8870\u51cf             k = np.random.randint(0, self.bandit.K)         else:             k = np.argmax(self.estimates)          r = self.bandit.step(k)         self.estimates[k] += 1. / (self.counts[k] + 1) * (r - self.estimates[k])          return k  np.random.seed(1) decaying_epsilon_greedy_solver = DecayingEpsilonGreedy(bandit_10_arm) decaying_epsilon_greedy_solver.run(5000) print('epsilon\u503c\u8870\u51cf\u7684\u8d2a\u5a6a\u7b97\u6cd5\u7684\u7d2f\u79ef\u61ca\u6094\u4e3a\uff1a', decaying_epsilon_greedy_solver.regret) plot_results([decaying_epsilon_greedy_solver], [\"DecayingEpsilonGreedy\"]) <pre>epsilon\u503c\u8870\u51cf\u7684\u8d2a\u5a6a\u7b97\u6cd5\u7684\u7d2f\u79ef\u61ca\u6094\u4e3a\uff1a 266.2033962764968\n</pre> In\u00a0[11]: Copied! <pre>class DecayingEpsilonGreedy(Solver):\n    \"\"\" epsilon\u503c\u968f\u65f6\u95f4\u8870\u51cf\u7684epsilon-\u8d2a\u5a6a\u7b97\u6cd5,\u7ee7\u627fSolver\u7c7b \"\"\"\n    def __init__(self, bandit, init_prob=1.0):\n        super().__init__(bandit)\n        self.estimates = np.array([init_prob] * self.bandit.K)\n        self.total_count = 0\n\n    def run_one_step(self):\n        self.total_count += 1\n        if np.random.random() &lt; np.e ** (-self.total_count/10):  # epsilon\u503c\u968f\u65f6\u95f4\u8870\u51cf\n            k = np.random.randint(0, self.bandit.K)\n        else:\n            k = np.argmax(self.estimates)\n\n        r = self.bandit.step(k)\n        self.estimates[k] += 1. / (self.counts[k] + 1) * (r - self.estimates[k])\n\n        return k\n\n\nnp.random.seed(1)\ndecaying_epsilon_greedy_solver = DecayingEpsilonGreedy(bandit_10_arm)\ndecaying_epsilon_greedy_solver.run(500)\nprint('epsilon\u503c\u8870\u51cf\u7684\u8d2a\u5a6a\u7b97\u6cd5\u7684\u7d2f\u79ef\u61ca\u6094\u4e3a\uff1a', decaying_epsilon_greedy_solver.regret)\nplot_results([decaying_epsilon_greedy_solver], [\"DecayingEpsilonGreedy\"])\n</pre> class DecayingEpsilonGreedy(Solver):     \"\"\" epsilon\u503c\u968f\u65f6\u95f4\u8870\u51cf\u7684epsilon-\u8d2a\u5a6a\u7b97\u6cd5,\u7ee7\u627fSolver\u7c7b \"\"\"     def __init__(self, bandit, init_prob=1.0):         super().__init__(bandit)         self.estimates = np.array([init_prob] * self.bandit.K)         self.total_count = 0      def run_one_step(self):         self.total_count += 1         if np.random.random() &lt; np.e ** (-self.total_count/10):  # epsilon\u503c\u968f\u65f6\u95f4\u8870\u51cf             k = np.random.randint(0, self.bandit.K)         else:             k = np.argmax(self.estimates)          r = self.bandit.step(k)         self.estimates[k] += 1. / (self.counts[k] + 1) * (r - self.estimates[k])          return k   np.random.seed(1) decaying_epsilon_greedy_solver = DecayingEpsilonGreedy(bandit_10_arm) decaying_epsilon_greedy_solver.run(500) print('epsilon\u503c\u8870\u51cf\u7684\u8d2a\u5a6a\u7b97\u6cd5\u7684\u7d2f\u79ef\u61ca\u6094\u4e3a\uff1a', decaying_epsilon_greedy_solver.regret) plot_results([decaying_epsilon_greedy_solver], [\"DecayingEpsilonGreedy\"]) <pre>epsilon\u503c\u8870\u51cf\u7684\u8d2a\u5a6a\u7b97\u6cd5\u7684\u7d2f\u79ef\u61ca\u6094\u4e3a\uff1a 10.974707633756497\n</pre> <p></p> In\u00a0[12]: Copied! <pre>class UCB(Solver):\n    \"\"\" UCB\u7b97\u6cd5,\u7ee7\u627fSolver\u7c7b \"\"\"\n    def __init__(self, bandit, coef, init_prob=1.0):\n        super().__init__(bandit)\n        self.total_count = 0\n        self.estimates = np.array([init_prob] * self.bandit.K)\n        self.coef = coef\n\n    def run_one_step(self):\n        self.total_count += 1\n        ucb = self.estimates + self.coef * np.sqrt(\n            np.log(self.total_count) / (2 * (self.counts + 1)))  # \u8ba1\u7b97\u4e0a\u7f6e\u4fe1\u754c\n        k = np.argmax(ucb)  # \u9009\u51fa\u4e0a\u7f6e\u4fe1\u754c\u6700\u5927\u7684\u62c9\u6746\n        r = self.bandit.step(k)\n        self.estimates[k] += 1. / (self.counts[k] + 1) * (r - self.estimates[k])\n        return k\n\nnp.random.seed(1)\ncoef = 1  # \u63a7\u5236\u4e0d\u786e\u5b9a\u6027\u6bd4\u91cd\u7684\u7cfb\u6570\nUCB_solver = UCB(bandit_10_arm, coef)\nUCB_solver.run(5000)\nprint('\u4e0a\u7f6e\u4fe1\u754c\u7b97\u6cd5\u7684\u7d2f\u79ef\u61ca\u6094\u4e3a\uff1a', UCB_solver.regret)\nplot_results([UCB_solver], [\"UCB\"])\n</pre> class UCB(Solver):     \"\"\" UCB\u7b97\u6cd5,\u7ee7\u627fSolver\u7c7b \"\"\"     def __init__(self, bandit, coef, init_prob=1.0):         super().__init__(bandit)         self.total_count = 0         self.estimates = np.array([init_prob] * self.bandit.K)         self.coef = coef      def run_one_step(self):         self.total_count += 1         ucb = self.estimates + self.coef * np.sqrt(             np.log(self.total_count) / (2 * (self.counts + 1)))  # \u8ba1\u7b97\u4e0a\u7f6e\u4fe1\u754c         k = np.argmax(ucb)  # \u9009\u51fa\u4e0a\u7f6e\u4fe1\u754c\u6700\u5927\u7684\u62c9\u6746         r = self.bandit.step(k)         self.estimates[k] += 1. / (self.counts[k] + 1) * (r - self.estimates[k])         return k  np.random.seed(1) coef = 1  # \u63a7\u5236\u4e0d\u786e\u5b9a\u6027\u6bd4\u91cd\u7684\u7cfb\u6570 UCB_solver = UCB(bandit_10_arm, coef) UCB_solver.run(5000) print('\u4e0a\u7f6e\u4fe1\u754c\u7b97\u6cd5\u7684\u7d2f\u79ef\u61ca\u6094\u4e3a\uff1a', UCB_solver.regret) plot_results([UCB_solver], [\"UCB\"]) <pre>\u4e0a\u7f6e\u4fe1\u754c\u7b97\u6cd5\u7684\u7d2f\u79ef\u61ca\u6094\u4e3a\uff1a 70.45281214197854\n</pre> <p></p> In\u00a0[13]: Copied! <pre>class ThompsonSampling(Solver):\n    \"\"\" \u6c64\u666e\u68ee\u91c7\u6837\u7b97\u6cd5,\u7ee7\u627fSolver\u7c7b \"\"\"\n    def __init__(self, bandit):\n        super().__init__(bandit)\n        self._a = np.ones(self.bandit.K)  # \u5217\u8868,\u8868\u793a\u6bcf\u6839\u62c9\u6746\u5956\u52b1\u4e3a1\u7684\u6b21\u6570\n        self._b = np.ones(self.bandit.K)  # \u5217\u8868,\u8868\u793a\u6bcf\u6839\u62c9\u6746\u5956\u52b1\u4e3a0\u7684\u6b21\u6570\n\n    def run_one_step(self):\n        samples = np.random.beta(self._a, self._b)  # \u6309\u7167Beta\u5206\u5e03\u91c7\u6837\u4e00\u7ec4\u5956\u52b1\u6837\u672c\n        k = np.argmax(samples)  # \u9009\u51fa\u91c7\u6837\u5956\u52b1\u6700\u5927\u7684\u62c9\u6746\n        r = self.bandit.step(k) # \u4e0e\u73af\u5883\u4ea4\u4e92\n\n        self._a[k] += r  # \u66f4\u65b0Beta\u5206\u5e03\u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\n        self._b[k] += (1 - r)  # \u66f4\u65b0Beta\u5206\u5e03\u7684\u7b2c\u4e8c\u4e2a\u53c2\u6570\n        return k\n\nnp.random.seed(1)\nthompson_sampling_solver = ThompsonSampling(bandit_10_arm)\nthompson_sampling_solver.run(5000)\nprint('\u6c64\u666e\u68ee\u91c7\u6837\u7b97\u6cd5\u7684\u7d2f\u79ef\u61ca\u6094\u4e3a\uff1a', thompson_sampling_solver.regret)\nplot_results([thompson_sampling_solver], [\"ThompsonSampling\"])\n</pre> class ThompsonSampling(Solver):     \"\"\" \u6c64\u666e\u68ee\u91c7\u6837\u7b97\u6cd5,\u7ee7\u627fSolver\u7c7b \"\"\"     def __init__(self, bandit):         super().__init__(bandit)         self._a = np.ones(self.bandit.K)  # \u5217\u8868,\u8868\u793a\u6bcf\u6839\u62c9\u6746\u5956\u52b1\u4e3a1\u7684\u6b21\u6570         self._b = np.ones(self.bandit.K)  # \u5217\u8868,\u8868\u793a\u6bcf\u6839\u62c9\u6746\u5956\u52b1\u4e3a0\u7684\u6b21\u6570      def run_one_step(self):         samples = np.random.beta(self._a, self._b)  # \u6309\u7167Beta\u5206\u5e03\u91c7\u6837\u4e00\u7ec4\u5956\u52b1\u6837\u672c         k = np.argmax(samples)  # \u9009\u51fa\u91c7\u6837\u5956\u52b1\u6700\u5927\u7684\u62c9\u6746         r = self.bandit.step(k) # \u4e0e\u73af\u5883\u4ea4\u4e92          self._a[k] += r  # \u66f4\u65b0Beta\u5206\u5e03\u7684\u7b2c\u4e00\u4e2a\u53c2\u6570         self._b[k] += (1 - r)  # \u66f4\u65b0Beta\u5206\u5e03\u7684\u7b2c\u4e8c\u4e2a\u53c2\u6570         return k  np.random.seed(1) thompson_sampling_solver = ThompsonSampling(bandit_10_arm) thompson_sampling_solver.run(5000) print('\u6c64\u666e\u68ee\u91c7\u6837\u7b97\u6cd5\u7684\u7d2f\u79ef\u61ca\u6094\u4e3a\uff1a', thompson_sampling_solver.regret) plot_results([thompson_sampling_solver], [\"ThompsonSampling\"]) <pre>\u6c64\u666e\u68ee\u91c7\u6837\u7b97\u6cd5\u7684\u7d2f\u79ef\u61ca\u6094\u4e3a\uff1a 57.19161964443925\n</pre>"},{"location":"lm/rl/basic/mab-code/#-code","title":"\u591a\u81c2\u8001\u864e\u673a-Code\u00b6","text":""},{"location":"lm/rl/basic/mab/","title":"\u591a\u81c2\u8001\u864e\u673a","text":"<p>\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\u662f\u7814\u7a76\u63a2\u7d22\uff08explore\uff09\u4e0e\u5229\u7528\uff08exploit\uff09\u6280\u672f\u7406\u8bba\u7684\u6700\u4f73\u73af\u5883\u3002\u4e86\u89e3\u591a\u81c2\u8001\u864e\u673a\u7684\u63a2\u7d22\u4e0e\u5229\u7528\u95ee\u9898\uff0c\u5bf9\u63a5\u4e0b\u6765\u6211\u4eec\u5b66\u4e60\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u63a2\u7d22\u6709\u5f88\u91cd\u8981\u7684\u5e2e\u52a9\u3002</p> <p>\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\u4e0e\u5f3a\u5316\u5b66\u4e60\u7684\u4e00\u5927\u533a\u522b\u5728\u4e8e\u5176\u4e0e\u73af\u5883\u7684\u4ea4\u4e92\u5e76\u4e0d\u4f1a\u6539\u53d8\u73af\u5883\uff0c\u5373\u591a\u81c2\u8001\u864e\u673a\u7684\u6bcf\u6b21\u4ea4\u4e92\u7684\u7ed3\u679c\u548c\u4ee5\u5f80\u7684\u52a8\u4f5c\u65e0\u5173\uff0c\u6240\u4ee5\u53ef\u770b\u4f5c\u65e0\u72b6\u6001\u7684\u5f3a\u5316\u5b66\u4e60\uff08stateless reinforcement learning\uff09\u3002</p>"},{"location":"lm/rl/basic/mab/#\u521b\u5efa\u7c7b","title":"\u521b\u5efa\u7c7b","text":"<p>\u9996\u5148\u6211\u4eec\u521b\u5efa\u4e86\u4e00\u4e2a\u8001\u864e\u673a\u7684\u7c7b</p> <p>\u5173\u4e8e\u7c7b</p> <p>\u7f16\u5199\u7c7b\u662f\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\u7684\u4e00\u5927\u7279\u8272\u3002\u5bf9\u8c61\u662f\u6307\u67d0\u4e2a\u7279\u5b9a\u7684\u4e1c\u897f\uff0c\u6bd4\u5982\u6211\u7684\u52b3\u65af\u83b1\u65af\u5e7b\u5f71\u3002\u90a3\u4e48\u4e3a\u4e86\u66f4\u597d\u5730\u8ba9\u4eba\u4eec\uff08\u7f16\u7a0b\u65f6\u662f\u8ba1\u7b97\u673a\uff09\uff0c\u4f60\u53ef\u4ee5\u544a\u8bc9\u5b83\u8fd9\u662f\u4e00\u8f86\u8c6a\u8f66\uff08\u7f16\u7a0b\u65f6\u662f\u5b9a\u4e49\u4e00\u4e2a\u7c7b\uff09\u3002\u8c6a\u8f66\u5c31\u662f\u4e00\u4e2a\u7c7b\u3002\u4f60\u5f53\u7136\u4e0d\u80fd\u5f00\u8c6a\u8f66\u672c\u8eab\uff0c\u4f60\u53ea\u80fd\u5f00\u5c5e\u4e8e\u8c6a\u8f66\u8fd9\u4e2a\u7c7b\u4e2d\u7684\u67d0\u4e00\u5177\u4f53\u7684\u8f66\uff0c\u6bd4\u5982\u6211\u7684\u52b3\u65af\u83b1\u65af\u5e7b\u5f71\u3002\u90a3\u4e48\u6839\u636e\u7c7b\u6765\u521b\u5efa\u5bf9\u8c61\u7684\u8fc7\u7a0b\u88ab\u79f0\u4e3a\u5b9e\u4f8b\u5316\uff0c\u8fd9\u8ba9\u4f60\u80fd\u4f7f\u7528\u7c7b\u7684\u5b9e\u4f8b\u3002</p> <ul> <li><code>__init__()</code>\u662f\u4e00\u4e2a\u6bcf\u6b21\u521b\u5efa\u5b9e\u4f8b\u65f6\u90fd\u4f1a\u81ea\u52a8\u8fd0\u884c\u4e00\u904d\u7684\u65b9\u6cd5\uff08\u5b9a\u4e49\u5728\u7c7b\u4e2d\u7684\u51fd\u6570\u90fd\u53eb\u65b9\u6cd5\uff09\u3002</li> <li>\u5f62\u53c2self\u5fc5\u987b\u653e\u7b2c\u4e00\u4e2a\uff0c\u5b83\u662f\u4e00\u4e2a\u6307\u5411\u5b9e\u4f8b\u672c\u8eab\u7684\u5f15\u7528\uff0c\u6bcf\u4e2a\u4e0e\u7c7b\u76f8\u5173\u7684\u65b9\u6cd5\u90fd\u81ea\u52a8\u8c03\u7528self\u3002\u540e\u9762\u7684\u5f62\u53c2\u53ef\u4ee5\u81ea\u5df1\u8bbe\u7f6e\u3002</li> <li><code>self.</code>\u5f00\u5934\u7684\u53d8\u91cf\u53ef\u4f9b\u7c7b\u5185\u6240\u6709\u65b9\u6cd5\u4f7f\u7528\uff0c\u6211\u4eec\u8fd8\u53ef\u4ee5\u901a\u8fc7\u7c7b\u7684\u4efb\u4f55\u5b9e\u4f8b\u6765\u8bbf\u95ee\u8fd9\u4e9b\u53d8\u91cf\uff0c\u4f8b\u5982\uff1a\u5148\u5b9a\u4e49\u4e86<code>my_worst_car=car(Rolls-Royce,Phantom)</code>\uff0c\u5047\u8bbe\u6709\u5b9a\u4e49\u76f8\u5e94\u5c5e\u6027\uff0c\u5219\u53ef\u4ee5\u5982\u6b64\u4f7f\u7528<code>my_worst_car.car_name</code></li> <li>\u5173\u4e8e\u5c5e\u6027\u503c</li> <li>\u7c7b\u4e2d\u6bcf\u4e00\u4e2a\u5c5e\u6027\u90fd\u5fc5\u987b\u6709\u521d\u59cb\u503c\uff0c\u54ea\u6015\u662f0\u6216\u7a7a\u5b57\u7b26\u4e32\uff0c\u6bd4\u5982\u4f60\u53ef\u4ee5\u76f4\u63a5\u5728<code>__init__()</code>\u5b9a\u4e49<code>self.odometer=0</code></li> <li>\u4fee\u6539\u5c5e\u6027\u503c\u7684\u4e09\u79cd\u65b9\u6cd5<ul> <li>\u5b9e\u4f8b\u4e2d\u76f4\u63a5\u4fee\u6539\uff0c\u89c1\u4e0a\u9762\u6bd4\u5982<code>my_worst_car.car_name=tesla</code></li> <li>\u901a\u8fc7\u65b9\u6cd5\u4fee\u6539\uff0c\u5728\u7c7b\u4e2d\u5b9a\u4e49\u4e00\u4e2a\u53ef\u4ee5\u4f20\u5165\u53c2\u7684\u65b9\u6cd5\u5e76\u4f7f\u7528\u5b83\u53bb\u4fee\u6539\u5b9e\u4f8b\u5bf9\u5e94\u7684\u5c5e\u6027\uff0c\u5982\u4e0b</li> </ul> </li> </ul> <pre><code>...\n  def update_car_name(self, car_name):\n    self.car_name = car_name\n...\nmy_worst_car.update_car_name(tesla)\n</code></pre>"},{"location":"lm/rl/basic/mab/#\u7ee7\u627f\u7c7b","title":"\u7ee7\u627f\u7c7b","text":""},{"location":"lm/rl/basic/mab/#\u91cd\u5199\u5b9e\u4f8b\u7528\u4f5c\u5c5e\u6027","title":"\u91cd\u5199\u3001\u5b9e\u4f8b\u7528\u4f5c\u5c5e\u6027","text":"<p>\u7136\u540e\uff0c\u6211\u4eec\u521b\u5efa\u4e86Solver\u7236\u7c7b\u548c\u5b50\u7c7b</p> <ul> <li>\u521b\u5efa\u5b50\u7c7b\u65f6\uff0c\u7236\u7c7b\u5fc5\u987b\u5305\u542b\u5728\u5f53\u524d\u6587\u4ef6\u5939\u4e2d\uff0c\u5e76\u4e14\u5728\u524d\u9762</li> <li>\u5b9a\u4e49\u5b50\u7c7b\u65f6\u5fc5\u987b\u5728\u62ec\u53f7\u5185\u6307\u5b9a\u7236\u7c7b\u540d\u79f0\uff0c\u8fd9\u91cc<code>class EpsilonGreedy(Solver):</code>\uff0c\u5b50\u7c7b\u4f1a\u7ee7\u627f\u7236\u7c7b\u7684\u6240\u6709\u5c5e\u6027\u548c\u65b9\u6cd5</li> <li>super()\u662f\u4e00\u4e2a\u7279\u6b8a\u7684\u51fd\u6570\uff0c\u7528\u4e8e\u5c06\u7236\u7c7b\u548c\u5b50\u7c7b\u5173\u8054\u8d77\u6765\uff0c\u8fd9\u884c\u4ee3\u7801\u8868\u793a\uff0c\u8c03\u7528\u7236\u7c7b\u7684\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u8ba9\u5b50\u7c7b\u5b9e\u4f8b\u5305\u542b\u7236\u7c7b\u7684\u6240\u6709\u5c5e\u6027\uff1b\u5728\u5b98\u7f51\u4e2d\u7684<code>super(EpsilonGreedy, self)</code>\u662fPython 2\u7684\u5199\u6cd5\uff0c\u5728Python 3\u4e2d\u7a7a\u7740\u5373\u53ef\uff0c\u5b8c\u5168\u76f8\u540c</li> <li>\u91cd\u5199\u7236\u7c7b\u7684\u65b9\u6cd5\uff1a\u9700\u8981\u5b50\u7c7b\u4e2d\u5b9a\u4e49\u4e00\u4e2a\u548c\u7236\u7c7b\u4e2d\u65b9\u6cd5\u5b8c\u5168\u540c\u540d\u7684\u65b9\u6cd5\uff0c\u5c31\u50cf\u8fd9\u91cc\u7684<code>run_one_step</code></li> <li>\u5c06\u5b9e\u4f8b\u7528\u4f5c\u5c5e\u6027<ul> <li>\u5f53\u6211\u4eec\u7ed9\u7c7b\u6dfb\u52a0\u8d8a\u6765\u8d8a\u591a\u7ec6\u8282\u65f6\u4f1a\u53d8\u5f97\u81c3\u80bf\uff0c\u90a3\u4e48\u5c31\u53ef\u4ee5\u62c6\u51fa\u4e00\u4e9b\u5c0f\u7c7b\uff0c\u6bd4\u5982\u7535\u8f66\u53ef\u4ee5\u63d0\u53d6\u51fa\u4e00\u4e2a<code>Battery</code>\u7684\u7c7b\uff0c\u5e76\u5c06\u4e00\u4e2a<code>Battery</code>\u7684\u5b9e\u4f8b\u7528\u4e8e\u7535\u8f66\u7c7b\u7684\u5c5e\u6027\uff0c\u6bd4\u5982\u5728\u7535\u8f66\u7c7b\u7684\u521d\u59cb\u5316\u65b9\u6cd5\u4e2d\u5199<code>self.battery=Battery()</code></li> <li>\u4e8e\u662f\u6211\u4eec\u53ef\u4ee5\u8fd9\u4e48\u7528\u53bb\u8bbf\u95ee\u6211\u7279\u65af\u62c9\u7684\u7535\u6c60\u60c5\u51b5\uff0c<code>my_worst_car.battery.describe_battery()</code>\uff08<code>describe_battery()</code>\u662f<code>Battery</code>\u7c7b\u4e2d\u7684\u4e00\u4e2a\u65b9\u6cd5\uff09</li> </ul> </li> </ul>"},{"location":"lm/rl/basic/mab/#\u591a\u91cd\u7ee7\u627f","title":"\u591a\u91cd\u7ee7\u627f","text":"<p>\u6bd4\u5982\u963f\u65af\u987f\u9a6c\u4e01\u8fd9\u8f66\u65e2\u662f\u5c5e\u4e8e\u8457\u540d\u7535\u5f71\u9053\u5177\uff08007\u4e2d\uff09\uff0c\u53c8\u662f\u8c6a\u8f66\uff0c\u90a3\u600e\u4e48\u529e\u5462\uff1f</p> <p><pre><code>class MovieProp:\n    def __init__(self, movie_name, **kwargs):\n        self.movie_name = movie_name\n        super().__init__(**kwargs)  # \u7ee7\u7eed\u8c03\u7528\u4e0b\u4e00\u4e2a\u7236\u7c7b\n\n    def appear_in_movie(self):\n        return f\"\u51fa\u73b0\u5728\u7535\u5f71\u300a{self.movie_name}\u300b\u4e2d\"\n\nclass LuxuryCar:\n    def __init__(self, price, brand, **kwargs):\n        self.price = price\n        self.brand = brand\n        super().__init__(**kwargs)  # \u7ee7\u7eed\u8c03\u7528\u4e0b\u4e00\u4e2a\u7236\u7c7b\n\n    def show_luxury(self):\n        return f\"{self.brand}\u8c6a\u8f66\uff0c\u552e\u4ef7{self.price}\u4e07\"\n\nclass AstonMartin(MovieProp, LuxuryCar):\n    def __init__(self, model, movie_name, price):\n        super().__init__(\n            movie_name=movie_name,\n            price=price,\n            brand=\"Aston Martin\"\n        ) # &lt;- 1 \n        self.model = model\n\n    def introduce(self):\n        return f\"{self.model}: {self.appear_in_movie()}, {self.show_luxury()}\"\n</code></pre> 1\u5904\u540c\u65f6\u7ee7\u627f\u7684\u4ee3\u7801\u4e5f\u53ef\u4ee5\u7528\u4e0b\u9762\u7684\uff1a <pre><code>    def __init__(self, model, movie_name, price):\n        MovieProp.__init__(self, movie_name)\n        LuxuryCar.__init__(self, price, \"Aston Martin\")\n        self.model = model\n</code></pre></p>"},{"location":"lm/rl/basic/mab/#\u03b5\u8870\u51cf\u65b9\u5f0f\u5b58\u5728\u6761\u4ef6","title":"\u03b5\u8870\u51cf\u65b9\u5f0f\u5b58\u5728\u6761\u4ef6","text":"<p>\u8fd9\u662f\u5b98\u7f51\u03b5-\u8d2a\u5fc3\u7b97\u6cd5\u7684\u8fd0\u884c\u7ed3\u679c</p> <p>\u4f46\u5b83\u5e76\u6ca1\u6709\u89e3\u91ca\u4e3a\u5565\u9009\u62e9\u5012\u6570\u8870\u51cf\uff0c\u5176\u5b9e\u5b8c\u5168\u53ef\u4ee5\u8bd5\u8bd5\u5176\u4ed6\u8870\u51cf\u7684\u65b9\u6cd5\uff0c\u4f60\u4f1a\u53d1\u73b0\u53ef\u80fd\u5e76\u4e0d\u603b\u662f\u6709\u6548\u7684\u3002</p> <p>\u8fd9\u91cc\u63d0\u4f9b\u4e24\u79cd\u4e0d\u540c\u7684\u8870\u51cf\u65b9\u5f0f\u7684\u8fd0\u884c\u7ed3\u679c</p> \u8870\u51cf\u5f62\u5f0f \u6570\u5b66\u5f62\u5f0f \u63a2\u7d22\u6b21\u6570\u968f\u65f6\u95f4\u589e\u957f \u95ee\u9898\u5206\u6790 \u5012\u6570\u8870\u51cf \u03b5(t) = 1 / t \u2211\u03b5(t) \u2248 log(t)\uff08\u53d1\u6563\uff09 \u4f9d\u7136\u80fd\u4fdd\u8bc1\u6bcf\u4e2a\u81c2\u88ab\u63a2\u7d22\u65e0\u7a77\u591a\u6b21\uff08\u5145\u5206\u63a2\u7d22\uff09 \u5bf9\u6570\u8870\u51cf \u03b5(t) = 1 / log(t+1) \u2211\u03b5(t) \u2248 t / log(t)\uff08\u53d1\u6563\u592a\u5feb\uff09 \u524d\u671f\u8870\u51cf\u592a\u5feb\uff0c\u540e\u671f\u51e0\u4e4e\u4e0d\u518d\u63a2\u7d22\uff0c\u5bb9\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18 \u6307\u6570\u8870\u51cf \u03b5(t) = e^{-t/c} \u2211\u03b5(t) \u6536\u655b \u63a2\u7d22\u6b21\u6570\u6709\u9650\uff08finite\uff09\uff0c\u7b97\u6cd5\u53ef\u80fd\u6c38\u8fdc\u505c\u5728\u9519\u8bef\u7684\u81c2\u4e0a <p>\u4e8b\u5b9e\u4e0a\u7ecf\u5178\u591a\u81c2\u8001\u864e\u673a\u5b58\u5728\u6536\u655b\u6761\u4ef6\uff1a\u03b5(t) \u2192 0 \u4e14 \u2211 \u03b5(t) = \u221e </p>"},{"location":"lm/rl/basic/mab/#\u7406\u89e3\u4e0a\u7f6e\u4fe1\u7b97\u6cd5","title":"\u7406\u89e3\u4e0a\u7f6e\u4fe1\u7b97\u6cd5","text":"<p>\u8003\u8651\u5230\u539f\u6765\u7b97\u6cd5\u5728\u63a2\u7d22\u7684\u9009\u62e9\u4e0a\u6ca1\u6709\u7ae0\u6cd5\uff0c\u6839\u636e\u4eba\u7c7b\u7ecf\u9a8c\uff0c\u80af\u5b9a\u662f\u4f18\u5148\u63a2\u7d22\u90a3\u4e9b\u6ca1\u600e\u4e48\u63a2\u7d22\u8fc7\u7684\uff0c\u4e8e\u662f\u5c31\u6709\u4e86\u4e0a\u7f6e\u4fe1\uff08upper confidence bound\uff0cUCB\uff09\u7b97\u6cd5\uff0c\u4ee3\u7801\u8fd0\u884c\u7ed3\u679c\u5728\u8fd9</p> \\[\\mathbb{P}\\{E[X] \\geq \\bar{x}_n + u\\} \\leq e^{-2nu^2}\\] <p>\u7b80\u5355\u6765\u8bf4\u6211\u62c9\u4e86\u62c9\u6746n\u6b21\uff0c\u4f9d\u636e\u6b64\u6709\u4e2a\u9884\u671f\u4f30\u8ba1\\(x_n\\)\uff0c\u4f46\u662f\u603b\u5f52\u548c\u771f\u5b9e\u7684\\(E[x]\\)\u6709\u5dee\u8ddd\uff08\u4e5f\u5c31\u662f\u5b58\u5728\u8fd0\u6c14\u95ee\u9898\uff09\u3002\u90a3\u4e48\u8fd9\u4e2a\u771f\u5b9e\u7684\u671f\u671b\u503c\u5927\u4e8e\\(x_n+u\\)\uff08u\u662f\u4e00\u4e2a\u81ea\u5df1\u5b9a\u7684\u503c\uff09\u7684\u6982\u7387\u4f1a\u5c0f\u4e8e\u7b49\u4e8e\\(e^{-2nu^2}\\)\u3002</p> <p>\u8be5\u7b97\u6cd5\u5148\u5047\u8bbe\u4e86\u4e00\u4e2a\u786e\u5b9a\u7684p\uff0c\u5e76\u4e14\u6240\u6709\u62c9\u6746\u90fd\u662f\u53ea\u6709p\u7684\u6982\u7387\u771f\u5b9e\u503c\u5927\u4e8e\\(Q_t(A)+U_t(a)\\)\uff0c\u7136\u540e\u5c31\u53bb\u627e\u6240\u6709\u62c9\u6746\u4e2d\u8fd9\u4e2a\u4e1c\u897f\u6700\u5927\u7684\u90a3\u6839\u62c9\u6746\u3002</p> <ul> <li>\\(Q_t(A)\\)\u5c31\u662f\\(x_n\\)\uff0c\u6211\u4eec\u5728\u67d0\u4e00\u4e2a\u65f6\u523b\u81ea\u7136\u77e5\u9053\u6240\u6709\u62c9\u6746\u7684\\(Q_t(A)\\)</li> <li>\u5df2\u77e5\\(p \\leq e^{-2nu^2}\\)\uff0c\u6211\u4eec\u8ba9\u6bcf\u6839\u62c9\u6746\u90fd\u6709\u6700\u5927\u7684\\(U_t(a)\\)\uff0c\u90a3\u4e48\u53d6\u7b49\u5c31\u53ef\u4ee5\u5f97\u5230\\(U_t(a) = \\sqrt{\\frac{2\\log t}{N_t(a)}}\\)</li> </ul> <p>np.argmax\u548cnp.max</p> <p><code>np.argmax</code>\u53ef\u4ee5\u627e\u5230\u4e00\u4e2a\u6570\u7ec4\u4e2d\u6700\u5927\u7684\u9879\u7684\u7d22\u5f15\uff08\u4ece0\u5f00\u59cb\uff09\uff1b<code>np.max</code>\u5219\u662f\u627e\u5176\u4e2d\u6700\u5927\u7684\u9879\u3002</p>"},{"location":"lm/rl/basic/mab/#\u7406\u89e3\u6c64\u666e\u68ee\u7b97\u6cd5","title":"\u7406\u89e3\u6c64\u666e\u68ee\u7b97\u6cd5","text":"<p>\u540c\u6837\u662f\u7528\u6982\u7387\u7684\u65b9\u6cd5\uff0c\u6c64\u666e\u68ee\u91c7\u6837\u7b97\u6cd5\u6bcf\u6b21\u62bd\u53d6\u4e4b\u540e\u5c31\u4f1a\u66f4\u65b0\u5bf9\u5e94\u62c9\u6746\u7684Beta\u5206\u5e03\uff0c\u5e76\u5bf9\u6bcf\u4e2a\u62c9\u6746\u62bd\u5176\u53ef\u80fd\u7684p\uff0c\u9009\u62e9\u62bd\u5230\u6700\u5927p\u7684\u62c9\u6746\u66f4\u65b0\u3002\u8be5\u7b97\u6cd5\u7684\u8fd0\u884c\u7ed3\u679c\u5728\u8fd9</p> <p>np.random.beta</p> <p>\u4ece<code>Beta\u5206\u5e03</code>\u4e2d\u751f\u6210\u4e00\u4e2a\u968f\u673a\u6837\u672c\u3002\u901a\u4fd7\u5730\u8bb2\uff0c<code>np.random.\u6982\u7387\u5bc6\u5ea6\u51fd\u6570</code>\u5c31\u662f\u628a\u51fd\u6570\u5207\u6210\u4e00\u6761\u6761\uff0c\u6492\u8c46\uff0c\u9009\u8c46\u5b50\u843d\u7684\u591a\u7684\u90a3\u4e2a\u6a2a\u8f74\u7684<code>p</code>\u3002</p>"},{"location":"main/","title":"What is BioNeMo?","text":"<p>BioNeMo is a software ecosystem produced by NVIDIA for the development and deployment of life sciences-oriented artificial intelligence models. BioNeMo provides a set of tools to help researchers build, train, and deploy AI models for various biological applications. The main components of BioNeMo are:</p> <ul> <li> <p>BioNeMo Framework: a free-to-use collection of programming tools and packages offering access to optimized, pre-trained biomolecular models and workflows. The framework enables building and customizing models, including training and fine-tuning. Capabilities span various workloads and therapeutic modalities, such as molecular generation, protein structure prediction, protein-ligand, and representation learning.</p> </li> <li> <p>BioNeMo NIMs: easy-to-use, enterprise-ready inference microservices with built-in API endpoints. NIMs are engineered for scalable, self- or cloud-hosted deployment of optimized, production-grade biomolecular foundation models. Check out the growing list of BioNeMo NIMs here.</p> </li> </ul> <p>When choosing between the BioNeMo Framework and BioNeMo NIMs, consider your project's specific requirements. The Framework is ideal for scenarios that require model training, fine-tuning, or customization, offering a comprehensive suite of tools and packages. In contrast, NIMs are optimized for inference-only workflows, providing easy-to-use, enterprise-ready microservices with built-in API endpoints. As a rule, use the Framework for custom model development or high-control modeling, and NIMs for inference against existing models.</p> <p>Get notified of new releases, bug fixes, critical security updates, and more for biopharma. Subscribe.</p>"},{"location":"main/#bionemo-user-success-stories","title":"BioNeMo User Success Stories","text":"<p>Enhancing Biologics Discovery and Development With Generative AI - Amgen leverages BioNeMo and DGX Cloud to train large language models (LLMs) on proprietary protein sequence data, predicting protein properties and designing biologics with enhanced capabilities. By using BioNeMo, Amgen achieved faster training and up to 100X faster post-training analysis, accelerating the drug discovery process.</p> <p>Cognizant to apply generative AI to enhance drug discovery for pharmaceutical clients with NVIDIA BioNeMo - Cognizant leverages BioNeMo to enhance drug discovery for pharmaceutical clients using generative AI technology. This collaboration enables researchers to rapidly analyze vast datasets, predict interactions between drug compounds, and create new development pathways, aiming to improve productivity, reduce costs, and accelerate the development of life-saving treatments.</p> <p>Cadence and NVIDIA Unveil Groundbreaking Generative AI and Accelerated Compute-Driven Innovations - Cadence's Orion molecular design platform will integrate with BioNeMo generative AI tool to accelerate therapeutic design and shorten time to trusted results in drug discovery. The combined platform will enable pharmaceutical companies to quickly generate and assess design hypotheses across various therapeutic modalities using on-demand GPU access.</p> <p>Find more user stories on NVIDIA's Customer Stories and Technical Blog sites.</p>"},{"location":"main/SUMMARY/","title":"SUMMARY","text":"<ul> <li>About</li> <li>Get Started</li> <li>Developer Guide</li> <li>Data Sets</li> <li>Contributing</li> <li>References</li> </ul>"},{"location":"main/about/SUMMARY/","title":"SUMMARY","text":"<ul> <li>Overview</li> <li>Background</li> <li>Release Notes</li> </ul>"},{"location":"main/about/overview/","title":"Overview of BioNeMo","text":"<p>BioNeMo is a software ecosystem produced by NVIDIA for the development and deployment of life sciences-oriented artificial intelligence models. BioNeMo provides a set of tools to help researchers build, train, and deploy AI models for various biological applications. The main components of BioNeMo are:</p> <ul> <li> <p>BioNeMo Framework: A free-to-use collection of programming tools and packages offering access to optimized, pre-trained biomolecular models and workflows. The framework enables building and customizing models, including training and fine-tuning. Capabilities span various workloads and therapeutic modalities, such as molecular generation, protein structure prediction, protein-ligand, and representation learning.</p> </li> <li> <p>BioNeMo NIMs: Easy-to-use, enterprise-ready inference microservices with built-in API endpoints. NIMs are engineered for scalable, self- or cloud-hosted deployment of optimized, production-grade biomolecular foundation models. Check out the growing list of BioNeMo NIMs here.</p> </li> </ul> <p>When choosing between the BioNeMo Framework and BioNeMo NIMs, consider your project's specific requirements. The Framework is ideal for scenarios that require model training, fine-tuning, or customization, offering a comprehensive suite of tools and packages. In contrast, NIMs are optimized for inference-only workflows, providing easy-to-use, enterprise-ready microservices with built-in API endpoints. As a rule, use the Framework for custom model development or high-control modeling, and NIMs for inference against existing models.</p> <p>Get notified of new releases, bug fixes, critical security updates, and more for biopharma. Subscribe.</p>"},{"location":"main/about/overview/#bionemo-user-success-stories","title":"BioNeMo User Success Stories","text":"<p>Enhancing Biologics Discovery and Development With Generative AI - Amgen leverages BioNeMo and DGX Cloud to train large language models (LLMs) on proprietary protein sequence data, predicting protein properties and designing biologics with enhanced capabilities. By using BioNeMo, Amgen achieved faster training and up to 100X faster post-training analysis, accelerating the drug discovery process.</p> <p>Cognizant to apply generative AI to enhance drug discovery for pharmaceutical clients with NVIDIA BioNeMo - Cognizant leverages BioNeMo to enhance drug discovery for pharmaceutical clients using generative AI technology. This collaboration enables researchers to rapidly analyze vast datasets, predict interactions between drug compounds, and create new development pathways, aiming to improve productivity, reduce costs, and accelerate the development of life-saving treatments.</p> <p>Cadence and NVIDIA Unveil Groundbreaking Generative AI and Accelerated Compute-Driven Innovations - Cadence's Orion molecular design platform will integrate with BioNeMo generative AI tool to accelerate therapeutic design and shorten time to trusted results in drug discovery. The combined platform will enable pharmaceutical companies to quickly generate and assess design hypotheses across various therapeutic modalities using on-demand GPU access.</p> <p>Find more user stories on NVIDIA's Customer Stories and Technical Blog sites.</p>"},{"location":"main/about/releasenotes-fw/","title":"Release Notes","text":""},{"location":"main/about/releasenotes-fw/#bionemo-framework-v27","title":"BioNeMo Framework v2.7","text":""},{"location":"main/about/releasenotes-fw/#updates--improvements","title":"Updates &amp; Improvements","text":"<ul> <li> <p>Evo2 model improvements:</p> </li> <li> <p>Context, tensor and data parallelism support in the prediction endpoint as well as support for context lengths over 8192 https://github.com/NVIDIA/bionemo-framework/pull/1123. Fixes https://github.com/NVIDIA/bionemo-framework/issues/910 and https://github.com/NVIDIA/bionemo-framework/issues/1048.</p> </li> <li> <p>LoRA fine-tuning by @gabenavarro: https://github.com/NVIDIA/bionemo-framework/pull/980. Note: internal CI coverage of LoRA convergence is still a work in progress; therefore, we cannot guarantee convergence.</p> </li> <li> <p>Fix a 2x memory-usage issue during Evo2 generation: https://github.com/NVIDIA/NeMo/pull/14515</p> </li> <li> <p>Add flash-decode support in inference: https://github.com/NVIDIA/bionemo-framework/pull/1000</p> </li> <li> <p>Update Rotary Embedding and sequence-length defaults to address incorrect checkpoint conversion: https://github.com/NVIDIA/NeMo/pull/14514</p> </li> <li> <p>Improvements to tag masking in the Evo2 loss: https://github.com/NVIDIA/bionemo-framework/pull/1008</p> </li> <li> <p>Support for Spike-no-more to improve training stability: https://github.com/NVIDIA/bionemo-framework/pull/1011</p> </li> <li> <p>Added a header to SCDL archives, providing improved provenance tracking and supporting future releases. It also adds tracking of AnnData API coverage in SCDL tests.   This header stores metadata about the archive and its composite arrays, including a version; the array lengths and data types; and information about the RowFeatureIndexes. This adds the features necessary to fix https://github.com/NVIDIA/bionemo-framework/issues/999 as well as to implement simple bit-packing of the rowptr, colptr, and data arrays. It should also make SCDL more secure, enable strict compatibility checking, and open the door to further performance improvements: https://github.com/NVIDIA/bionemo-framework/pull/1030</p> </li> <li> <p><code>bionemo-geometric</code> has been deprecated and removed. The molecular-featurization tooling in this package has moved to cuik-molmaker.</p> </li> </ul>"},{"location":"main/about/releasenotes-fw/#known-issues","title":"Known Issues","text":"<ul> <li>We have removed <code>libtiff</code> from the container due to a known vulnerability, CVE-2025-9900. <code>libtiff</code> isn't directly used in any BioNeMo code; however, users might face issues with e.g. Pillow or other common image-manipulation libraries inside this container.</li> </ul>"},{"location":"main/about/releasenotes-fw/#bionemo-framework-v263","title":"BioNeMo Framework v2.6.3","text":""},{"location":"main/about/releasenotes-fw/#updates--improvements_1","title":"Updates &amp; Improvements","text":"<ul> <li>Fixes numerous issues with Evo2 model:</li> <li>Inference/Generation issues resolved. https://github.com/NVIDIA/bionemo-framework/issues/890</li> <li>FP8 training resumption issues resolved. https://github.com/NVIDIA/bionemo-framework/issues/973</li> <li>Bug in inference script that concerns checkpoint loading is fixed. https://github.com/NVIDIA/bionemo-framework/pull/950</li> <li>ESM2 LoRA model inference issue resolved. https://github.com/NVIDIA/bionemo-framework/pull/996</li> <li>Added experimental evo2-mamba model. https://github.com/NVIDIA/bionemo-framework/pull/888</li> <li>Updated base Docker image to nvidia-pytorch 25.06-py3</li> <li>NCCL issue in ESM2 pretraing resolved. https://github.com/NVIDIA/bionemo-framework/issues/970</li> </ul>"},{"location":"main/about/releasenotes-fw/#whats-changed","title":"What's Changed","text":"<ul> <li>Fix test_train_evo2_stops test by @balvisio in https://github.com/NVIDIA/bionemo-framework/pull/965</li> <li>Enable test_train_evo2_stop_at_max_steps_and_continue. by @balvisio in https://github.com/NVIDIA/bionemo-framework/pull/966</li> <li>automated benchmarks: esm2 650M training analogous to bionemo-recipes by @dorotat-nv in https://github.com/NVIDIA/bionemo-framework/pull/975</li> <li>Fix database path in esm2_pretrain_recipes by @pstjohn in https://github.com/NVIDIA/bionemo-framework/pull/978</li> <li>Add fp8 stop and go test for evo2 by @jwilber in https://github.com/NVIDIA/bionemo-framework/pull/974</li> <li>Update Docs Banner for GitHub Pages-hosted Docs by @tshimko-nv in https://github.com/NVIDIA/bionemo-framework/pull/981</li> <li>Add release notes for v2.6.2 (25.06) by @trvachov in https://github.com/NVIDIA/bionemo-framework/pull/971</li> <li>Evo2 Generation fixes and necessary base dependency and container updates. Large change. by @jwilber in https://github.com/NVIDIA/bionemo-framework/pull/949</li> <li>Point NeMo submodule back to main repo by @trvachov in https://github.com/NVIDIA/bionemo-framework/pull/984</li> <li>Use new b2b kernels in evo2 jet tests by @jwilber in https://github.com/NVIDIA/bionemo-framework/pull/985</li> <li>change where dtype is found in checkpoint export by @pstjohn in https://github.com/NVIDIA/bionemo-framework/pull/989</li> <li>Evo2 Mamba by @jstjohn in https://github.com/NVIDIA/bionemo-framework/pull/888</li> <li>Adding inference CDS length tests by @jstjohn in https://github.com/NVIDIA/bionemo-framework/pull/991</li> <li>Fix PIL CVE by @trvachov in https://github.com/NVIDIA/bionemo-framework/pull/992</li> <li>(BIONEMO-2334) Patch TE to fix Evo2 stop and go training by @balvisio in https://github.com/NVIDIA/bionemo-framework/pull/987</li> <li>Fix bug in evo2-mamba train and add test by @jstjohn in https://github.com/NVIDIA/bionemo-framework/pull/994</li> <li>Fix esm2 lora inference by @yzhang123 in https://github.com/NVIDIA/bionemo-framework/pull/996</li> <li>Reset parameters for the ESM-2 contact head on HF export by @pstjohn in https://github.com/NVIDIA/bionemo-framework/pull/983</li> </ul>"},{"location":"main/about/releasenotes-fw/#bionemo-framework-v262","title":"BioNeMo Framework v2.6.2","text":""},{"location":"main/about/releasenotes-fw/#updates--improvements_2","title":"Updates &amp; Improvements","text":"<ul> <li>Fixes numerous ESM2 model issues:</li> <li>Finetuning metric for token classification is fixed. https://github.com/NVIDIA/bionemo-framework/pull/946</li> <li>Losses for finetuning were fixed for data and model parallelism. https://github.com/NVIDIA/bionemo-framework/pull/959</li> <li>Bug in inference script that concerns checkpoint loading is fixed. https://github.com/NVIDIA/bionemo-framework/pull/950</li> <li>Updated base Docker image to nvidia-pytorch 25.04-py3</li> </ul>"},{"location":"main/about/releasenotes-fw/#known-issues_1","title":"Known Issues","text":"<ul> <li>Evo2 generation is broken (i.e. <code>bionemo-evo2/src/bionemo/evo2/run/infer.py</code>). See issue https://github.com/NVIDIA/bionemo-framework/issues/890. A workaround exists on branch https://github.com/NVIDIA/bionemo-framework/pull/949 and we are working to fix this issue for the July release.</li> <li>There is a NCCL communication issue on certain A100 multi-node environments. In our internal testing, we were not able to reproduce the issue reliably across environments. If end users see the following error, please report in issue https://github.com/NVIDIA/bionemo-framework/issues/970 :</li> </ul> <pre><code>[rank9]: torch.distributed.DistBackendError: NCCL error in: /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:3356, internal error - please report this issue to the NCCL developers, NCCL version 2.26.3\n</code></pre>"},{"location":"main/about/releasenotes-fw/#bionemo-framework-v261","title":"BioNeMo Framework v2.6.1","text":""},{"location":"main/about/releasenotes-fw/#updates--improvements_3","title":"Updates &amp; Improvements","text":"<ul> <li>Fixes around ESM2 pretraining and funetuning checkpoints.</li> <li>Added sanity dataset for AMPLIFY testing.</li> <li>Tested against A100 brev instances.</li> <li>Update <code>tornado</code> package to <code>&gt;6.5.0</code> to fix container CVEs.</li> </ul>"},{"location":"main/about/releasenotes-fw/#bionemo-framework-v26","title":"BioNeMo Framework v2.6","text":""},{"location":"main/about/releasenotes-fw/#new-features","title":"New Features","text":"<ul> <li>Adds support for AMPLIFY doi:10.1101/2024.09.23.614603 pre-training and inference, offering a 70% speedup over the xformers-based attention backend with similar final perplexity values at 1M pre-training steps. (4.23 for 120M, 3.05 for 350M). The model is fully compatible with existing weights on HuggingFace.</li> <li>Adds alpha support for LoRA fine-tuning to for ESM2 models. Inference and fine-tuning are enabled along with resumption from a checkpoint.</li> </ul>"},{"location":"main/about/releasenotes-fw/#updates--improvements_4","title":"Updates &amp; Improvements","text":"<ul> <li>Blackwell support, tested on B200 systems.</li> <li>Fixed Grace CPU support, released ARM compatible container.</li> </ul>"},{"location":"main/about/releasenotes-fw/#bionemo-framework-v25","title":"BioNeMo Framework v2.5","text":""},{"location":"main/about/releasenotes-fw/#new-features_1","title":"New Features","text":"<ul> <li>Adding the Evo2 model training workflow, including data preprocessing, pre-training, fine-tuning and inference with bf16 and fp8 support.</li> </ul>"},{"location":"main/about/releasenotes-fw/#updates--improvements_5","title":"Updates &amp; Improvements","text":"<ul> <li>Supporting/upgrading federated learning examples of BioNeMo in NVFlare</li> <li>Upgrade bionemo-moco to v0.0.2</li> <li>Brev.dev launchable tutorials</li> </ul>"},{"location":"main/about/releasenotes-fw/#known-issues_2","title":"Known Issues","text":"<ul> <li>Partial test failures on ARM CPUs.</li> </ul>"},{"location":"main/about/releasenotes-fw/#bionemo-framework-v241","title":"BioNeMo Framework v2.4.1","text":""},{"location":"main/about/releasenotes-fw/#updates--improvements_6","title":"Updates &amp; Improvements","text":"<ul> <li>Applies fixes to ESM2 metric logging that result in NotImplementedError while using Model Parallelism.</li> </ul>"},{"location":"main/about/releasenotes-fw/#bionemo-framework-v24","title":"BioNeMo Framework v2.4","text":""},{"location":"main/about/releasenotes-fw/#new-features_2","title":"New Features","text":"<ul> <li>Draft implementation of Evo2 with support for Hyena operators</li> <li>bionemo-moco v0.0.1 released for building diffusion-like generative models.</li> </ul>"},{"location":"main/about/releasenotes-fw/#known-issues_3","title":"Known Issues","text":"<ul> <li>Partial test failures on ARM CPUs.</li> </ul>"},{"location":"main/about/releasenotes-fw/#updates--improvements_7","title":"Updates &amp; Improvements","text":"<ul> <li>ESM2 fine-tuning script with CLI (finetune_esm2) that supports sequence-level/token-level classification/regression using a CSV dataset.</li> <li>Brev.dev launchable fine-tuning tutorial for ESM2</li> </ul>"},{"location":"main/about/releasenotes-fw/#bionemo-framework-v23","title":"BioNeMo Framework v2.3","text":""},{"location":"main/about/releasenotes-fw/#new-features_3","title":"New Features","text":"<ul> <li>Distributed Inference Support for ESM2 and Geneformer</li> <li>Enables linear inference throughput as GPU number is increased</li> <li>See ESM2 inference notebook and use <code>--num-gpus</code> parameter.</li> </ul>"},{"location":"main/about/releasenotes-fw/#updates--improvements_8","title":"Updates &amp; Improvements","text":"<ul> <li>Prior Geneformer inference on H100 accuracy regression fixed.</li> <li>Base image updated to <code>nvcr.io/nvidia/pytorch:24.12-py3</code>; python updated to 3.12 among other core dependency upgrades (base container release notes here).</li> </ul>"},{"location":"main/about/releasenotes-fw/#bionemo-framework-v22","title":"BioNeMo Framework v2.2","text":""},{"location":"main/about/releasenotes-fw/#new-features_4","title":"New Features","text":"<ul> <li>Small Molecule Featurization</li> <li>Implemented elementary and advanced atom, bond, and full molecule featurizers.</li> <li>GH200 Support for BioNeMo</li> <li>Added a <code>Dockerfile.arm</code> that builds a BioNeMo container that runs on GH200 machines.</li> <li>Publish a version of the BioNeMo container that supports multiple architectures to NGC.</li> </ul>"},{"location":"main/about/releasenotes-fw/#updates--improvements_9","title":"Updates &amp; Improvements","text":"<ul> <li>Single-Cell Dataloader (SCDL)</li> <li>Changed metadata storage to <code>parquet</code> files, which creates a 30x speed up when iterating over a large dataset.</li> <li>Added functionality to concatenate several <code>anndata</code> files without doubling disk memory usage.</li> <li>ESM2</li> <li>Added support for <code>SIGTERM</code> preemption checkpoint saving.</li> <li>Moved ESM-2 and Geneformer training scripts to new executables, <code>train_esm2</code> and <code>train_geneformer</code>, respectively.</li> <li>Moved inference script to a new executable <code>infer_esm2</code>, and deprecated the inference example in the fine-tuning tutorial.</li> <li>Added new Jupyter notebook tutorials for inference and zero-shot protein design. These notebooks can be deployed on the cloud resources as a brev.dev launchable.</li> </ul>"},{"location":"main/about/releasenotes-fw/#known-issues_4","title":"Known Issues:","text":"<ul> <li>Loading a checkpoint for Geneformer inference on H100 has a known regression in accuracy. Work is in progress to resolve by next release.</li> </ul>"},{"location":"main/about/releasenotes-fw/#bionemo-framework-v21","title":"BioNeMo Framework v2.1","text":""},{"location":"main/about/releasenotes-fw/#new-features_5","title":"New Features:","text":"<ul> <li>ESM2 Implementation</li> <li>Updated the ESM-2 Model Card with detailed performance benchmarks comparing BioNeMo2 training against vanilla pytorch.</li> <li>Added ESM-2 inference endpoint for evaluating pre-trained models</li> <li>Size-Aware Batching</li> <li>Added SizeAwareBatchSampler, a pytorch data sampler that batches elements of varying sizes while ensuring that the total size of each batch does not exceed a specified maximum.</li> <li>Added BucketBatchSampler, another pytorch data sampler that groups elements of varying sizes based on predefined bucket ranges, and create batches with elements from each bucket to ensure that each batch has elements with homogeneous sizes.</li> <li>CLI Support</li> <li>Added pydantic interface for pretraining jobs via parsing JSON configuration files that enables passing customized Model and DataModules classes.</li> <li>Implemented pydantic configuration for Geneformer and ESM2 pretraining and finetuning.</li> <li>Added 'recipes' for generating validated JSON files to be used with pydantic interface.</li> <li>Added installable scripts for 2/3 respectively, bionemo-esm2-recipe, bionemo-esm2-train, bionemo-geneformer-recipe, bionemo-geneformer-train.</li> <li>Geneformer support in BioNeMo2:</li> <li>Tested pre-training scripts and fine-tuning example scripts that can be used as a starting point for users to create custom derivative models.</li> <li>Geneformer 10M and 106M checkpoints ported from BioNeMo v1 into BioNeMo v2 available and included in documentation.</li> <li>Added inference scripts</li> <li>Documentation</li> <li>Cell type classification example notebook which covers the process of converting anndata into our internal format, and running inference on that data with a geneformer checkpoint, as well as making use of the inference results.</li> <li>Updated Getting Started guide, ESM-2 tutorials</li> <li>Added Frequently Asked Questions (FAQ) page</li> </ul>"},{"location":"main/about/releasenotes-fw/#bionemo-framework-v20","title":"BioNeMo Framework v2.0","text":""},{"location":"main/about/releasenotes-fw/#new-features_6","title":"New Features:","text":"<ul> <li>ESM-2 implementation</li> <li>State of the art training performance and equivalent accuracy to the reference implementation</li> <li>650M, and 3B scale checkpoints available which mirror the reference model</li> <li>Flexible fine-tuning examples that can be copied and modified to accomplish a wide variety of downstream tasks</li> <li>First version of our NeMo v2 based reference implementation which re-imagines bionemo as a repository of megatron models, dataloaders, and training recipes which make use of NeMo v2 for training loops.</li> <li>Modular design and permissible Apache 2 OSS licenses enables the import and use of our framework in proprietary applications.</li> <li>NeMo2 training abstractions allows the user to focus on the model implementation while the training strategy handles distribution and model parallelism.</li> <li>Documentation and documentation build system for BioNeMo 2.</li> </ul>"},{"location":"main/about/releasenotes-fw/#known-issues_5","title":"Known Issues:","text":"<ul> <li>PEFT support is not yet fully functional.</li> <li>Partial implementation of Geneformer is present, use at your own risk. It will be optimized and officially released in the future.</li> <li>Command line interface is currently based on one-off training recipes and scripts. We are working on a configuration based approach that will be released in the future.</li> <li>Fine-tuning workflow is implemented for BERT based architectures and could be adapted for others, but it requires you to inherit from the biobert base model config. You can follow similar patterns in the short term to load weights from an old checkpoint partially into a new model, however in the future we will have a more direct API which is easier to follow.</li> <li>Slow memory leak occurs during ESM-2 pretraining, which can cause OOM during long pretraining runs. Training with a   microbatch size of 48 on 40 A100s raised an out-of-memory error after 5,800 training steps.</li> <li>Possible workarounds include calling <code>gc.collect(); torch.cuda.empty_cache()</code> at every ~1,000 steps, which appears     to reclaim the consumed memory; or training with a lower microbatch size and re-starting training from a saved     checkpoint periodically.</li> </ul>"},{"location":"main/about/releasenotes-fw/#bionemo-framework-v19","title":"BioNeMo Framework v1.9","text":""},{"location":"main/about/releasenotes-fw/#new-features_7","title":"New Features","text":"<ul> <li>[Documentation] Updated, executable ESM-2nv notebooks demonstrating: Data preprocessing and model training with custom datasets, Fine-tuning on FLIP data, Inference on OAS sequences, Pre-training from scratch and continuing training</li> <li>[Documentation] New notebook demonstrating Zero-Shot Protein Design Using ESM-2nv. Thank you to @awlange from A-Alpha Bio for contributing the original version of this recipe!</li> </ul>"},{"location":"main/about/releasenotes-fw/#bug-fixes-and-improvements","title":"Bug fixes and Improvements","text":"<ul> <li>[Geneformer] Fixed bug in preprocessing due to a relocation of dependent artifacts.</li> <li>[Geneformer] Fixes bug in finetuning to use the newer preprocessing constructor.</li> </ul>"},{"location":"main/about/releasenotes-fw/#bionemo-framework-v18","title":"BioNeMo Framework v1.8","text":""},{"location":"main/about/releasenotes-fw/#new-features_8","title":"New Features","text":"<ul> <li>[Documentation] Updated, executable MolMIM notebooks demonstrating: Training on custom data, Inference and downstream prediction, ZINC15 dataset preprocesing, and CMA-ES optimization</li> <li>[Dependencies] Upgraded the framework to NeMo v1.23, which updates PyTorch to version 2.2.0a0+81ea7a4 and CUDA to version 12.3.</li> </ul>"},{"location":"main/about/releasenotes-fw/#bug-fixes-and-improvements_1","title":"Bug fixes and Improvements","text":"<ul> <li>[ESM2] Fixed a bug in gradient accumulation in encoder fine-tuning</li> <li>[MegaMolBART] Make MegaMolBART encoder finetuning respect random seed set by user</li> <li>[MegaMolBART] Finetuning with val_check_interval=1 bug fix</li> </ul>"},{"location":"main/about/releasenotes-fw/#known-issues_6","title":"Known Issues","text":"<ul> <li>Minor training speed regression observed for models DNABERT, Geneformer, MolMIM</li> <li>Two known critical CVEs GHSA-cgwc-qvrx-rf7f, GHSA-mr7h-w2qc-ffc2. The vulnerabilities arise within a package that's installed by lightning by default. We do not use that package in bionemo framework container. we are also unable to remove the package in question as it's installed as a side-effect of installing lightning.</li> <li>Two known High CVEs from pytorch : GHSA-pg7h-5qx3-wjr3, GHSA-5pcm-hx3q-hm94.</li> </ul>"},{"location":"main/about/releasenotes-fw/#bionemo-framework-v17","title":"BioNeMo Framework v1.7","text":""},{"location":"main/about/releasenotes-fw/#new-models","title":"New Models","text":"<ul> <li>DSMBind, developed under the BioNeMo framework, is a model which can produce comparative values for ranking protein-ligand binding affinities. This release features the capability to perform inference using a newly trained checkpoint.</li> </ul>"},{"location":"main/about/releasenotes-fw/#new-features_9","title":"New Features","text":"<ul> <li>[EquiDock] Remove steric clashes as a post-processing step after equidock inference.</li> <li>[Documentation] Updated Getting Started section which sequentially describes prerequisites, BioNeMo Framework access, startup instructions, and next steps.</li> </ul>"},{"location":"main/about/releasenotes-fw/#known-issues_7","title":"Known Issues","text":"<ul> <li>There is a known security vulnerability with NLTK that can allow for arbitrary code execution via pickle files that are external assets downloaded via nltk.download() (https://github.com/nltk/nltk/issues/3266). BioNeMo itself does not use this dependency in any way, however parts of NeMo text-to-speech (nemo.collections.tts) does use this vulnerable codepath. Since NeMo is installed in the BioNeMo release containers, users are urged to exercise caution when using nemo.collections.tts or nltk.</li> </ul>"},{"location":"main/about/releasenotes-fw/#bionemo-framework-v16","title":"BioNeMo Framework v1.6","text":""},{"location":"main/about/releasenotes-fw/#new-features_10","title":"New Features","text":"<ul> <li>[Model Fine-tuning] <code>model.freeze_layers</code> fine-tuning config parameter added to freeze a specified number of layers. Thank you to github user @nehap25!</li> <li>[ESM2] Loading pre-trained ESM-2 weights and continue pre-training on the MLM objective on a custom FASTA dataset is now supported.</li> <li>[OpenFold] MLPerf feature 3.2 bug (mha_fused_gemm) fix has merged.</li> <li>[OpenFold] MLPerf feature 3.10 integrated into bionemo framework.</li> <li>[DiffDock] Updated data loading module for DiffDock model training, changing from sqlite3 backend to webdataset.</li> </ul>"},{"location":"main/about/releasenotes-fw/#bionemo-framework-v15","title":"BioNeMo Framework v1.5","text":""},{"location":"main/about/releasenotes-fw/#new-models_1","title":"New Models","text":"<ul> <li>Geneformer is out of Beta status. This release includes newly trained checkpoints and benchmarks, including a variant based on the publication with 10M parameters, and the largest variant of geneformer publically available to date with 106M parameters.</li> </ul>"},{"location":"main/about/releasenotes-fw/#bionemo-framework-v14","title":"BioNeMo Framework v1.4","text":""},{"location":"main/about/releasenotes-fw/#new-models_2","title":"New Models","text":"<ul> <li>Beta Geneformer a foundation model for single-cell data that encodes each cell as represented by an ordered list of differentially expressed genes for that cell.</li> </ul>"},{"location":"main/about/releasenotes-fw/#new-features_11","title":"New Features","text":"<ul> <li>Beta Geneformer pretraining with custom datasets</li> <li>Low-Rank Adaptation (LoRA) finetuning for ESM2</li> </ul>"},{"location":"main/about/releasenotes-fw/#bug-fixes-and-improvements_2","title":"Bug fixes and Improvements","text":"<ul> <li>OpenFold training improved benchmarks and validation of optimizations</li> </ul>"},{"location":"main/about/releasenotes-fw/#known-issues_8","title":"Known Issues","text":"<ul> <li>BioNeMo Framework v24.04 container is vulnerable to GHSA-whh8-fjgc-qp73 in onnx 1.14.0. Users are advised not to open untrusted onnx files with this image. Restrict your mount point to minimize directory traversal impact. A fix for this is scheduled in the 24.05 (May) release.</li> </ul>"},{"location":"main/about/releasenotes-fw/#bionemo-framework-v13","title":"BioNeMo Framework v1.3","text":""},{"location":"main/about/releasenotes-fw/#new-models_3","title":"New Models","text":"<ul> <li>MolMIM implementation under BioNeMo framework, a small molecule model developed at NVIDIA which can be used to produce embeddings and novel molecules.</li> </ul>"},{"location":"main/about/releasenotes-fw/#new-features_12","title":"New Features","text":"<ul> <li>MolMIM re-trained on more data is now available in the framework, and achieves state of the art performance.</li> <li>MolMIM property guided tutorial notebook covering property guided optimization using our new framework model.</li> <li>MolMIM training tutorial available walking users through either training from scratch or from an existing checkpoint on your own data.</li> <li>MolMIM tutorial notebook covering molecular sampling and property prediction is also now available.</li> <li>Numerous optimizations from NVIDIA's entry to the MLPerf competition have been added to OpenFold. Documentation and detailed benchmarks are works in progress and will be published in upcoming releases. This release contains the following performance optimizations:</li> <li>Fused GEMMs in multi-head attention (MHA)</li> <li>Non-blocking data pipeline</li> <li>BF16 precision training</li> <li>Fused MHA gating</li> <li>Inductor Compiled LayerNorm</li> <li>OpenAI Triton LayerNorm kernels</li> <li>OpenAI Triton MHA</li> </ul>"},{"location":"main/about/releasenotes-fw/#bug-fixes-and-improvements_3","title":"Bug fixes and Improvements","text":"<ul> <li>NeMo upgraded to v1.22 (see NeMo release notes),</li> <li>PyTorch Lightning upgraded to 2.0.7</li> <li>NGC CLI has been removed from the release container. If users   download models from inside the container (e.g. using <code>bionemo_data_download</code> or via running specific unit tests),   the NGC CLI will be auto-installed to pull the models from NGC.</li> </ul>"},{"location":"main/about/releasenotes-fw/#known-issues_9","title":"Known Issues","text":"<ul> <li>BioNeMo Framework v24.03 container is vulnerable to GHSA-whh8-fjgc-qp73 in onnx 1.14.0. Users are advised not to open untrusted onnx files with this image. Restrict your mount point to minimize directory traversal impact.</li> </ul>"},{"location":"main/about/releasenotes-fw/#bionemo-framework-v12","title":"BioNeMo Framework v1.2","text":""},{"location":"main/about/releasenotes-fw/#new-models_4","title":"New Models","text":"<ul> <li>OpenFold implementation under BioNeMo framework, derived from public OpenFold and DeepMind AlphaFold-2.</li> <li>DNABERT implementation for computing embeddings for each nucleotide in the input DNA sequence.</li> </ul>"},{"location":"main/about/releasenotes-fw/#new-features_13","title":"New Features","text":"<ul> <li>Training recipes for DNABERT and OpenFold, including automated data processing and full configuration for training.</li> <li>Example tutorials for running inference using OpenFold.</li> <li>Splice Prediction downstream task example for DNABERT.</li> <li>Wrapper scripts for DNABERT and OpenFold to launch jobs on BCP.</li> </ul>"},{"location":"main/about/releasenotes-fw/#bug-fixes-and-improvements_4","title":"Bug fixes and Improvements","text":"<ul> <li>Interface improvements for ESM-2 data ingestion and pre-processing. The interface allows for explicit specification of training, validation, and test sets. The user may set <code>config.model.data.default_dataset_path</code> to maintain prior behavior, or set <code>config.model.data.train.dataset_path</code>, <code>config.model.data.val.dataset_path</code>, <code>config.model.data.test.dataset_path</code> which may all be unique.</li> </ul>"},{"location":"main/about/releasenotes-fw/#known-issues_10","title":"Known Issues","text":"<ul> <li>OpenFold training speed does not yet include MLPerf optimizations, and these will be released in the subsequent release.</li> </ul>"},{"location":"main/about/releasenotes-fw/#bionemo-framework-v11","title":"BioNeMo Framework v1.1","text":""},{"location":"main/about/releasenotes-fw/#new-models_5","title":"New Models","text":"<ul> <li>EquiDock for protein-protein docking pose prediction</li> <li>DiffDock for protein-ligand blind docking pose generation</li> </ul>"},{"location":"main/about/releasenotes-fw/#new-features_14","title":"New Features","text":"<ul> <li>Training recipes for EquiDock and DiffDock, including automated data processing and full configuration for training.</li> <li>Accelerated inference and training for DiffDock via fast tensor-product kernels.</li> <li>Example tutorials for running inference using EquiDock and DiffDock.</li> <li>Recipes for running EquiDock and DiffDock on BCP and Slurm.</li> <li>Pipeline parallel supported for ESM-2nv.</li> <li>Migration of inference notebooks to using pytriton.</li> </ul>"},{"location":"main/about/releasenotes-fw/#bug-fixes-and-improvements_5","title":"Bug fixes and Improvements","text":"<ul> <li>Faster pre-processing of data on BCP.</li> <li>Refactor of download_models.sh to download_models.py for easier CLI use.</li> <li>Refactor of install structure to move from /opt/nvidia to /workspace/bionemo. The environment variable $BIONEMO_HOME now points to the repo base and is required to be set for tests to pass.</li> </ul>"},{"location":"main/about/releasenotes-fw/#security-notice","title":"Security Notice","text":"<p>SchedMD Slurm in the release container is shipped with a security vulnerability, CVE-2022-29501, and therefore this version of Slurm should not be used to run a Slurm cluster (specifically, the processes <code>slurmdbd</code>, <code>slurmctld</code>, and <code>slurmd</code>.</p> <p>In general, the BioNeMo Framework release is designed to ship code and an environment that would be executed on local workstations, or deployed on clusters for large scale training jobs. This container is not designed to run as a service with public facing APIs. A full summary of security vulnerabilities can be found here.</p>"},{"location":"main/about/releasenotes-fw/#bionemo-framework-v10","title":"BioNeMo Framework v1.0","text":""},{"location":"main/about/releasenotes-fw/#new-models_6","title":"New Models","text":"<ul> <li>ESM-2nv for protein sequence representations, pretrained weights of ESM-2 650M and ESM-2 3B converted from HF checkpoint available.</li> </ul>"},{"location":"main/about/releasenotes-fw/#new-features_15","title":"New Features","text":"<ul> <li>Pre-training recipes for ESM-2nv, including automated data processing and full configuration for training</li> <li>Fine-tuning of ESM-2nv with encoder frozen or trainable</li> <li>Downstream task finetuning support for single-value classification (e.g. subcellular localization), single-value regression (e.g. meltome) and per-token classification (e.g. secondary structure)</li> <li>Validation in loop to evaluate performance on downstream tasks during training</li> <li>Example tutorials for pre-training, fine tuning, and downstream tasks</li> </ul>"},{"location":"main/about/releasenotes-fw/#bionemo-framework-v040","title":"BioNeMo Framework v0.4.0","text":""},{"location":"main/about/releasenotes-fw/#new-models_7","title":"New Models","text":"<ul> <li>ESM-1nv for protein sequence representations, pretrained weights available</li> <li>ProtT5nv for protein sequence representation and sequence-to-sequence tasks, pretrained weights available</li> </ul>"},{"location":"main/about/releasenotes-fw/#new-features_16","title":"New Features","text":"<ul> <li>Pre-training for all models, including automated data processing and full configuration for training</li> <li>Fine-tuning of MegaMolBART, ESM-1nv, and ProtT5nv with encoder frozen or trainable</li> <li>Downstream task example applications \u2013 secondary structure prediction for ESM-1nv and ProtT5nv, physchem prediction (lipophilicity, FreeSolv, ESOL) and retrosynthesis prediction for MegaMolBART</li> <li>Validation in loop to evaluate performance on downstream tasks during training: physchem prediction (MegaMolBART) and secondary structure prediction (ESM-1nv and ProtT5nv).</li> <li>Pipeline parallelism supported as a beta feature. Not fully tested.</li> <li>Example notebooks for pre-training, fine tuning, and downstream tasks</li> </ul>"},{"location":"main/about/releasenotes-fw/#known-issues_11","title":"Known Issues","text":"<ul> <li>Data preprocessing on DGX Cloud is slow. Faster to do it on a local machine.</li> </ul>"},{"location":"main/about/releasenotes-fw/#new-apis","title":"New APIs","text":"<ul> <li>BioNeMoDataModule - Encapsulates dataset instantiation in bionemo models so that many different datasets can be used with the same model</li> <li>EncoderFineTuning - Base class to facilitate implementation of downstream tasks built on embeddings from other models</li> </ul>"},{"location":"main/about/background/SUMMARY/","title":"SUMMARY","text":"<ul> <li>NeMo2</li> <li>Megatron Dataset Considerations</li> </ul>"},{"location":"main/about/background/megatron_datasets/","title":"Writing Megatron-LM Compatible Datamodules","text":"<p>Megatron-LM relies on determinism in the training dataset classes to ensure that input tensors are initialized correctly across model-parallel ranks (see NeMo2 Parallelism). As a consequence, ensure that the new dataset classes preserve the required determinism. Common operations such as data augmentation and masking can cause <code>dataset[i]</code> to return random results for a given index, breaking this megatron contract.</p>"},{"location":"main/about/background/megatron_datasets/#multi-epoch-training","title":"Multi-Epoch Training","text":"<p>One training regime where this limitation is most apparent is multi-epoch training, where standard training recipes would apply different random masks or different data augmentation strategies each time the data is encountered. BioNeMo provides some utilities that make multi-epoch training easier, while obeying the determinism requirements of megatron.</p> <p>The [MultiEpochDatasetResampler][bionemo.core.data.multi_epoch_dataset.MultiEpochDatasetResampler] class simplifies the process of multi-epoch training, where the data should both be re-shuffled each epoch with different random effects applied each time the data is seen. To be compatible with this resampler, the provided dataset class's <code>__getitem__</code> method should accept a [EpochIndex][bionemo.core.data.multi_epoch_dataset.EpochIndex] tuple that contains both an epoch and index value. Random effects can then be performed by setting the torch random seed based on the epoch value:</p> <pre><code>class MyDataset:\n    def __getitem__(self, idx: EpochIndex):\n        rng = torch.Generator()\n        rng.manual_seed(idx.epoch)\n        ...\n</code></pre> <p>Avoid <code>torch.manual_seed</code></p> <pre><code>Megatron-LM handles torch seeding internally. Calling `torch.cuda.manual_seed` inside the user-provided dataset\ncan cause issues with model parallelism. See [megatron/core/tensor_parallel/random.py#L198-L199](\nhttps://github.com/NVIDIA/Megatron-LM/blob/dddecd19/megatron/core/tensor_parallel/random.py#L198-L199) for more\ndetails.\n</code></pre> <p>For deterministic datasets that still want to train for multiple epochs with epoch-level shuffling, the [IdentityMultiEpochDatasetWrapper][bionemo.core.data.multi_epoch_dataset.IdentityMultiEpochDatasetWrapper] class can simplify this process by wrapping a dataset that accepts integer indices and passes along the [EpochIndex][bionemo.core.data.multi_epoch_dataset.EpochIndex] index values from the resampled dataset.</p> <pre><code>class MyDeterministicDataset:\n    def __getitem__(self, index: int): ...\n\n\ndataset = IdentityMultiEpochDatasetWrapper(MyDeterministicDataset())\nfor sample in MultiEpochDatasetResampler(dataset, num_epochs=3, shuffle=True):\n    ...\n</code></pre>"},{"location":"main/about/background/megatron_datasets/#training-resumption","title":"Training Resumption","text":"<p>To ensure identical behavior with and without job interruption, BioNeMo provides [MegatronDataModule][bionemo.llm.data.datamodule.MegatronDataModule] to save and load state dict for training resumption, and provides [WrappedDataLoader][nemo.lightning.data.WrappedDataLoader] to add a <code>mode</code> attribute to [DataLoader][torch.utils.data.DataLoader].</p> <pre><code>class MyDataModule(MegatronDataModule):\n    def __init__(self, *args, **kwargs):\n        super().__init__()\n        ...\n\n    def train_dataloader(self):\n        self.update_init_global_step()  # required to set the correct `global_step` for resumption\n        return WrappedDataLoader(\n            ...,  # any other arguments for DataLoader\n            mode=\"train\",\n        )\n\n    def val_dataloader(self):\n        self.update_init_global_step()  # required to set the correct `global_step` for resumption\n        return WrappedDataLoader(\n            ...,  # any other arguments for DataLoader\n            mode=\"validation\",\n        )\n\n    def test_dataloader(self):\n        self.update_init_global_step()  # required to set the correct `global_step` for resumption\n        return WrappedDataLoader(\n            ...,  # any other arguments for DataLoader\n            mode=\"test\",\n        )\n</code></pre> <p>MegatronDataModule</p> <pre><code>Users will see non-overlapping training curve if their datamodule is not inheritting from `MegatronDataModule`, unless similar logics are handled by the users. In `MegatronDataModule`, `self.update_init_global_step()` must be called right before the dataloaders are returned to ensure that training resumes with the correct sample index instead of restarting from 0 everytime. We recommend users to inherit from `MegatronDataModule` similar to the pattern above.\n</code></pre> <p>WrappedDataLoader</p> <pre><code>The `WrappedDataLoader` class is a wrapper around the PyTorch DataLoader class that adds the `mode` attribute to the dataloader. The dataloader will resume from the last sample index only when mode is 'train'. `val_dataloader` and `test_dataloader` are unaffected.\n\nWARNING: 'train' is the default value of `mode` in `WrappedDataLoader`. If not set, users might find their validation/test dataloader changes behavior by resuming from a non-zero sample index.\n</code></pre>"},{"location":"main/about/background/megatron_datasets/#testing-datasets-for-megatron-compatibility","title":"Testing Datasets for Megatron Compatibility","text":"<p>BioNeMo also provides utility functions for test suites to validate that datasets conform to the megatron data model. The [assert_dataset_compatible_with_megatron][bionemo.testing.data_utils.assert_dataset_compatible_with_megatron] function calls the dataset with identical indices and ensures the outputs are identical, while also checking to see if <code>torch.manual_seed</code> was used.</p> <p>Example datasets in BioNeMo</p> <pre><code>The [ESMMaskedResidueDataset][bionemo.esm2.data.dataset.ESMMaskedResidueDataset] demonstrates one approach for\nleveraging [EpochIndex][bionemo.core.data.multi_epoch_dataset.EpochIndex] indices to perform epoch-level\nrandomization within the confines of megatron's data model.\n</code></pre>"},{"location":"main/about/background/nemo2/","title":"NeMo2","text":""},{"location":"main/about/background/nemo2/#checkpointing","title":"Checkpointing","text":"<p>In NeMo, there are two distinct mechanisms for continuing training from a checkpoint: resuming from a training directory and restoring from a checkpoint.</p> <p>Note: If both <code>--result-dir</code> and <code>--ckpt-dir</code> are provided, checkpoints in <code>--result-dir</code> take precedence. The <code>--ckpt-dir</code> is only used if <code>--result-dir</code> contains no checkpoints.</p> <p>1. Resuming Training from a Directory</p> <p>When a training job runs, NeMo saves checkpoints in a designated results directory specified with the <code>--result-dir</code> flag. If the same job is restarted and a checkpoint exists in that directory, the most recent checkpoint is automatically loaded and training continues from the exact step and optimizer state stored there.</p> <p>If no checkpoint is found in the results directory:</p> <ul> <li>No checkpoint directory specified \u2192 training starts from scratch.</li> <li>Checkpoint dir is specified by <code>--ckpt-dir</code> \u2192 NeMo attempts to restore from that checkpoint (see \"Restoring from a   Checkpoint\" below).</li> </ul> <p>2. Restoring from a Checkpoint</p> <p>To start a new training run initialized from a checkpoint in a different directory, the restore configuration can be set to point to that checkpoint via the <code>--ckpt-dir</code> flag. NeMo will begin training from that checkpoint\u2019s weights and optimizer state. After the initial restoration, subsequent runs of the same job follow the standard resuming flow - loading from the results directory \u2014 without repeating the restore step.</p> <pre><code>               +-------------------------+\n               | Start Training Job      |\n               +-----------+-------------+\n                         |\n     +-------------------+-------------------+\n     |                                       |\nResults dir has                         Results dir empty\ncheckpoint \u2192 Resume                           |\n                                             v\n                                   +----------------------------+\n                                   | Checkpoint dir specified?  |\n                                   +-------------+--------------+\n                                             |\n                              +----------------+----------------+\n                              |                                 |\n                         No \u2192 Start from scratch        Yes \u2192 Restore\n                                                       from checkpoint\n                                                                 \u2193\n                                                            Resume flow\n</code></pre>"},{"location":"main/about/background/nemo2/#parallelism","title":"Parallelism","text":"<p>NeMo2 represents tools and utilities to extend the capabilities of <code>pytorch-lightning</code> to support training and inference with megatron models. While pytorch-lightning supports parallel abstractions sufficient for LLMs that fit on single GPUs (distributed data parallel, aka DDP) and even somewhat larger architectures that need to be sharded across small clusters of GPUs (Fully Sharded Data Parallel, aka FSDP), when you get to very large architectures and want the most efficient pretraining and inference possible, megatron-supported parallelism is a great option.</p> <p>So in other words, NeMo2 adds the Megatron strategy in addition to the standard DDP and FSDP strategies.</p> <p>Many downstream constraints and conventions are driven by the underlying constraints of megatron.</p>"},{"location":"main/about/background/nemo2/#deeper-background-on-megatron","title":"Deeper Background on Megatron","text":""},{"location":"main/about/background/nemo2/#other-options-for-parallelizing-smaller-models","title":"Other Options for Parallelizing Smaller Models","text":"<p>Megatron is a system for supporting advanced varieties of model parallelism. While vanilla models can be executed in parallel with systems, such as distributed data parallel (DDP), or moderately large models can be trained with Meta's Fully Sharded Data Parallel (FSDP/FSDP2), when you work with larger models and want to train them with maximal efficiency, it is ideal to use some variant of megatron.</p>"},{"location":"main/about/background/nemo2/#ddp-background","title":"DDP Background","text":"<p>DDP is the best option when you can fit the entire model on every GPU in your cluster. With DDP, you can parallelize your <code>global batch</code> across multiple GPUs by splitting it into smaller <code>mini-batches</code>, one for each GPU. Each GPU computes the forward and backward pass independently for its subset of data, allowing for maximal utilization. Synchronization of gradients occurs after the backward pass is complete for each batch, followed by a weight update that ensures all GPUs have synchronized parameters for the next iteration. Here is an example of how this might appear on your cluster with a small model:</p> <p></p>"},{"location":"main/about/background/nemo2/#fsdp-background","title":"FSDP Background","text":"<p>FSDP extends DDP by sharding (splitting) model weights across GPUs in your cluster to optimize memory usage. While data is still split across GPUs in the same way as DDP, FSDP strategically synchronizes and broadcasts the necessary shards of model weights to all GPUs just-in-time for computation during the forward pass.</p> <p>For example, when a layer is needed for computation, the owning GPU sends that shard of weights to the other GPUs, which then perform the forward computation on that layer. After the computation is complete, FSDP frees the memory for that layer on all GPUs except the one that owns the shard. This process continues iteratively for each layer until the entire model has been executed on the data.</p> <p>Note: This process parallelizes the storage in a way that enables too large models to be executed (assuming a single layer is not too large to fit on a GPU). Megatron (next) co-locates both storage and compute.</p> <p>The following two figures show two steps through the forward pass of a model that has been sharded with FSDP.  </p>"},{"location":"main/about/background/nemo2/#model-parallelism","title":"Model Parallelism","text":"<p>Model parallelism is the catch-all term for the variety of different parallelism strategies that could be applied to parallelizing your model across a cluster. Below we explain several varieties of model parallelism that are implemented in megatron. As mentioned in the previous section, one key advantage to the megatron-specific parallelism types described next are that they co-locate storage and compute of the layers. Inefficiencies caused by naive scheduler implementations are also addressed (discussed in the section on schedulers).</p>"},{"location":"main/about/background/nemo2/#pipeline-parallelism","title":"Pipeline Parallelism","text":"<p>Pipeline parallelism is similar to FSDP, but the model blocks that are sharded are also computed in parallel on the nodes that own the model weight in question. You can think of this as a larger simulated GPU that happens to be spread across several child GPUs. Examples of this include <code>parallel_state.is_pipeline_last_stage()</code>, which is commonly used to tell if a particular node is on last pipeline stage, where you compute the final head outputs or loss. </p> <p>Similarly, there are convenience environmental lookups for the first pipeline stage (where you compute the embedding for example) <code>parallel_state.is_pipeline_first_stage()</code>.</p>"},{"location":"main/about/background/nemo2/#tensor-parallelism","title":"Tensor Parallelism","text":"<p>Tensor parallelism represents splitting single layers across GPUs. This can also solve the problem where some individual layers could in theory be too large to fit on a single GPU, where FSDP would not be possible. This would still work since individual layer weights (and computations) are distributed. Examples of this in megatron include <code>RowParallelLinear</code> and <code>ColumnParallelLinear</code> layers. </p>"},{"location":"main/about/background/nemo2/#sequence-parallelism","title":"Sequence Parallelism","text":"<p>In megatron, \"sequence parallelism\" refers to the parallelization of the dropout, and layernorm blocks of a transformer. The idea is roughly as follows. First, remember that in a typical transformer architecture, the <code>embedding_dimension</code> is the only dimension that <code>LayerNorm</code> is applied over. Similarly, Dropout (outside of the attention block) is an operation that is applied on the last embedding dimension. These two layers are independent over the sequence dimension, so they can be processed in blocks on separate GPUs. As can be seen in the following figure, the initial <code>LayerNorm</code> in a multi-headed transformer block is executed in parallel. Next the results are gathered for the self attention and linear layers (which are typically set up for tensor parallelism). Next the result from those layers is scattered back to sequence parallel nodes which execute dropout, do a residual connection from the previous sequence parallel output, and a layernorm. Next those results are again gathered for the final FFN and activation layers prior to a final scattering across sequence parallel GPUs for the output of that transformer block. </p> <p>As a user, if you know that your transformer is executed in parallel and you have custom losses or downstream layers, you need to make sure that the appropriate gather operations are occurring for your loss computation etc.</p>"},{"location":"main/about/background/nemo2/#context-parallelism","title":"Context Parallelism","text":"<p>Context parallelism extends sequence parallelism by also parallelizing the attention mechanism itself, similar to Ring Attention. In general, if you are using a transformer, context parallelism is going to perform better than sequence parallelism for very long input sequences. That said, due to the necessity of all-gather and reduce scatter operations throughout the architecture, the general advice that you should avoid these kinds of parallelism if a micro-batch fits on a single device still holds. Splitting across elements in a global batch represent the fewest necessary communications between GPUs on your cluster, so standard DDP should run the fastest if you can get your training loop for a micro batch to fit on one GPU.</p>"},{"location":"main/about/background/nemo2/#mixing-parallelism-strategies","title":"Mixing Parallelism Strategies","text":"<p>You can mix different kinds of parallelism together to achieve a better result. In general, experimentation should be done to identify the optimal mix of parallelism. See this YouTube tutorial from Jared Casper for more background on megatron parallelism strategies.</p> <p>The figure below demonstrates how mixing strategies results in larger \"virtual GPUs\", which similarly means you have fewer distinct micro-batches in flight across your cluster. Note that the number of virtual GPUs is multiplicative so if you have <code>TP=2</code> and <code>PP=2</code>, then you are creating a larger virtual GPU out of <code>2*2=4</code> GPUs, so your cluster size needs to be a multiple of 4 in this case. </p>"},{"location":"main/about/background/nemo2/#scheduling-model-parallelism","title":"Scheduling Model Parallelism","text":"<p>You can improve on naive schedules by splitting up micro-batches into smaller pieces, executing many stages of the model on single GPUs, and starting computing the backwards pass of one micro-batch while another is going through forward. These optimizations allow for better cluster GPU utilization to be achieved. For example, the following figure shows how more advanced splitting techniques in megatron (for example, the interleaved scheduler) offer better utilization when model parallelism is used. As best possible, we don't recommend using model parallelism (DDP). </p>"},{"location":"main/contributing/code-review/","title":"Code Review","text":"<p>This document describes the process and etiquette for code review in the BioNeMo repo. You should read this document if you are a developer working in the BioNeMo repo.</p> <p>The purpose of these guidelines is to help reduce the friction between engineers writing code and those reviewing code. As with many rules, there are exceptions. These exceptions are not comprehensive, so if you find exceptions that should be listed, please raise them so they can be evaluated for their inclusion.</p>"},{"location":"main/contributing/code-review/#code-review-process","title":"Code Review Process","text":"<p>The code review process is progressive:</p> <ol> <li>Review by your team</li> <li>Review by domain experts (CODEOWNERS)</li> <li>Approval by Approval-list users.</li> <li>(Optional) Coverage Check approval by Approval-list users.</li> </ol>"},{"location":"main/contributing/code-review/#1-team-review","title":"1. Team Review","text":"<p>You should first ask contributors to review your change. The contributing team can provide the most contextualized feedback, and this review step is where most issues with the change should be caught and addressed.</p> <p>Proceed to the next step after you've addressed your team's comments and have received an approval. There is no actual requirement in gitlab to receive your team-based approval - it is simply best practice.</p>"},{"location":"main/contributing/code-review/#2-owner-review","title":"2. Owner Review","text":"<p>Code owners are domain experts for a particular part of the repository. They are typically the original authors of a set of source files. Code ownership structures tend to mirror team structures; a single team is often responsible for a functional component.</p> <p>You must receive approval from at least one owner of every file you change. Unless the file(s) do not have any owners specified in the <code>CODEOWNERS</code> file.</p> <p>If your change only modifies files owned by your team, owner review happens implicitly in the team review step (i.e. in many cases you may already have this requirement satisfied after step 1 above).</p>"},{"location":"main/contributing/code-review/#3-approval","title":"3. Approval","text":"<p>You must also receive approval for your change. Approval indicates that the change is ready to be merged, and is the final step in the review process. Self approval is strictly forbidden.</p> <p>Approval is granted by an approver, in the form of an approval stamp in gitlab. Approvers review an entire change, in contrast to owners, who focus on reviewing the files that they own.</p> <p>To find an approver, first ask your team if there is a preferred approver. You can also check in #clara-discovery-bionemo-dev.</p> <p>*If your team has an approver, approval will usually be granted shortly after your team has had a chance to review your change.</p> <p>*Often, a single review from one person will be sufficient to complete the entire review process. If the reviewer is on your team, is an approver, and is an owner of the files you modified, then the process may collapse to a single review.</p>"},{"location":"main/contributing/code-review/#4-coverage-check","title":"4. Coverage Check","text":"<p>Our repository has automated checks to ensure test coverage has not regresed. The coverage check approvers will be the same as the Approval-list users. If codeline test coverage regresses, the Approvers must make a judgement call whether it is acceptible or not the merge the code. Occaisonally the coverage check algorithm has a false positive (i.e. code coverage doesn't regress, yet coverage check approval is flagged by gitlab), and in this case Approvers are i free to simply approve the false coverage regression.</p>"},{"location":"main/contributing/code-review/#responsibilities","title":"Responsibilities","text":""},{"location":"main/contributing/code-review/#all-commenters-reviewers-owners-approvers-etc","title":"All Commenters (Reviewers, Owners, Approvers, etc.)","text":"<p>If a comment thread is start by anyone, it is expected that the thread starter resolves the comment. Resolving a thread by the original thread starter indicates that the person who started the discussion is happy with the outcome.</p>"},{"location":"main/contributing/code-review/#reviewers","title":"Reviewers","text":"<p>All developers can and should review changes. These reviews are fundamental to maintaining the quality of the codebase. Reviews are also an important way to stay aware of what people are working on and increase the bus factor for areas of the code.</p> <p>Reviewers should always do the following when reviewing code:</p> <ul> <li> <p>Be respectful.</p> </li> <li> <p>Assume best intentions.</p> </li> <li> <p>Review the code, not the person.</p> </li> <li> <p>Leave clear, actionable feedback. Use comments in gitlab to signal that you expect   changes to be made, and explicitly enumerate them. If you don't, it can leave the author of the patch wondering if   your comments are optional. Requesting code changes should not be interpreted as a   judgment of the change, but rather as an indicator that the   reviewer wants to engage with the author to turn it into an   approval.</p> </li> </ul> <p>A more detailed etiquette guide can be found later in this document.</p>"},{"location":"main/contributing/code-review/#owners","title":"Owners","text":"<p>As an owner, you have the ability to delay code from being merged by withholding your signoff. This ability comes with important responsibilities:</p> <ul> <li> <p>A duty to respond to reviews in a timely manner. If you can't stay   on top of review requests, you should relinquish ownership.</p> </li> <li> <p>A bias to \"yes\". \"No\", by itself, is never an acceptable answer.   When you reject a change you must work with the change author to   arrive at a mutually agreeable solution.</p> </li> </ul>"},{"location":"main/contributing/code-review/#approvers","title":"Approvers","text":"<p>As an approver, you have additional responsibilities beyond that of an owner:</p> <ul> <li> <p>You are responsible for the change and the effect it has on the   codebase.</p> </li> <li> <p>You must ensure that reviews have been performed by the appropriate   reviewers, that these reviews were not rushed.</p> </li> <li> <p>If a change breaks something, you are expected to be actively   involved in the cleanup.</p> </li> </ul> <p>You should always decline to approve a change if you're unfamiliar with the areas of code it touches.</p>"},{"location":"main/contributing/code-review/#becoming-an-owner","title":"Becoming an Owner","text":"<p>Code ownership information is stored in CODEOWNERS file. Since these CODEOWNERS file are stored in the repository, changing them follows the same process as changing code.</p> <p>To become an owner, add your github username to the CODEOWNERS file that you want to be a part of, and submit the change to Gitlab. The change to the CODEOWNERS file will follow the same review process as any other code change. The existing owners will decide whether to delegate ownership to you or not.</p>"},{"location":"main/contributing/code-review/#becoming-an-approver","title":"Becoming an Approver","text":"<p>As an approver, you are responsible for ensuring the consistency and integrity of our code base. Before becoming an approver, study this document so that you are completely familiar with the responsibilities of reviewers and approvers. Additionally, make sure that you are intimately familiar with our coding style guides and best practices:</p> <ul> <li>Contributing</li> <li>In addition, make sure that you understand and can apply all elements of the     Google Python style guide, which we adhere     to for all Python code</li> </ul>"},{"location":"main/contributing/code-review/#details-on-etiquette-for-good-citizens","title":"Details on Etiquette for Good Citizens","text":"<p>In the following sections, we provide deeper thoughts and recommendations for everyone contributing to the repo, in order to have a fruitful interaction across the team members.</p>"},{"location":"main/contributing/code-review/#patch-changes-sizes-and-policies","title":"Patch changes, sizes, and policies","text":"<ul> <li> <p>It takes 30-45 minutes to review every 100-200 lines of code. Be   mindful of the size of changes you are introducing and try to keep   your patch under 500 lines of code whenever possible. As a change   grows in size (lines of codes) the reviewer's ability to find   issues diminishes.</p> </li> <li> <p>As a corollary, for a refactor-type change, consider separating     \"no-logic-change\" and \"logic-change\" into distinct reviews     (perhaps in a dependent review change) to ease the pattern     matching burden on your reviewers.</p> </li> <li> <p>All reviewers may request an PR is too large if it is larger than   500 lines of net code addition. The only exception are MRs into   the <code>bionemo2/contrib</code> directory, where larger MRs are permissible.   This includes lines of code, but not something such as dummy data or   a fake dataset that may contain thousands of lines of stuff that is not   actually functional code.</p> </li> <li> <p>Each patch should be kept to one logical change, which should be   described in the title of the patch. Unrelated changes should be   split out into separate patches. Fixing whitespace on a line   you're editing is reasonable. Fixing whitespace around the code   you're working on should be a separate 'cleanup' patch.</p> </li> <li> <p>Where possible, larger patches (&gt;500 LOC) should be split into   multiple smaller patches that are consistent individually. Test   your patches before submitting them to Gitlab via gitlab pipelines or locally.   The more you test before submitting your patch for review, the better. It's also   appreciated if you add a line to the commit message describing how   the patch was tested. This prevents people from having to ask   whether and how the patch was tested. Stating that the patch was   not tested is also fine, although you might be asked to do some   testing in cases where that would be reasonable.</p> </li> <li> <p>Abandon patches that are no longer useful or that you don't intend   to keep working on.</p> </li> <li> <p>Follow code styling and rules stated in the project's documents   (for example, contributing.md, of which the Google Python   Style Guide is a subet) as these define the   look and feel of the code which defines the most fundamentals of how the code should be   developed and allows reviewers to focus on the most important aspects of a new piece of code.   For bash scripting please follow the Google Shell Style Guide here</p> </li> <li> <p>We follow a revert + fix policy in the codebase for any showstopper   bug that might appear as a result of an PR introducing errors not   caught by sanity. In exceptional circumstances when an MR cannot be   reverted and there is a hotfix ready, leadership can consider   merging without revert. However, this should be an exception.   Failures policies are described in more depth here.</p> </li> </ul>"},{"location":"main/contributing/code-review/#review-timelines","title":"Review timelines","text":"<ul> <li> <p>In general, patches should remain open for review for at least 24   hours since the last significant modification to the change. The   purpose is to let developers around the world have a chance to   review. Complex reworks, even if they don't change the purpose of   the patch but the way it's implemented, should restart the waiting   period.</p> </li> <li> <p>Speedy changes: A change can go in without the waiting period if its   purpose is to fix a recently-introduced issue that has not been   possible to revert. In that case, the commit message has to   explain what change introduced the problem and the nature of the   problem so that the emergency need becomes apparent. The change   itself should be as limited in scope and impact as possible to   make it simple to assess the impact.</p> </li> <li> <p>Trivial changes that deal with minor issues like inconsistencies in   whitespace or spelling fixes that don't impact the final binary   output also don't need to wait for the round of the world reviews.   Such changes should point out in their commit messages how the   author verified that the binary output is identical. Note that   trivial fixes shouldn't necessarily be expedited: Just like   they're not critical enough for things to go wrong because of   them, they're not critical enough to require quick handling.</p> </li> </ul>"},{"location":"main/contributing/code-review/#reviewers_1","title":"Reviewers","text":"<ul> <li> <p>Do not approve if you have not reviewed the code you were asked to   review. Spend time reviewing or re-assign to someone else. Someone   that approves the change must review the entire change holistically   If you are a code owner of a particular file, it is appropriate to only reviews the files you own.</p> </li> <li> <p>If request an PR change their code, you are responsible for giving concrete   recommendations for what could be changed to resolve the issue the   patch addresses. If you feel strongly that a patch should NEVER be   merged, you are responsible for defending your position and   listening to other points of view. Asking for changes and walking away is   not acceptable, and may cause your approval status to be removed by the   leadership team.</p> </li> <li> <p>Include justification for critique: When you review code, you should   always try to include justification for your critique, unless that   critique is a nit, a style guide violation, or an obvious bug.   Nits and style guide violations tend to overlap, and you shouldn't   have to justify the use of a shared style guide or things like   proper spelling. Likewise, you shouldn't have to justify bug-free   code. However, when it comes to design choices you should always   include justification for when you might want to change certain   things</p> </li> <li> <p>If there have been comments or discussion on a patch, verify that   the comments have been addressed before giving an approval. If you feel   that a comment is invalid, please respond to that comment instead   of just ignoring it.</p> </li> <li> <p>Be conscientious when approving patches. As the arbiter, you need to make sure the MR   is complete, that proper reviews are done, that all the required   tests have passed, that API changes have been reviewed by the API   owners. Please make sure that the necessary convergence tests and unit tests   have passed and have not regressed. If KPI regression (convergence tests) is found, you may need to   consult with other stakeholders before approving the MR. In some   cases a Cl will require convergence testing. Owners/ Approvers   should make sure convergence testing is performed when necessary and   that no new issues are identified. And that overall, the code   changes are sound and integrate well with the rest of the modules   and systems. In the event that the patch breaks things, you are   expected to be actively involved in the cleanup effort and support   the authors by reverting and speeding the fixes. This means you   shouldn't approve a patch just because you trust the author of a   patch - Make sure you understand what the implications of a patch   might be, or leave the review to others. Partial reviews,   reviewing code style, for example, can be given a positive review or a LGTM.   This also applies if you think the patch looks good, but may   not have the experience to know if there may be unintended   consequences.</p> </li> <li> <p>Please make sure that the code changes are covered by the existing   unit tests and if necessary ask the contributor to add or update   tests.</p> </li> </ul>"},{"location":"main/contributing/code-review/#contributors","title":"Contributors","text":"<ul> <li> <p>Before providing a patch for review ask yourself these questions:</p> </li> <li> <p>Is this PR the right size? If it's too long break it up.</p> </li> <li> <p>Is this MR and all the changes included necessary? (all code has     to be maintained)</p> </li> <li> <p>Does this MR duplicate existing functionality? If yes, can I     extend what is there?</p> </li> <li> <p>Is the code readable? Am I using esoteric language constructs     that affect readability? Does the code follow the conventions     of the codebase?</p> </li> <li> <p>Is the MR production ready? In other words - does it have tests,     documentation, error handling, etc, etc.</p> </li> <li> <p>Bring attention to patches that you would like reviewed. Add   reviewers, ask for reviewers on slack or even just rebase it   against the current codebase to bring it to the top of the Gitlab   list. If you're not sure who would be a good reviewer, gitlab will suggest OWNERS based   on the CODEOWNERS file in the UI or look at the   git history of the files that you've changed, and add those   people. For NIM-API based changes there is a small team managing these   therefore seek for those people to review APIs.</p> </li> <li> <p>Try to coordinate with other significant contributors to the code   when making changes to areas you do not own. Before you type a   single line of code!. These people made the most significant   changes to that part of the code and therefore are knowledgeable   of any tradeoffs to be made. Coming with new code already written   will cause painful back and forth and will be less efficient for   all. Learn the design, propose changes and get an agreement before   making changes.</p> </li> <li> <p>Don't modify other people's branches unless you have coordinated this   with the owner of that branch. Not only is this considered rude,   but your changes could be unintentionally lost. An exception to   this would be for branches that have not been updated for more than   90 days and therefore can be considered orphaned.</p> </li> <li> <p>Respond to anyone who has taken the time to review your branches,   even if it's just to say that you disagree. While it may seem   annoying to address a request to fix spelling or 'trivial' issues,   it's generally easy to handle in Gitlab's built-in editor. If you   do use the built-in editor, remember to get that change to your   local copy before re-pushing. It's also acceptable to add fixes   for these sorts of comments to another branch, but it's recommended   that that branch be pushed to Gitlab before the initial branch gets   submitted.</p> </li> <li> <p>Check if there's documentation that needs to be updated to remain   current after your change. If there's no documentation for the   part you're working on, consider adding some.</p> </li> <li> <p>When contributing a significant change to core parts of the code   base, or when introducing a new way of doing something that you   think is worthwhile to apply across the tree, please bring up your   design doc to the commit, so reviewers can read it.</p> </li> <li> <p>Don't expect that people will review your patch unless you ask them   to. Adding other people as reviewers is the easiest way.   But also you can use Slack to actively ping the reviewers, which   is especially useful for urgent MRs.</p> </li> <li> <p>Don't expect people to drop all of what they are doing to review   your patch. Everyone has a day-time job, and while code reviews   are part of that job, they usually do not extend the full working   day.</p> </li> <li> <p>Do not resolve (ack/Done) any comments open by others so they can   find their comments easily and resolve them. Unless being told to   self-resolve.</p> </li> <li> <p>As a contributor you are responsible for the code you bring in and   any failures being caught during unit or convergence testing. Etc.   You should monitor that your code gets merged successfully and   that no errors have appeared after the code has been merged   (nightly testing / convergence testing) and respond promptly to address   any failures.</p> </li> </ul>"},{"location":"main/contributing/code-review/#general-etiquette","title":"General Etiquette","text":"<ul> <li> <p>We try to assume the best of each other in this community. It's okay   to discuss mistakes (e.g., isolated instances of non-trivial and   non-critical changes submitted early) but try to keep such   inquiries blameless. If a change leads to problems with the code,   the focus should be on fixing the issue, not on assigning blame.</p> </li> <li> <p>Be respectful to others when commenting on branches. Comments should   be kept to the code and should be kept in a polite tone. Assume   your colleagues are intelligent and do not intend any malice or   disrespect. Resist the urge to retaliate against perceived verbal   misconduct, such behavior is not conducive to getting branches   merged. Also, avoid absolute and aggressive language as this can   tend to escalate emotions. Comments are meant to be collaborative.   Very often, the commenter might also be incorrect since they may not have   the full story of the patch in mind since they were not the author. A comment   is not a demand, it's a suggestion towards a mutually acceptable solution   between the author and the reviewer.</p> </li> <li> <p>Don't submit code that you know will break other   platforms/dependencies. If your patch affects code that is used by   others, it should be compatible with those. While it would be nice   to update any other dependents, you must at least provide a path   that will allow other platforms to continue working.</p> </li> <li> <p>Don't write commit messages that are vague or wouldn't make sense to   partners that read the logs. For example, do not write \"[topic]   Bugfix\" as your header in the commit message. Keep links to videos   out of the commit message. Again, partners are going to see these   logs and it does not make sense to link to something they will not   have access to view. Keep your commit messages under 72 chars in   length per line. Good commits have an appropriate topic with a   nice one-liner that explains the change briefly. This is then   followed by a few sentences or more on a description of the   change. Be professional in your language and do not put things in   the message that a partner would not understand. Avoid the use of   acronyms, abbreviations, or codenames, especially those meaningful   only at nvidia. Also, use correct English (check your spelling   please). This pertains to the final commit message after the branch   is squashed. Intermediary commit messages do not matter at all. Commits   must be squashed on merge.</p> </li> <li> <p>Consider breaking up large individual patches into smaller patches   grouped by areas. This makes the patches easier to review but   increases the number of patches. The way this is handled is a   personal decision, as long as each patch is still one logical   change.</p> </li> <li> <p>Contributions made to the <code>bionemo/contrib</code> folder have more flexible requirements. All requirements not mentioned below still   apply to the contrib folder. These exceptions are</p> </li> <li> <p>Code line numbers limit is increased to 2200 lines.</p> </li> <li>Unit test coverage requirements are decreased to 65% coverage.</li> <li>Code line length of \\&lt;=120 character spaces is acceptable.</li> <li> <p>Commit messages do not need have as verbose of an explanation.     All other requirements pertaining to approver, contributor, and reviewer responsibility still apply.</p> </li> <li> <p>Reviews are about the code. It's easy to take it personally when   someone is criticizing your code, but the whole idea is to get   better code into our codebase. Again, this also applies in the   other direction: review code, critically think about and respond   to the code, but don't make it personal.</p> </li> <li> <p>Don't develop on a personal branch for a long time and then dump a   large number of files and lines of code into a review as a new   \"feature.\" Features should be developed off of the main trunk just   like any other change. It is even more important to follow   processes as the code becomes more critical. Features can   be broken into small working changes and don't need to be   developed all at once. Creating large changes like this leads to   less efficiency in the review process and can lead to more   mistakes.</p> </li> <li> <p>In BioNeMo, for features under development that are not ready for   production, we put them inside the <code>bionemo2/contrib</code> folder. This allows for teams to develop   faster (less strict reviews) while testing code. When a feature is   complete and well tested, we move it to <code>bionemo2/src</code> or   <code>bionemo2/core</code> and we complete all the requirements for productroduction.</p> </li> </ul>"},{"location":"main/contributing/code-review/#references","title":"References","text":"<ul> <li>Coreboot gerrit guidelines (heavily - inspired the etiquette portion of this document)</li> <li>Code Review Culture</li> <li>Proven practices for peer review</li> <li>https://confluence.nvidia.com/display/DS/SDK+Code+reviews</li> <li>https://confluence.nvidia.com/display/DS/SDK+Best+Practices (Review and source control sections)</li> </ul>"},{"location":"main/contributing/contributing/","title":"Contributing Guidelines","text":"<p>Note</p> <p>For code review standards please see the Code Review page.</p> <pre><code>For all PRs, an approved NVIDIA staff member must sign off and trigger the continuous integration (CI) tests.\nThese are initiated by the member commenting `/build-ci` directly on the PR. All PRs must have successful CI runs and\nsufficient code review before being merged.\n</code></pre>"},{"location":"main/contributing/contributing/#developer-certificate-of-origin-dco","title":"Developer Certificate of Origin (DCO)","text":"<p>We require that all contributors \"sign-off\" on their commits (not GPG signing, just adding the <code>-s | --signoff</code> argument, or follow the instructions below for auto-signing). This sign-off certifies that you adhere to the Developer Certificate of Origin (DCO) (full text); in short that the contribution is your original work, or you have rights to submit it under the same license or a compatible license.</p> <p>Any contribution which contains commits that are not signed-off will not be accepted.</p> <p>To sign off on a commit, simply use the <code>--signoff</code> (or <code>-s</code>) option when committing your changes:</p> <pre><code>git commit -s -m \"Add cool feature.\"\n</code></pre> <p>This will append the following to your commit message:</p> <pre><code>Signed-off-by: Your Name &lt;your@email.com&gt;\n</code></pre> <p>If you would like this to happen automatically to all of your commits, you can modify your local <code>~/.git-config-template.txt</code> file. You can do this with a command like the following:</p> <pre><code>echo \"Signed-off-by: Your Name &lt;your@email.com&gt;\" &gt; ~/.git-commit-template.txt\ngit config --local commit.template ~/.git-commit-template.txt\n</code></pre> <p>If you have a commit that you want to retroactively sign, you can do that with:</p> <pre><code>git commit --amend --no-edit --signoff\n</code></pre>"},{"location":"main/contributing/contributing/#python-coding-standards","title":"Python Coding Standards","text":"<p>This page contains the Python coding standards for the BioNeMo repository. They apply to all Python code in the repository (unless external constraints prevent it).</p>"},{"location":"main/contributing/contributing/#coding-style","title":"Coding Style","text":"<ul> <li>We follow the Google Python Style Guide with a few tweaks.</li> <li>The most important parts of this style guide that our code must adhere to are:</li> <li>Docstring</li> <li>Mutable global state</li> <li>Do not use mutable values as default arguments</li> <li>Default iterators</li> <li>Bad naming / abbreviation</li> <li>The exceptions to this style guide are:</li> <li>Module imports. If a module is uniquely named, import     the module. Otherwise, import the value, type, or function directly.</li> <li>Linting and formatting of all code is required by using <code>ruff</code> with BioNeMo's configured options.</li> <li>Unit testing with <code>pytest</code>. See Unit Tests for more details.</li> <li>Add type annotations everywhere. In particular, new code should all be type-annotated as thoroughly as possible. This   also obviates the need for including type hints in the function docstring. It is ok to omit annotations for private   helper functions, but use your best judgement.</li> <li>Include docstrings for every class, function, and method exposed to the user.</li> <li>Docstrings should answer (a) what is the code doing and (b) why would someone use it.</li> <li>Never use wildcard imports.</li> <li>Define <code>__all__ = (,)</code> in modules: make explicit the API of each module, auto-documenting the most important definitions.</li> <li>Minimize the use of <code>**kwargs</code>.</li> <li><code>raise</code> an <code>Exception</code> instead of using an <code>assert</code> statement.</li> <li>F-strings are preferred to format strings.</li> <li>Loggers are preferred to print. In BioNeMo, you can use logger from <code>import logging</code>.</li> <li>Private functions (functions starting with <code>_</code>) shouldn't be called outside its host file.</li> </ul>"},{"location":"main/contributing/contributing/#general-guidelines","title":"General Guidelines","text":"<ul> <li>User-oriented: make it easy for end users, even at the cost of writing more code in the background</li> <li>Robust: make it hard for users to make mistakes.</li> <li>Well-tested: please add simple, fast unit tests. See Unit Tests.</li> <li>Reusable: for every piece of code, think about how it can be reused in the future and make it easy to reuse.</li> <li>Readable: code should be easy to read and well documented (with comments and docstrings).</li> <li>Legal: if you copy even one line of code from the Internet, make sure that the code allows the license that   BioNeMo supports. Give credit and link back to the code.</li> <li>Sensible: code should make sense. If you think a piece of code might be confusing, write comments.</li> <li>Consistent: we work in a team. It is important to integrate changes with existing code.</li> <li>Readable: your code should be easy to read and understand by any other engineer, including outside NVIDIA. Some   tips:</li> <li>Document your code. Make all comments complete sentences, starting with a capitalized letter and ending with a     period.</li> <li>Avoid abbreviations: 'bn' is harder to understand than 'batch_norm'.</li> <li>Avoid baked-in constants throughout the code. Instead, specify them as parameters to your function. If you must have     a constant, follow the naming guideline (e.g., <code>GLOBAL_CONSTANT</code>).</li> <li>Avoid functions that span hundreds of lines. Large functions are more difficult to read and more difficult to test.     If &gt;120 lines, consider re-factoring it into smaller logical functions, each unit-tested and well-documented.</li> <li>Re-use code by importing. Do not copy and paste code.</li> <li>Usage of third-party code should be legally compatible and attributed.</li> </ul>"},{"location":"main/contributing/contributing/#pull-request-pr-guidelines","title":"Pull Request (PR) Guidelines","text":""},{"location":"main/contributing/contributing/#labeling-your-pr-as-external-contributor","title":"Labeling Your PR as External Contributor","text":"<p>If you are an external contributor (not an NVIDIA employee), please add the <code>contribution</code> label to your PR before submitting. Labels can be accessed in the right sidebar of the GitHub user interface when creating or editing a PR.</p>"},{"location":"main/contributing/contributing/#ci-pipeline-configuration-controls","title":"CI Pipeline Configuration Controls","text":"<p>CI pipeline behavior can be controlled labels to optimize test execution:</p> <p>Key behaviors:</p> <ul> <li>Labels are processed automatically on PR submit/update</li> <li>Invalid combinations default to most restrictive option</li> </ul> <p>By default, CI pipeline is enabled for all PRs and only unit tests are run. To skip CI pipeline, add the <code>ciflow:skip</code> label</p>"},{"location":"main/contributing/contributing/#ciflowskip","title":"ciflow:skip","text":"<ul> <li>Skips entire CI pipeline</li> <li>Use for documentation typos, README updates</li> </ul>"},{"location":"main/contributing/contributing/#ciflowslow","title":"ciflow:slow","text":"<ul> <li>Run slow single GPU integration tests marked as @pytest.mark.slow for bionemo2</li> <li>Use when modifying core functionalities and require extensive moderate complexity testing on a single GPU</li> <li>Disabled by default</li> </ul>"},{"location":"main/contributing/contributing/#ciflownotebooks","title":"ciflow:notebooks","text":"<ul> <li>Enables Jupyter notebooks validation tests under <code>./docs</code> subfolder and <code>./sub-packages/*</code></li> <li>Use when modifying notebooks or notebook-related code</li> <li>Disabled by default</li> </ul>"},{"location":"main/contributing/contributing/#ciflowall","title":"ciflow:all","text":"<ul> <li>Run all tests (unit tests, slow tests, and notebooks) for bionemo2.</li> <li>Without this label, unit tests for bionemo2 in PR CI are run only on when the bionemo2 codebase has been modified</li> <li>Use when introducing significant codebase changes for comprehensive testing</li> <li>Disabled by default</li> </ul>"},{"location":"main/contributing/contributing/#ciflowall-recipes","title":"ciflow:all-recipes","text":"<ul> <li>Run tests for all recipes (under bionemo-recipes). This label can be used to enforce running tests for all recipes.</li> <li>Without this label, unit tests for recipes in PR CI are run only on folders whose codebases have been modified</li> </ul>"},{"location":"main/contributing/contributing/#developer-workflows","title":"Developer Workflows","text":"<p>You should always carefully test your changes. Run <code>pytest ...</code> in your container locally. All tests are done via <code>pytest</code>.</p> <p>Changes that affect model training accuracy or compute performance should be tested on SLURM.</p> <p>Developer workflow for external code contributions is as follows:</p> <ol> <li> <p>External developers must first fork the    upstream BioNeMo OSS repository and for BioNeMo2 (this branch)    use the <code>main</code> branch as base.</p> </li> <li> <p>Clone the forked repository and push changes to the personal fork.</p> </li> </ol> <pre><code>git clone https://github.com/YOUR_USERNAME/YOUR_FORK.git bionemo-framework\n# Checkout the targeted branch and commit changes\n# Push the commits to a branch on the fork (remote).\ngit push -u origin &lt;local-branch&gt;:&lt;remote-branch&gt;\n</code></pre> <p>Developer workflow for internal or those developers that have been granted push access to our repository is as follows:</p> <ol> <li>Clone this repository locally</li> <li>Create a branch which ideally should be of the form <code>username/branch_description</code></li> <li>Push branch up to our repository <code>git push -u origin HEAD</code></li> </ol> <p>For both internal and external developers, the next step is opening a PR:</p> <ol> <li>Once the code changes are staged on the fork and ready for review, a    Pull Request (PR) can be    requested to merge the changes from a branch of the    fork or branch into <code>main</code>.</li> <li>Exercise caution when selecting the source and target branches for the PR.      Note that versioned releases of TensorRT OSS are posted to <code>release/</code> branches of the upstream repo.</li> <li>Creation of a PR creation kicks off the code review process.</li> <li>At least one TensorRT engineer will be assigned for the review.</li> <li>While under review, mark your PRs as work-in-progress by prefixing the PR title with [WIP].</li> <li>Once ready, CI can be started by a developer with permissions when they add a <code>/build-ci</code> comment. This must pass    prior to merging.</li> </ol>"},{"location":"main/contributing/contributing/#general-guidelines_1","title":"General Guidelines","text":"<p>Send your PRs to the <code>main</code> branch. Branch off from <code>main</code> when making your changes. Prefix your branches with your name or initials (for example, <code>your_name/branch_description</code>) if you have push access to our repository otherwise please create a fork with your branch and submit a PR with <code>main</code> as the target.</p> <ul> <li>Make sure your PR does one thing. Have a clear answer to \"What does this PR do?\"</li> <li>Make sure you have the linters enabled via pre-commit hooks (<code>pre-commit install</code>) (See also Pre-commit   validation)</li> <li>Follow the default PR template</li> <li>Make sure all unit tests finish successfully before running PR pipeline by invoking <code>pytest scripts sub-packages</code>.</li> <li>Make sure you added necessary tests and documentation changes (could be just comments in the config files) for the   feature in your PR</li> <li>Rebase your feature branch with the latest <code>main</code> to include any new changes that have been added. Resolve merge   conflicts, if any</li> <li>Send your PR and request a review</li> <li>If your PR is still a work in progress, mark it as \"Draft\"</li> <li>Your merge request must pass all pipelines and be peer-reviewed before it can be merged.</li> <li>Make sure to merge your PR when it is ready and pipeline is successful</li> </ul>"},{"location":"main/contributing/contributing/#unit-tests","title":"Unit Tests","text":"<p>Contributors to BioNeMo FW are expected to unit test their introduced changes.</p> <p>After testing your code locally, trigger tests in the PR's CI. Let a code-owner know that you are ready for the build to run and they will leave a <code>/build-ci</code> comment on your PR which will run the CI test suite.</p>"},{"location":"main/contributing/contributing/#adding-unit-tests","title":"Adding Unit Tests","text":"<p>Add unit tests under <code>tests</code> to examine use cases of new classes or methods that are being added to the codebase. Each test file must be for a particular file or module. For example if you have a file that is under <code>src/path/to/module/my_file_name.py</code> then your test should match the path at <code>tests/path/to/module/test_my_file_name.py</code>. Check the tests folders in the sub-modules of this repository for examples. If you are testing a module, such as integrating multiple examples of different files, then you can use the following pattern to test the module, say in the above example, if you wanted to test functions from several files together that all exist in the same <code>src/path/to/module</code> then you could create a <code>tests/path/to/test_module.py</code> file. The same is true for parents of that module and so on. Generally unit tests should exist at the level of the individual file however.</p>"},{"location":"main/contributing/contributing/#pre-commit-validation","title":"Pre-Commit Validation","text":"<p>We use pre-commit for essential static checks. These checks are enforced on new PRs through the CI process, but should also be run locally. After following the installation instructions for pre-commit, run <code>pre-commit install</code> in the bionemo-framework repository to initialize the checks.</p> <p>To run pre-commit checks (and fix errors where possible), run <code>pre-commit run --all-files</code>. To ignore a pre-commit error locally, use <code>git commit -n ...</code> to allow the commit to proceed with some failing pre-commit checks.</p>"},{"location":"main/contributing/contributing/#updating-license-header-on-python-files","title":"Updating License Header on Python Files","text":"<p>If you add new Python (<code>.py</code>) files, be sure to run our license-check. If you have not already done sone, please install the dev-requirements.txt. If you are working directly inside a release container, you may need to manually install these. We recommend using the developer container for contributions.</p> <pre><code>pip install -r dev-requirements.txt --user\npython ci/scripts/license_check.py --modify --replace --license-header ./license_header -c sub-packages/ -c docs/ -c scripts/ -c ci/ -c internal/\n</code></pre>"},{"location":"main/contributing/contributing/#updating-the-secrets-baseline-file","title":"Updating the secrets baseline file","text":"<p>If false-positives are raised by the detect-secrets pre-commit hook, they can be added to the baseline files by running the following commands:</p> <pre><code>detect-secrets scan --baseline .secrets.baseline --exclude-files '(.*\\.ipynb|.*\\.baseline)$'\ndetect-secrets scan --baseline .secrets-nb.baseline --exclude-files '^.(?!.*\\.ipynb)' --exclude-lines '\"(hash|id|image/\\w+)\":.*'\n</code></pre> <p>The resulting altered baseline files should then be committed.</p>"},{"location":"main/contributing/contributing/#contributing-python-sub-packages-to-bionemo-framework","title":"Contributing Python Sub-Packages to BioNeMo Framework","text":""},{"location":"main/contributing/contributing/#requirements","title":"Requirements","text":"<ul> <li>The sub-package should be located in <code>bionemo-framework/sub-packages</code>.</li> <li>The sub-package should have a <code>pyproject.toml</code> or equivalent package, a <code>VERSION</code> file dynamically linked to the <code>pyproject.toml</code>, a <code>README.md</code> that documents the functionality, usage, and structure of the modules in the package, and a <code>LICENSE</code>.</li> <li>Source code should be placed into <code>src/bionemo/&lt;package-name-suffix&gt;</code> and testing code should be placed into <code>tests/...</code> following the exact same directory structure as the source code that is tested, i.e. <code>src/bionemo/evo2/run/train.py</code> should have unit tests located in <code>tests/bionemo/evo2/run/test_train.py</code> for organizational purposes.</li> <li>Unit tests not associated with source code in BioNeMo can be placed anywhere reasonable under <code>tests/bionemo/&lt;package-name-suffix&gt;</code>.</li> <li>Verify that the <code>pyproject.toml</code> is <code>pip install</code>-able (and <code>python -m build</code>-able).</li> <li>If the sub-package is publishable, follow the instructions in Publishing to PyPI to register or link your package to the sub-package workflow in BioNeMo Framework.</li> <li>Add test dependencies to a <code>test</code> field under <code>[project.optional-dependencies]</code> for test-only dependencies.</li> </ul>"},{"location":"main/contributing/contributing/#publishing-to-pypi","title":"Publishing to PyPI","text":"<p>To publish your sub-package via \"Trusted Publishing\" to PyPI, you can follow the directions specified here: Publishing PyPI Package Distribution Releases using GitHub Actions CI/CD Workflows</p> <ul> <li>Log in to PyPI and Test PyPI.</li> <li>Go to <code>Account Settings &gt; Publishing</code>, and either...</li> <li>If your package already exists on PyPI: <code>Manage [Package Name] &gt; Add a New Publisher</code>.</li> <li>If your package does not yet exist on PyPI: <code>Add a New Pending Publisher</code>.</li> <li>Under the <code>GitHub</code> tab of the publisher management page, input the following information:</li> <li>Owner: <code>NVIDIA</code></li> <li>Repository Name: <code>bionemo-framework</code></li> <li>Workflow: <code>bionemo-subpackage-ci.yml</code></li> <li>Environment Name:<ul> <li><code>pypi</code> for PyPI</li> <li><code>testpypi</code> for Test PyPI</li> </ul> </li> <li>NVIDIA-Only: Run the workflow! For more information, refer to: Sub-Package GitHub Actions Workflow</li> <li>Optional: Add <code>bionemo</code> as an owner or maintainer of the PyPI package if you want help maintaining it.</li> <li>Disclaimer: If this is not done, and the package becomes dysfunctional, then NVIDIA / BioNeMo are not responsible for the health of the package or the sub-package source code, because we will not have the ability to deprecate versions, etc.</li> </ul>"},{"location":"main/contributing/contributing/#sub-package-github-actions-workflow","title":"Sub-Package GitHub Actions Workflow","text":"<ul> <li>Dispatch the <code>bionemo-subpackage-ci.yml</code> workflow from GitHub Actions to test, build, and publish your sub-packages to PyPI!</li> <li>Required: Input a comma-separated list of sub-packages you want to test and/or publish into <code>subpackages</code>.<ul> <li>For example, <code>bionemo-moco,bionemo-llm,bionemo-webdatamodule</code>. The sub-packages will be tested and published in separate parallel environments.</li> </ul> </li> <li>Optional: Set <code>test</code> to <code>true</code> if you want to test your sub-package. (Default: <code>true</code>)<ul> <li>Sub-packages that require pre- or post- installation steps may require modification of the <code>install-and-test</code> job in <code>bionemo-framework/.github/workflows/bionemo-subpackage-ci.yml</code>.</li> <li>Supported <code>pyproject.toml</code> Optional Dependencies: [ <code>te</code> ]</li> </ul> </li> <li>Optional: Set <code>publish</code> to <code>true</code> if you want to publish to Test PyPI or PyPI. (Default: <code>false</code>)<ul> <li>Pre-Requisite: BioNeMo Publishing to PyPI</li> <li>Publishing requires package building, but does not require testing for flexibility of package management.</li> </ul> </li> <li>Optional: Publishes to Test PyPI by default. To publish to PyPI, check <code>Publish to PyPI instead of TestPyPI</code>.</li> <li>Optional: Overwrite the published version of the sub-package on PyPI.<ul> <li>Not recommended, because overwriting a published version will break the <code>pip cache</code> for all users. They will need to re-install the updated package.</li> </ul> </li> <li>Optional: Python-wrapped (PyO3) Rust-based sub-packages are supported with <code>maturin</code> if you set <code>build_framework</code> to <code>rust_pyo3_maturin</code>.</li> <li>Optional: Python, CUDA, Linux, and hardware architecture types can be specified if your sub-package is only supported on a specific ecosystem.</li> </ul>"},{"location":"main/contributing/contributing/#faq","title":"FAQ","text":"<ul> <li>What do I do if I want to test and publish two updated sub-packages that depend on each other?</li> <li>To deal with circular dependencies, publish one package to PyPI first, followed by testing and publishing the other. <code>pip</code> installs dependencies in reverse topological order, and will resolve / break circular dependencies as long as dependency conflicts do not exist. (If dependency conflicts exist, resolve them!)</li> <li>For example, if <code>A</code> depends on <code>B</code>, and <code>B</code> depends on <code>A</code>...<ul> <li>Publish <code>B</code> to PyPI without testing. Untested sub-packages will be published with the version suffix <code>*-dev</code>.</li> <li>Set <code>A</code> to depend on the latest version (i.e. the <code>*-dev</code> version) of <code>B</code>.</li> <li>Test and publish <code>A</code> to PyPI.</li> <li>Test and publish <code>B</code> (which depends on the now-released <code>A</code>) to PyPI.</li> </ul> </li> </ul>"},{"location":"main/contributing/contributing/#todo","title":"TODO","text":"<ul> <li>Support building packages that have installation dependencies, such as <code>bionemo-noodles</code> dependent on <code>maturin</code> or <code>bionemo-&lt;model&gt;</code> dependent on <code>transformer-engine</code>.</li> <li>Automatically cut a release tag for the sub-package via GHA.</li> <li>Support <code>--no-deps</code> installation for BioNeMo sub-packages in TestPyPI, but install OSS dependencies from PyPI, because many OSS dependencies do not have functional versions on TestPyPI.</li> </ul>"},{"location":"main/contributing/sub-package_dependency_graph/","title":"Sub package dependency graph","text":""},{"location":"main/contributing/sub-package_dependency_graph/#sub-package-dependency-graph","title":"Sub-Package Dependency Graph","text":"<p>The script in <code>sub-packages/bionemo/fw/src/dependency_graph.py</code> generates a dependency graph for the BioNeMo sub-packages and verifies that the pyproject.toml and tach.toml files align and capture the dependencies needed for imports in the python files. Additionally, it checks dependencies between BioNeMo sub-packages and creates visual representations of the dependencies in pyproject.toml files, in tach.toml, and in the source files.</p> <p>These are visualizations of the dependency graph from the pyproject.toml files:</p> <p></p> <p>Similarly from the tach.toml file:</p> <p></p> <p>And these are the dependencies from the file imports:</p> <p></p>"},{"location":"main/contributing/Writing%20Documentation/","title":"Writing Good and Thorough Documentation","text":"<p>As a contributor to our codebase, writing high-quality documentation is an essential part of ensuring that others can understand and work with your code effectively. Good documentation helps to reduce confusion, facilitate collaboration, and streamline the development process. In this guide, we will outline the principles and best practices for writing thorough and readable documentation that adheres to the Chicago Manual of Style.</p>"},{"location":"main/contributing/Writing%20Documentation/#chicago-manual-of-style","title":"Chicago Manual of Style","text":"<p>Our documentation follows the Chicago Manual of Style, a widely accepted standard for writing and formatting. This style guide provides a consistent approach to writing, grammar, and punctuation, making it easier for readers to understand and navigate our documentation.</p>"},{"location":"main/contributing/Writing%20Documentation/#key-principles","title":"Key Principles","text":"<p>When writing documentation, keep the following principles in mind:</p> <ol> <li>Clarity: Use clear and concise language to convey your message. Avoid ambiguity and jargon that may confuse readers.</li> <li>Accuracy: Ensure that your documentation is accurate and up-to-date. Verify facts, details, and code snippets    before publishing.</li> <li>Completeness: Provide all necessary information to understand the code, including context, syntax, and examples.</li> <li>Consistency: Use a consistent tone, voice, and style throughout the documentation.</li> <li>Accessibility: Make your documentation easy to read and understand by using headings, bullet points, and short paragraphs.</li> </ol>"},{"location":"main/contributing/Writing%20Documentation/#documentation-structure","title":"Documentation Structure","text":"<p>A well-structured documentation page should include the following elements:</p> <ol> <li>Header: A brief title that summarizes the content of the page.</li> <li>Introduction: A short overview of the topic, including its purpose and relevance.</li> <li>Syntax and Parameters: A detailed explanation of the code syntax, including parameters, data types, and return values.</li> <li>Examples: Concrete examples that illustrate how to use the code, including input and output.</li> <li>Tips and Variations: Additional information, such as best practices, common pitfalls, and alternative approaches.</li> <li>Related Resources: Links to relevant documentation, tutorials, and external resources.</li> </ol>"},{"location":"main/contributing/Writing%20Documentation/#best-practices","title":"Best Practices","text":"<p>To ensure high-quality documentation, follow these best practices:</p> <ol> <li>Use headings and subheadings: Organize your content with clear headings and subheadings to facilitate scanning and navigation.</li> <li>Use bullet points and lists: Break up complex information into easy-to-read lists and bullet points.</li> <li>Provide context: Give readers a clear understanding of the code's purpose, history, and relationships to other components.</li> <li>Review and edit: Carefully review and edit your documentation to ensure accuracy, completeness, and consistency.</li> </ol>"},{"location":"main/contributing/Writing%20Documentation/#resources","title":"Resources","text":"<p>For more information on the Chicago Manual of Style, refer to their online published version.</p> <p>By following these guidelines and principles, you wi ll be able to create high-quality documentation that helps others understand and work with your code effectively. Remember to always prioritize clarity, accuracy, and completeness, and to use the Chicago Style Guide as your reference for writing and formatting.</p>"},{"location":"main/contributing/Writing%20Documentation/jupyter-notebooks/","title":"Jupyter Notebook Support","text":"In\u00a0[1]: Copied! <pre>a = 1\nb = 2\na + b\n</pre> a = 1 b = 2 a + b Out[1]: <pre>3</pre> In\u00a0[2]: Copied! <pre>%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\nxs = np.linspace(0, 2 * np.pi, 100)\nplt.plot(xs, np.sin(xs))\n</pre> %matplotlib inline import matplotlib.pyplot as plt import numpy as np   xs = np.linspace(0, 2 * np.pi, 100) plt.plot(xs, np.sin(xs)) Out[2]: <pre>[&lt;matplotlib.lines.Line2D at 0x7672067fb190&gt;]</pre> In\u00a0[3]: Copied! <pre># NBVAL_CHECK_OUTPUT\n\nimport numpy as np\n\n\nprint(np.arange(5))\n</pre> # NBVAL_CHECK_OUTPUT  import numpy as np   print(np.arange(5)) <pre>[0 1 2 3 4]\n</pre>"},{"location":"main/contributing/Writing%20Documentation/jupyter-notebooks/#jupyter-notebook-support","title":"Jupyter Notebook Support\u00b6","text":"<p>Jupyter notebooks can be rendered as part of the documentation build system as an alternative to markdown files. The docs site uses mkdocs-jupyter to build and render jupyter notebooks as markdown files.</p> <p>Note: There are some limitations to jupyter rendering.</p> <ol> <li>Notebooks are not executed as part of the docs publishing pipeline. CI tests to ensure notebook consistency are run separately (see Testing Jupyter Notebooks).</li> <li>Notebook markdown cells don't support the full range of mkdocs-material configuration, including things like admonitions, referencing automatically-generated API documentation via mkdocstrings etc. (more here).</li> </ol>"},{"location":"main/contributing/Writing%20Documentation/jupyter-notebooks/#example-code-block","title":"Example code block\u00b6","text":"<p>Markdown headings can be used to create a TOC similarly to traditional mkdocs pages.</p>"},{"location":"main/contributing/Writing%20Documentation/jupyter-notebooks/#embedded-visualizations","title":"Embedded visualizations\u00b6","text":"<p>We can also embed images using standard approaches to embedding graphics in notebooks.</p>"},{"location":"main/contributing/Writing%20Documentation/jupyter-notebooks/#testing-jupyter-notebooks","title":"Testing Jupyter Notebooks\u00b6","text":"<p>Jupyter notebooks are run as part of the CI build suite using <code>nbval</code>. To run these tests locally, run</p> <pre>pytest --nbval-lax docs/\n</pre> <p>from the repository root. By default, <code>nbval</code> will only check that the notebook executes successfully. To add additional checks to ensure the consistency of the output, add a <code>#NBVAL_CHECK_OUTPUT</code> marker comment, which will ensure that the output of the saved jupyter notebook matches the output when the notebook is executed in CI.</p> <p>For example:</p>"},{"location":"main/contributing/Writing%20Documentation/mkdocs/","title":"MkDocs","text":""},{"location":"main/contributing/Writing%20Documentation/mkdocs/#build-system","title":"Build system","text":"<p>BioNeMo 2 uses Material for MkDocs to build it's documentation. Docstrings are converted to automatically-generated API reference pages using <code>mkdocstrings</code>, and can be linked from markdown pages using paths.</p>"},{"location":"main/datasets/","title":"BioNeMo Framework: Available Datasets","text":"<p>The BioNeMo Framework provides access to a variety of high-quality datasets for bioinformatics and cheminformatics research. These datasets cover a range of biological and chemical modalities, supporting various research applications. The following table lists the currently available datasets:</p> Dataset Modality Uses CELLxGENE Single Cell Single-Cell Gene Expression UniProt Protein Protein Sequence and Function Analysis <p>For more information about the datasets included in the BioNeMo Framework, refer to the Dataset Cards linked in the table above or the original sources referenced in the respective dataset descriptions.</p>"},{"location":"main/datasets/CELLxGENE/","title":"CELLxGENE","text":""},{"location":"main/datasets/CELLxGENE/#description","title":"Description","text":"<p>CELLxGENE is an aggregation of publicly available single-cell datasets collected by CZI.</p>"},{"location":"main/datasets/CELLxGENE/#dataset-attributes-of-version-2023-12-15","title":"Dataset attributes of version 2023-12-15","text":"<p>Data was downloaded using the CELLxGENE Discover Census version <code>2023-12-15</code>. We first downloaded CELLxGENE census version 2023-12-15 using the <code>cellxgene_census</code> python API. We limited cell data to <code>organism=\"Homo sapiens\"</code>, with a non \"na\" <code>suspension_type</code>, <code>is_primary_data=True</code>, and <code>disease=\"normal\"</code> to limit to non-diseased tissues that are also the primary data source per cell to make sure that cells are only included once in the download. We tracked metadata including \"assay\", \"sex\", \"development_stage\", \"tissue_general\", \"dataset_id\" and \"self_reported_ethnicity\". The metadata \"assay\", \"tissue_general\", and \"dataset_id\" were used to construct dataset splits into train, validation, and test sets. The training set represented 99% of the downloaded cells. We partitioned the data by dataset_id into a train set (99%) and a hold-out set (1%), to make sure that the hold-out datasets were independently collected single cell experiments, which helps evaluate generalizability to new future datasets. In this training split, we made sure that all \"assay\" and \"tissue_general\" labels were present in the training set so that our model would have maximal visibility into different tissues and assay biases. Finally the 1% hold-out set was split further into a validation and test set. This final split was mostly done randomly by cell, however we set aside a full dataset into the test split so that we could evaluate performance after training on a completely unseen dataset, including when monitoring the validation loss during training.</p> <p>These parameters resulted in 23.87 Million single cells collected from a variety of public datasets, all hosted by CZI CELLxGENE census. After the splitting procedure we had:</p> <ul> <li>23.64 Million cells in the training split</li> <li>0.13 Million cells in the validation split</li> <li>0.11 Million cells in the test split</li> </ul>"},{"location":"main/datasets/CELLxGENE/#distributions-of-donor-covariates","title":"Distributions of donor covariates","text":"<p>There are various biases apparent in this dataset.</p>"},{"location":"main/datasets/CELLxGENE/#tissue-distribution","title":"Tissue distribution","text":"<p>At a high level tissues were heavily biased toward the nervous system, which made up nearly 40 percent of the data.</p> <p></p>"},{"location":"main/datasets/CELLxGENE/#assay-distribution","title":"Assay distribution","text":"<p>Assays were also imbalanced in this dataset. As the 10x machine is fairly high throughput and currently popular, it makes sense that the majority of cells present would be from this instrument. Various versions of the 10x instrument made up 18M of the 24M cells while the next largest category was <code>sci-RNA-seq</code>. </p>"},{"location":"main/datasets/CELLxGENE/#sex-distribution","title":"Sex distribution","text":"<p>A bias exists in this dataset for sex. Most of the donor's cells were male-derived at 52%, while female donor's cell contribution made up 42%, and the remaining 6% were not annotated. .</p>"},{"location":"main/datasets/CELLxGENE/#reported-ethnicity-distribution","title":"Reported ethnicity distribution","text":"<p>The dataset has a heavy bias toward cells derived from donors with european ethnicity at 40%, while the next largest category, asian, made up 8%. When considering that nearly 50% were unknown, we might expect that as much as 75% of this dataset is made up of cells extracted from donors of self reported european ethnicity. </p>"},{"location":"main/datasets/CELLxGENE/#age-distribution","title":"Age distribution","text":"<p>This dataset is very heavily balanced toward younger donors. Many of the cells are derived from donors that are under a year of age (over 25%). After that the remaining 75% of cells are dispersed roughly under a normal distribution with a mode of 51-60 other than an additional peak in the 21-30 range. Donors over 61 years old make up approximately 15% of the data.</p> <p></p>"},{"location":"main/datasets/CELLxGENE/#assay-size-distribution","title":"Assay size distribution","text":"<p>Different assays have different ranges of reported gene measurements. On the low end <code>BD Rapsody Targetted mRNA</code> has only a few genes reported, while 10x instruments tend to report on 30,000 genes.</p> <p></p>"},{"location":"main/datasets/CELLxGENE/#dataset-distribution","title":"Dataset distribution","text":"<p>Dataset (for example, a publication that produces data and uploads to CELLxGENE) leads to known batch effects due to different handling procedures, collection procedures, and more. Hence, we stratify our training rather than hold out split by this covariate. Exploring the breakdown of datasets, we see that the top 10 datasets represent approximately 10 million cells of the full CELLxGENE dataset. The largest dataset alone has 4 million cells.</p> <p></p> <p>Looking at the makeup of these top datasets, we see that they represent single tissue categories predominately. Most of these tend to be nervous system datasets, with the exception of one that is balanced between many cell types. </p>"},{"location":"main/datasets/CELLxGENE/#references","title":"References","text":"<ul> <li>CZ CELLxGENE Discover: A single-cell data platform for scalable exploration, analysis and modeling of aggregated data CZI Single-Cell Biology, et al. bioRxiv 2023.10.30; doi: https://doi.org/10.1101/2023.10.30.563174</li> </ul>"},{"location":"main/datasets/CELLxGENE/#data-license","title":"Data License","text":"<p>The data in CELLxGENE are made available by the study authors and Chan Zuckerberg Initiative under the creative commons CC BY 4.0 license. Study authors agree prior to submission that their data is not identifiable, lacking any direct personal identifiers in the metadata. More information may be found in the CELLxGENE Data Submission Policy. Our training, validation and test data, including subsets made available for testing and demonstration purposes, was contributed to CELLxGENE through one or more of the following sources:</p> <ul> <li>Publication Reference: ; Dataset Version: https://datasets.cellxgene.cziscience.com/01fee550-877c-4a13-97b2-96bb43e5a2a5.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/6b701826-37bb-4356-9792-ff41fc4c3161</li> <li>Publication Reference: ; Dataset Version: https://datasets.cellxgene.cziscience.com/9959402b-2e69-4aeb-ba39-efdfa5e0de1a.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/10bf5c50-8d85-4c5f-94b4-22c1363d9f31</li> <li>Publication Reference: ; Dataset Version: https://datasets.cellxgene.cziscience.com/bc484ee8-b3cc-47a3-8f4f-f95aa1fec803.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/a98b828a-622a-483a-80e0-15703678befd</li> <li>Publication Reference: Ahern et al. (2022) Cell; Publication: https://doi.org/10.1016/j.cell.2022.01.012 Dataset Version: https://datasets.cellxgene.cziscience.com/e72d0170-3399-4aa0-8c56-da7b4f0ced6b.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/8f126edf-5405-4731-8374-b5ce11f53e82</li> <li>Publication Reference: Andrews et al. (2022) Hepatology Communications; Publication: https://doi.org/10.1002/hep4.1854 Dataset Version: https://datasets.cellxgene.cziscience.com/19b364f7-db0c-430b-bc16-9b31cbd45a58.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/44531dd9-1388-4416-a117-af0a99de2294</li> <li>Publication Reference: Arutyunyan et al. (2023) Nature; Publication: https://doi.org/10.1038/s41586-023-05869-0 Dataset Version: https://datasets.cellxgene.cziscience.com/5720f13d-fc15-4859-90df-447637fb37c4.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/e2c257e7-6f79-487c-b81c-39451cd4ab3c</li> <li>Publication Reference: Bhaduri et al. (2021) Nature; Publication: https://doi.org/10.1038/s41586-021-03910-8 Dataset Version: https://datasets.cellxgene.cziscience.com/677082ca-48d3-44b8-b5c4-84dffafbba23.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/c8565c6a-01a1-435b-a549-f11b452a83a8</li> <li>Publication Reference: Bhat-Nakshatri et al. (2021) Cell Reports Medicine; Publication: https://doi.org/10.1016/j.xcrm.2021.100219 Dataset Version: https://datasets.cellxgene.cziscience.com/f72aae6e-c997-484c-bffd-6d09e41ef9a4.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/c9706a92-0e5f-46c1-96d8-20e42467f287</li> <li>Publication Reference: Bondoc et al. (2021) Commun Biol; Publication: https://doi.org/10.1038/s42003-021-02562-8 Dataset Version: https://datasets.cellxgene.cziscience.com/20d54624-2098-4ed5-89f8-6da2bb460c3c.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/a261413d-835b-4f1e-ab0c-dada55ea6afd</li> <li>Publication Reference: Burclaff et al. (2022) Cellular and Molecular Gastroenterology and Hepatology; Publication: https://doi.org/10.1016/j.jcmgh.2022.02.007 Dataset Version: https://datasets.cellxgene.cziscience.com/e00e3a74-038a-46fd-8931-f6dc8c90fd13.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/64b24fda-6591-4ce1-89e7-33eb6c43ad7b</li> <li>Publication Reference: Calandrelli et al. (2020) Nat Commun; Publication: https://doi.org/10.1038/s41467-020-18957-w Dataset Version: https://datasets.cellxgene.cziscience.com/c3189372-fceb-493d-98be-23abe1947253.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/db468083-041c-41ca-8f6f-bf991a070adf</li> <li>Publication Reference: Cao et al. (2020) Science; Publication: https://doi.org/10.1126/science.aba7721 Dataset Version: https://datasets.cellxgene.cziscience.com/8f6296d0-5b29-4dca-8061-b97147df5fcc.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/c114c20f-1ef4-49a5-9c2e-d965787fb90c</li> <li>Publication Reference: Chan Zuckerberg Initiative Single-Cell COVID-19 Consortia et al. (2020) medRxiv; Publication: https://doi.org/10.1101/2020.11.20.20227355 Dataset Version: https://datasets.cellxgene.cziscience.com/6c779b98-f437-4cbf-9b81-a3e6be637419.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/0434a9d4-85fd-4554-b8e3-cf6c582bb2fa</li> <li>Publication Reference: Chan et al. (2021) Cancer Cell; Publication: https://doi.org/10.1016/j.ccell.2021.09.008 Dataset Version: https://datasets.cellxgene.cziscience.com/1ba7d495-c1a8-4809-b56d-548fbea77c8a.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/62e8f058-9c37-48bc-9200-e767f318a8ec</li> <li>Publication Reference: Chan et al. (2021) Cancer Cell; Publication: https://doi.org/10.1016/j.ccell.2021.09.008 Dataset Version: https://datasets.cellxgene.cziscience.com/c40911a4-47de-460e-be86-52e39800654c.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/62e8f058-9c37-48bc-9200-e767f318a8ec</li> <li>Publication Reference: Cheng et al. (2018) Cell Reports; Publication: https://doi.org/10.1016/j.celrep.2018.09.006 Dataset Version: https://datasets.cellxgene.cziscience.com/912d943b-9060-4fd3-a12c-ad641a89f0e4.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/43d4bb39-21af-4d05-b973-4c1fed7b916c</li> <li>Publication Reference: Cowan et al. (2020) Cell; Publication: https://doi.org/10.1016/j.cell.2020.08.013 Dataset Version: https://datasets.cellxgene.cziscience.com/b1989183-5808-46ab-87f5-978febb2d26e.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/2f4c738f-e2f3-4553-9db2-0582a38ea4dc</li> <li>Publication Reference: Cowan et al. (2020) Cell; Publication: https://doi.org/10.1016/j.cell.2020.08.013 Dataset Version: https://datasets.cellxgene.cziscience.com/c0d3867e-1a7b-4e57-af62-c563f1934226.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/2f4c738f-e2f3-4553-9db2-0582a38ea4dc</li> <li>Publication Reference: Dom\u00ednguez Conde et al. (2022) Science; Publication: https://doi.org/10.1126/science.abl5197 Dataset Version: https://datasets.cellxgene.cziscience.com/08f58b32-a01b-4300-8ebc-2b93c18f26f7.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/62ef75e4-cbea-454e-a0ce-998ec40223d3</li> <li>Publication Reference: Easter et al. (2024) Nat Commun; Publication: https://doi.org/10.1038/s41467-024-49037-y Dataset Version: https://datasets.cellxgene.cziscience.com/221dff56-a47d-4563-90ed-51b60e2f16d5.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/71f4bccf-53d4-4c12-9e80-e73bfb89e398</li> <li>Publication Reference: Egozi et al. (2021) Nat Med; Publication: https://doi.org/10.1038/s41591-021-01586-1 Dataset Version: https://datasets.cellxgene.cziscience.com/e3a84fef-b6df-49b2-b0ca-ecaf444773ec.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/7651ac1a-f947-463a-9223-a9e408a41989</li> <li>Publication Reference: Elmentaite et al. (2020) Developmental Cell; Publication: https://doi.org/10.1016/j.devcel.2020.11.010 Dataset Version: https://datasets.cellxgene.cziscience.com/3aedefc0-401a-4ee8-a1b5-a0ffc20e1ff2.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/17481d16-ee44-49e5-bcf0-28c0780d8c4a</li> <li>Publication Reference: Elmentaite et al. (2020) Developmental Cell; Publication: https://doi.org/10.1016/j.devcel.2020.11.010 Dataset Version: https://datasets.cellxgene.cziscience.com/5d27ffd6-1769-4564-961f-9bb32d9ca3a4.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/17481d16-ee44-49e5-bcf0-28c0780d8c4a</li> <li>Publication Reference: Elmentaite et al. (2021) Nature; Publication: https://doi.org/10.1038/s41586-021-03852-1 Dataset Version: https://datasets.cellxgene.cziscience.com/c463b937-dbdc-48ff-8037-dd191ea4e41e.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/e33ffcd3-7cbf-4b8c-b0f4-85587ad5019a</li> <li>Publication Reference: Eraslan et al. (2022) Science; Publication: https://doi.org/10.1126/science.abl4290 Dataset Version: https://datasets.cellxgene.cziscience.com/355ed159-f7d7-45e9-bc55-95639f0ab8b0.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/a3ffde6c-7ad2-498a-903c-d58e732f7470</li> <li>Publication Reference: Fan et al. (2019) Nat Commun; Publication: https://doi.org/10.1038/s41467-019-11036-9 Dataset Version: https://datasets.cellxgene.cziscience.com/9b2536db-4576-4906-ae9b-a01a623462f9.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/2902f08c-f83c-470e-a541-e463e25e5058</li> <li>Publication Reference: Fasolino et al. (2022) Nat Metab; Publication: https://doi.org/10.1038/s42255-022-00531-x Dataset Version: https://datasets.cellxgene.cziscience.com/d39144df-fa59-4b63-b07b-9b34613b5c84.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/51544e44-293b-4c2b-8c26-560678423380</li> <li>Publication Reference: Fawkner-Corbett et al. (2021) Cell; Publication: https://doi.org/10.1016/j.cell.2020.12.016 Dataset Version: https://datasets.cellxgene.cziscience.com/e8473c46-eada-43b7-bd1c-e0fed1c4c913.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/60358420-6055-411d-ba4f-e8ac80682a2e</li> <li>Publication Reference: Gabitto et al. (2023) bioRxiv; Publication: https://doi.org/10.1101/2023.05.08.539485 Dataset Version: https://datasets.cellxgene.cziscience.com/291ce735-8d18-4a2f-a6bc-98f75f8d6bc0.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/1ca90a2d-2943-483d-b678-b809bf464c30</li> <li>Publication Reference: Gabitto et al. (2023) bioRxiv; Publication: https://doi.org/10.1101/2023.05.08.539485 Dataset Version: https://datasets.cellxgene.cziscience.com/e9bffe1d-9f07-4467-9230-c080b362e737.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/1ca90a2d-2943-483d-b678-b809bf464c30</li> <li>Publication Reference: Garcia-Alonso et al. (2021) Nat Genet; Publication: https://doi.org/10.1038/s41588-021-00972-2 Dataset Version: https://datasets.cellxgene.cziscience.com/15f77a91-aadc-4e63-81c7-a8614e9ad33d.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/32f2fd23-ec74-486f-9544-e5b2f41725f5</li> <li>Publication Reference: Garcia-Alonso et al. (2022) Nature; Publication: https://doi.org/10.1038/s41586-022-04918-4 Dataset Version: https://datasets.cellxgene.cziscience.com/366847dc-8fc4-42c3-9c27-9704929c6792.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/661a402a-2a5a-4c71-9b05-b346c57bc451</li> <li>Publication Reference: Garcia-Alonso et al. (2022) Nature; Publication: https://doi.org/10.1038/s41586-022-04918-4 Dataset Version: https://datasets.cellxgene.cziscience.com/4b894b0d-6b27-4ab4-a48a-0205e4aaf348.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/661a402a-2a5a-4c71-9b05-b346c57bc451</li> <li>Publication Reference: Garcia-Alonso et al. (2022) Nature; Publication: https://doi.org/10.1038/s41586-022-04918-4 Dataset Version: https://datasets.cellxgene.cziscience.com/c74c3be0-1a80-4af9-8241-d560afc67886.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/661a402a-2a5a-4c71-9b05-b346c57bc451</li> <li>Publication Reference: Gray et al. (2022) Developmental Cell; Publication: https://doi.org/10.1016/j.devcel.2022.05.003 Dataset Version: https://datasets.cellxgene.cziscience.com/9fecd056-d8c8-4ec6-8522-8d40f19c90a8.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/99f1515b-46a2-4bc4-94c3-f62659dc1eb4</li> <li>Publication Reference: Guilliams et al. (2022) Cell; Publication: https://doi.org/10.1016/j.cell.2021.12.018 Dataset Version: https://datasets.cellxgene.cziscience.com/5f2d618d-2a5f-4c31-8750-982342d7dd04.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/74e10dc4-cbb2-4605-a189-8a1cd8e44d8c</li> <li>Publication Reference: Han et al. (2020) Nature; Publication: https://doi.org/10.1038/s41586-020-2157-4 Dataset Version: https://datasets.cellxgene.cziscience.com/7a455e3b-dd79-499b-95c9-8b1b2dde5339.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/38833785-fac5-48fd-944a-0f62a4c23ed1</li> <li>Publication Reference: Han et al. (2022) Blood Cancer Discovery; Publication: https://doi.org/10.1158/2643-3230.BCD-21-0075 Dataset Version: https://datasets.cellxgene.cziscience.com/f905e484-1162-467e-b8c5-835dcfe9bd5c.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/968834a0-1895-40df-8720-666029b3bbac</li> <li>Publication Reference: Hao et al. (2021) Cell; Publication: https://doi.org/10.1016/j.cell.2021.04.048 Dataset Version: https://datasets.cellxgene.cziscience.com/55c120dc-6a20-4caf-9513-f5970b24b1be.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/b0cf0afa-ec40-4d65-b570-ed4ceacc6813</li> <li>Publication Reference: He et al. (2022) Cell; Publication: https://doi.org/10.1016/j.cell.2022.11.005 Dataset Version: https://datasets.cellxgene.cziscience.com/256d6049-b499-47a9-9c9a-20b92f9c6ba6.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/2d2e2acd-dade-489f-a2da-6c11aa654028</li> <li>Publication Reference: He et al. (2022) Cell; Publication: https://doi.org/10.1016/j.cell.2022.11.005 Dataset Version: https://datasets.cellxgene.cziscience.com/25dbd3da-8cb0-4b9d-814c-85ae0a710353.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/2d2e2acd-dade-489f-a2da-6c11aa654028</li> <li>Publication Reference: He et al. (2022) Cell; Publication: https://doi.org/10.1016/j.cell.2022.11.005 Dataset Version: https://datasets.cellxgene.cziscience.com/2b55f5c0-aa82-41e8-9d84-915b1d5a797b.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/2d2e2acd-dade-489f-a2da-6c11aa654028</li> <li>Publication Reference: He et al. (2022) Cell; Publication: https://doi.org/10.1016/j.cell.2022.11.005 Dataset Version: https://datasets.cellxgene.cziscience.com/c4122ff1-79d9-405b-92f1-c1c27234a125.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/2d2e2acd-dade-489f-a2da-6c11aa654028</li> <li>Publication Reference: James et al. (2020) Nat Immunol; Publication: https://doi.org/10.1038/s41590-020-0602-z Dataset Version: https://datasets.cellxgene.cziscience.com/6e2ab5f9-bb51-459a-9fd7-605d29661823.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/7681c7d7-0168-4892-a547-6f02a6430ace</li> <li>Publication Reference: Jardine et al. (2021) Nature; Publication: https://doi.org/10.1038/s41586-021-03929-x Dataset Version: https://datasets.cellxgene.cziscience.com/7c452616-bc00-4499-b511-bfd5de1b7cd6.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/793fdaec-5067-428a-a9db-ecefe135c945</li> <li>Publication Reference: Jardine et al. (2021) Nature; Publication: https://doi.org/10.1038/s41586-021-03929-x Dataset Version: https://datasets.cellxgene.cziscience.com/8ef64f32-461d-4d50-81b6-5718b506a7a8.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/793fdaec-5067-428a-a9db-ecefe135c945</li> <li>Publication Reference: Jardine et al. (2021) Nature; Publication: https://doi.org/10.1038/s41586-021-03929-x Dataset Version: https://datasets.cellxgene.cziscience.com/f402b857-7871-45f4-9ad1-ff943552285a.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/793fdaec-5067-428a-a9db-ecefe135c945</li> <li>Publication Reference: Jin et al. (2021) iScience; Publication: https://doi.org/10.1016/j.isci.2021.103115 Dataset Version: https://datasets.cellxgene.cziscience.com/753caa81-61c5-4126-a61c-df2c546b16d1.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/b9fc3d70-5a72-4479-a046-c2cc1ab19efc</li> <li>Publication Reference: Jorstad et al. (2023) Science; Publication: https://doi.org/10.1126/science.adf6812 Dataset Version: https://datasets.cellxgene.cziscience.com/97a035e0-b9d3-4e7b-adc2-b318316da7f9.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/d17249d2-0e6e-4500-abb8-e6c93fa1ac6f</li> <li>Publication Reference: Joseph et al. (2021) J. Pathol.; Publication: https://doi.org/10.1002/path.5751 Dataset Version: https://datasets.cellxgene.cziscience.com/fb812806-ae3a-45de-9102-0b2f801424e2.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/4b54248f-2165-477c-a027-dd55082e8818</li> <li>Publication Reference: Kamath et al. (2022) Nat Neurosci; Publication: https://doi.org/10.1038/s41593-022-01061-1 Dataset Version: https://datasets.cellxgene.cziscience.com/4936be1a-c766-46e2-815f-1c994aed7a4f.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/b0f0b447-ac37-45b0-b1bf-5c0b7d871120</li> <li>Publication Reference: Kamath et al. (2022) Nat Neurosci; Publication: https://doi.org/10.1038/s41593-022-01061-1 Dataset Version: https://datasets.cellxgene.cziscience.com/dd206caf-13ca-4598-86af-339189adff0d.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/b0f0b447-ac37-45b0-b1bf-5c0b7d871120</li> <li>Publication Reference: Kanemaru et al. (2023) Nature; Publication: https://doi.org/10.1038/s41586-023-06311-1 Dataset Version: https://datasets.cellxgene.cziscience.com/1a7a9fb0-aee1-437f-8a7c-9d132253a4db.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/3116d060-0a8e-4767-99bb-e866badea1ed</li> <li>Publication Reference: King et al. (2021) Sci. Immunol.; Publication: https://doi.org/10.1126/sciimmunol.abe6291 Dataset Version: https://datasets.cellxgene.cziscience.com/02675fa7-5f13-4d89-a07d-9d0ff7996f0d.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/3a2af25b-2338-4266-aad3-aa8d07473f50</li> <li>Publication Reference: King et al. (2021) Sci. Immunol.; Publication: https://doi.org/10.1126/sciimmunol.abe6291 Dataset Version: https://datasets.cellxgene.cziscience.com/6c8a5c10-2617-4cb1-8ed6-20a5e25065ef.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/3a2af25b-2338-4266-aad3-aa8d07473f50</li> <li>Publication Reference: Knight-Schrijver et al. (2022) Nat Cardiovasc Res; Publication: https://doi.org/10.1038/s44161-022-00183-w Dataset Version: https://datasets.cellxgene.cziscience.com/c1e3c998-4961-46c9-929d-d011900964e8.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/43b45a20-a969-49ac-a8e8-8c84b211bd01</li> <li>Publication Reference: Kock et al. (2024) bioRxiv; Publication: https://doi.org/10.1101/2024.06.30.601119 Dataset Version: https://datasets.cellxgene.cziscience.com/a3850101-1e15-4ae2-82f7-bb9289e911d4.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/ced320a1-29f3-47c1-a735-513c7084d508</li> <li>Publication Reference: Kong et al. (2023) Immunity; Publication: https://doi.org/10.1016/j.immuni.2023.01.002 Dataset Version: https://datasets.cellxgene.cziscience.com/30d6b4f5-1475-4b86-a47c-48609d6706c2.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/5c868b6f-62c5-4532-9d7f-a346ad4b50a7</li> <li>Publication Reference: Kong et al. (2023) Immunity; Publication: https://doi.org/10.1016/j.immuni.2023.01.002 Dataset Version: https://datasets.cellxgene.cziscience.com/41bdc5da-b436-485a-a753-9ae297057ee6.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/5c868b6f-62c5-4532-9d7f-a346ad4b50a7</li> <li>Publication Reference: Kong et al. (2023) Immunity; Publication: https://doi.org/10.1016/j.immuni.2023.01.002 Dataset Version: https://datasets.cellxgene.cziscience.com/485d1aee-db62-4373-854c-12a34237e97b.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/5c868b6f-62c5-4532-9d7f-a346ad4b50a7</li> <li>Publication Reference: Kong et al. (2023) Immunity; Publication: https://doi.org/10.1016/j.immuni.2023.01.002 Dataset Version: https://datasets.cellxgene.cziscience.com/8db9570a-3f80-41c9-b927-ae3eb115ba1d.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/5c868b6f-62c5-4532-9d7f-a346ad4b50a7</li> <li>Publication Reference: Kong et al. (2023) Immunity; Publication: https://doi.org/10.1016/j.immuni.2023.01.002 Dataset Version: https://datasets.cellxgene.cziscience.com/dedfeef9-bfb8-4c2f-a196-1afea9a846d8.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/5c868b6f-62c5-4532-9d7f-a346ad4b50a7</li> <li>Publication Reference: Kong et al. (2023) Immunity; Publication: https://doi.org/10.1016/j.immuni.2023.01.002 Dataset Version: https://datasets.cellxgene.cziscience.com/ef7d48a5-c56b-4f13-9903-fb3327924445.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/5c868b6f-62c5-4532-9d7f-a346ad4b50a7</li> <li>Publication Reference: Kumar et al. (2023) Nature; Publication: https://doi.org/10.1038/s41586-023-06252-9 Dataset Version: https://datasets.cellxgene.cziscience.com/24ee53d1-e5ed-47ae-8b8e-7a0d62d91513.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/4195ab4c-20bd-4cd3-8b3d-65601277e731</li> <li>Publication Reference: Kumar et al. (2023) Nature; Publication: https://doi.org/10.1038/s41586-023-06252-9 Dataset Version: https://datasets.cellxgene.cziscience.com/b8b5be07-061b-4390-af0a-f9ced877a068.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/4195ab4c-20bd-4cd3-8b3d-65601277e731</li> <li>Publication Reference: Kuppe et al. (2022) Nature; Publication: https://doi.org/10.1038/s41586-022-05060-x Dataset Version: https://datasets.cellxgene.cziscience.com/c1f6034b-7973-45e1-85e7-16933d0550bc.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/8191c283-0816-424b-9b61-c3e1d6258a77</li> <li>Publication Reference: Lake et al. (2023) Nature; Publication: https://doi.org/10.1038/s41586-023-05769-3 Dataset Version: https://datasets.cellxgene.cziscience.com/1cbe52c1-0567-4188-9c18-9d7271c56055.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/bcb61471-2a44-4d00-a0af-ff085512674c</li> <li>Publication Reference: Lake et al. (2023) Nature; Publication: https://doi.org/10.1038/s41586-023-05769-3 Dataset Version: https://datasets.cellxgene.cziscience.com/d0ddf40e-dc4b-4134-8439-bfb8bf7a81f4.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/bcb61471-2a44-4d00-a0af-ff085512674c</li> <li>Publication Reference: Lavaert et al. (2020) Immunity; Publication: https://doi.org/10.1016/j.immuni.2020.03.019 Dataset Version: https://datasets.cellxgene.cziscience.com/22e3ee6e-e47b-4502-9b2c-21b4c30a455f.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/83ed3be8-4cb9-43e6-9aaa-3fbbf5d1bd3a</li> <li>Publication Reference: Ledergor et al. (2018) Nat Med; Publication: https://doi.org/10.1038/s41591-018-0269-2 Dataset Version: https://datasets.cellxgene.cziscience.com/680c8801-ccdd-4018-a14a-cefda2da3848.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/2a0b02c0-fea6-47bd-92b9-9b03f5d2580c</li> <li>Publication Reference: Lee et al. (2020) Sci. Immunol.; Publication: https://doi.org/10.1126/sciimmunol.abd1554 Dataset Version: https://datasets.cellxgene.cziscience.com/b0a99b60-7480-4b5c-93c5-11020c36adb2.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/4f889ffc-d4bc-4748-905b-8eb9db47a2ed</li> <li>Publication Reference: Lengyel et al. (2022) Cell Reports; Publication: https://doi.org/10.1016/j.celrep.2022.111838 Dataset Version: https://datasets.cellxgene.cziscience.com/da638059-73e0-4a3b-a6fc-5fb8e47d4bff.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/d36ca85c-3e8b-444c-ba3e-a645040c6185</li> <li>Publication Reference: Lengyel et al. (2022) Cell Reports; Publication: https://doi.org/10.1016/j.celrep.2022.111838 Dataset Version: https://datasets.cellxgene.cziscience.com/de2a800c-249f-4072-8454-cde3d6bfb5b4.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/d36ca85c-3e8b-444c-ba3e-a645040c6185</li> <li>Publication Reference: Li et al. (2022) Cancer Cell; Publication: https://doi.org/10.1016/j.ccell.2022.11.001 Dataset Version: https://datasets.cellxgene.cziscience.com/39196e03-e248-4724-a618-b3bef017d6b2.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/f7cecffa-00b4-4560-a29a-8ad626b8ee08</li> <li>Publication Reference: Liang et al. (2023) Cell Genomics; Publication: https://doi.org/10.1016/j.xgen.2023.100298 Dataset Version: https://datasets.cellxgene.cziscience.com/0da7c2ec-246f-4ffb-9c25-1aa059870a0a.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/af893e86-8e9f-41f1-a474-ef05359b1fb7</li> <li>Publication Reference: Liang et al. (2023) Cell Genomics; Publication: https://doi.org/10.1016/j.xgen.2023.100298 Dataset Version: https://datasets.cellxgene.cziscience.com/9a199269-5a65-4ade-aa85-07ab4cfb4c26.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/af893e86-8e9f-41f1-a474-ef05359b1fb7</li> <li>Publication Reference: Litvi\\u0148ukov\\u00e1 et al. (2020) Nature; Publication: https://doi.org/10.1038/s41586-020-2797-4 Dataset Version: https://datasets.cellxgene.cziscience.com/a5618935-5bbd-494d-b300-9ecc2402d5b0.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/b52eb423-5d0d-4645-b217-e1c6d38b2e72</li> <li>Publication Reference: Liu et al. (2021) Cell; Publication: https://doi.org/10.1016/j.cell.2021.02.018 Dataset Version: https://datasets.cellxgene.cziscience.com/504b4b53-f0fb-43a6-8b8d-6254e8d81e85.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/ed9185e3-5b82-40c7-9824-b2141590c7f0</li> <li>Publication Reference: Liu et al. (2021) Cell; Publication: https://doi.org/10.1016/j.cell.2021.02.018 Dataset Version: https://datasets.cellxgene.cziscience.com/6d14e6f5-9b9f-4e8e-8b31-cee9020e18a5.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/ed9185e3-5b82-40c7-9824-b2141590c7f0</li> <li>Publication Reference: Lukassen et al. (2020) EMBO J; Publication: https://doi.org/10.15252/embj.20105114 Dataset Version: https://datasets.cellxgene.cziscience.com/a6c47325-eae6-4111-9e47-89a550ef99af.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/6ff3401b-d72c-4940-a00c-3f0792397082</li> <li>Publication Reference: Lukassen et al. (2020) EMBO J; Publication: https://doi.org/10.15252/embj.20105114 Dataset Version: https://datasets.cellxgene.cziscience.com/b0c0edd1-a8ba-436c-bef4-667bdf3fc8f1.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/6ff3401b-d72c-4940-a00c-3f0792397082</li> <li>Publication Reference: Lukowski et al. (2019) EMBO J; Publication: https://doi.org/10.15252/embj.2018100811 Dataset Version: https://datasets.cellxgene.cziscience.com/9b910901-bcf8-4d51-a85b-268ccbd54544.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/3472f32d-4a33-48e2-aad5-666d4631bf4c</li> <li>Publication Reference: MacParland et al. (2018) Nat Commun; Publication: https://doi.org/10.1038/s41467-018-06318-7 Dataset Version: https://datasets.cellxgene.cziscience.com/f07d2b1d-2e04-4f30-92d2-7d55e22da909.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/bd5230f4-cd76-4d35-9ee5-89b3e7475659</li> <li>Publication Reference: Madissoon et al. (2020) Genome Biol; Publication: https://doi.org/10.1186/s13059-019-1906-x Dataset Version: https://datasets.cellxgene.cziscience.com/2c6ab5e2-09c9-410b-a472-7559e45e553a.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/4d74781b-8186-4c9a-b659-ff4dc4601d91</li> <li>Publication Reference: Madissoon et al. (2020) Genome Biol; Publication: https://doi.org/10.1186/s13059-019-1906-x Dataset Version: https://datasets.cellxgene.cziscience.com/55abbbab-bb53-4f92-92cd-483d8f74a881.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/4d74781b-8186-4c9a-b659-ff4dc4601d91</li> <li>Publication Reference: Madissoon et al. (2020) Genome Biol; Publication: https://doi.org/10.1186/s13059-019-1906-x Dataset Version: https://datasets.cellxgene.cziscience.com/ee76e44a-8b7a-4ddc-8e29-c8a355254033.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/4d74781b-8186-4c9a-b659-ff4dc4601d91</li> <li>Publication Reference: Melms et al. (2021) Nature; Publication: https://doi.org/10.1038/s41586-021-03569-1 Dataset Version: https://datasets.cellxgene.cziscience.com/739bae5d-2d6f-4664-a79f-d065610da5ae.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/e4c9ed14-e560-4900-a3bf-b0f8d2ce6a10</li> <li>Publication Reference: Menon et al. (2019) Nat Commun; Publication: https://doi.org/10.1038/s41467-019-12780-8 Dataset Version: https://datasets.cellxgene.cziscience.com/f34734b0-5de7-4b48-a3ba-bd9bb8c48e73.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/1a486c4c-c115-4721-8c9f-f9f096e10857</li> <li>Publication Reference: Muto et al. (2021) Nat Commun; Publication: https://doi.org/10.1038/s41467-021-22368-w Dataset Version: https://datasets.cellxgene.cziscience.com/3b84b0b5-3d0a-41a1-860a-bbadad3717bb.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/9b02383a-9358-4f0f-9795-a891ec523bcc</li> <li>Publication Reference: Nowicki-Osuch et al. (2023) Cancer Discovery; Publication: https://doi.org/10.1158/2159-8290.cd-22-0824 Dataset Version: https://datasets.cellxgene.cziscience.com/074caa96-9205-4bc6-b5ba-eef787f131dc.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/a18474f4-ff1e-4864-af69-270b956cee5b</li> <li>Publication Reference: Orozco et al. (2020) Cell Reports; Publication: https://doi.org/10.1016/j.celrep.2019.12.082 Dataset Version: https://datasets.cellxgene.cziscience.com/56334044-9f3a-4541-be24-28bed94c2d4a.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/939769a8-d8d2-4d01-abfc-55699893fd49</li> <li>Publication Reference: Otero-Garcia et al. (2022) Neuron; Publication: https://doi.org/10.1016/j.neuron.2022.06.021 Dataset Version: https://datasets.cellxgene.cziscience.com/70170717-45c4-4891-9b14-fb795ecc3d94.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/b953c942-f5d8-434f-9da7-e726ba7c1481</li> <li>Publication Reference: Otero-Garcia et al. (2022) Neuron; Publication: https://doi.org/10.1016/j.neuron.2022.06.021 Dataset Version: https://datasets.cellxgene.cziscience.com/b6ddb1cd-f058-450e-8e66-e81f6e8a3c4a.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/b953c942-f5d8-434f-9da7-e726ba7c1481</li> <li>Publication Reference: Park et al. (2020) Science; Publication: https://doi.org/10.1126/science.aay3224 Dataset Version: https://datasets.cellxgene.cziscience.com/59d5b3c5-9a55-44ae-a7fa-c14567e02755.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/de13e3e2-23b6-40ed-a413-e9e12d7d3910</li> <li>Publication Reference: Park et al. (2020) Science; Publication: https://doi.org/10.1126/science.aay3224 Dataset Version: https://datasets.cellxgene.cziscience.com/c6e08ab6-ab3b-41dc-8058-8e6442e081ec.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/de13e3e2-23b6-40ed-a413-e9e12d7d3910</li> <li>Publication Reference: Perez et al. (2022) Science; Publication: https://doi.org/10.1126/science.abf1970 Dataset Version: https://datasets.cellxgene.cziscience.com/8f2e4a29-e397-4f33-bc9a-3181e06b64b0.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/436154da-bcf1-4130-9c8b-120ff9a888f2</li> <li>Publication Reference: Reed et al. (2024) Nat Genet; Publication: https://doi.org/10.1038/s41588-024-01688-9 Dataset Version: https://datasets.cellxgene.cziscience.com/5a611776-aae0-41b9-9f2b-aaf5f83771a3.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/48259aa8-f168-4bf5-b797-af8e88da6637</li> <li>Publication Reference: Reichart et al. (2022) Science; Publication: https://doi.org/10.1126/science.abo1984 Dataset Version: https://datasets.cellxgene.cziscience.com/e0251a80-0058-4686-9ab8-b2e751313e18.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/e75342a8-0f3b-4ec5-8ee1-245a23e0f7cb</li> <li>Publication Reference: Ren et al. (2021) Cell; Publication: https://doi.org/10.1016/j.cell.2021.01.053 Dataset Version: https://datasets.cellxgene.cziscience.com/ae18e694-6f45-4635-affa-63ac0e29323d.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/0a839c4b-10d0-4d64-9272-684c49a2c8ba</li> <li>Publication Reference: Rodr\\u00edguez-Ubreva et al. (2022) Nat Commun; Publication: https://doi.org/10.1038/s41467-022-29450-x Dataset Version: https://datasets.cellxgene.cziscience.com/0ac22902-dfaa-4ceb-9cad-03afbd96f6d4.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/bf325905-5e8e-42e3-933d-9a9053e9af80</li> <li>Publication Reference: Rodr\\u00edguez-Ubreva et al. (2022) Nat Commun; Publication: https://doi.org/10.1038/s41467-022-29450-x Dataset Version: https://datasets.cellxgene.cziscience.com/5b4b134c-42f6-415b-a4fd-7f2a60128ff1.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/bf325905-5e8e-42e3-933d-9a9053e9af80</li> <li>Publication Reference: Rodr\\u00edguez-Ubreva et al. (2022) Nat Commun; Publication: https://doi.org/10.1038/s41467-022-29450-x Dataset Version: https://datasets.cellxgene.cziscience.com/d6e742c5-f6e5-42f4-8064-622783542f6b.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/bf325905-5e8e-42e3-933d-9a9053e9af80</li> <li>Publication Reference: Salcher et al. (2022) Cancer Cell; Publication: https://doi.org/10.1016/j.ccell.2022.10.008 Dataset Version: https://datasets.cellxgene.cziscience.com/99040b08-7e1a-4d81-911c-4d2fd2335757.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/edb893ee-4066-4128-9aec-5eb2b03f8287</li> <li>Publication Reference: Seeker et al. (2023) acta neuropathol commun; Publication: https://doi.org/10.1186/s40478-023-01568-z Dataset Version: https://datasets.cellxgene.cziscience.com/32c319ef-10e2-4948-8b40-093d2f9d7cb5.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/9d63fcf1-5ca0-4006-8d8f-872f3327dbe9</li> <li>Publication Reference: Sikkema et al. (2023) Nat Med; Publication: https://doi.org/10.1038/s41591-023-02327-2 Dataset Version: https://datasets.cellxgene.cziscience.com/8d84ba15-d367-4dce-979c-85da70b868a2.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/6f6d381a-7701-4781-935c-db10d30de293</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/005aba12-a5af-4fcd-9b80-e28d845885c8.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/05c60502-d980-4b5f-b093-d27cdf1360cd.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/09df20c1-3c87-465d-b67c-73dc5f3d1bc8.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/0eb52059-c5a4-4b6a-aa95-e9bec179e13c.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/0f509022-ab14-4151-a435-37bcf582e20d.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/137f5623-e19a-4cb4-9466-05ba393c3552.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/1a5d4cf1-e1a7-4081-918a-8d9cb441cd54.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/1eef8184-4629-406d-b04e-13f1c34b1071.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/1faafbca-0062-4fc0-8b50-a3d32a111d39.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/214485af-4c67-4fda-b430-995162804fbf.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/21fd9d75-dfec-443c-b634-9803792a081c.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/229ddec2-a177-4325-bb2c-0ec11092982a.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/25a92b24-76c5-4bdb-a431-3478a8b38a69.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/25cc85a9-8645-43cf-a552-d7487c04159e.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/2a8c8c02-e64b-4b39-9b1a-e46247031c1a.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/2baa0697-1757-4675-b1ae-51672b2d9bce.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/34c82f0d-04a7-4b13-8d4f-ae06065a2b1c.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/364a5dc5-2d78-4931-9eeb-477c56ba63e7.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/366254d0-6aef-4c49-a814-bc195a5bb6c6.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/3a64f908-b132-4d0c-aac6-28012cb6fd11.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/3f0713f8-2fd6-4b77-8ea2-010a0d9b51ae.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/3f1a2741-7b58-4eef-91ad-becc1646b1a4.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/3ff56875-32be-4008-be41-c9c6526fc730.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/443f8b59-a15d-4d22-9b18-9ec721560c19.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/45d8a451-d313-465d-b66d-bdea50800ce8.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/47a0e562-2745-4619-9623-d6fa431b4026.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/4a65c6dd-cb77-4cc3-8d95-06957a668c1f.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/4df9fbc5-871b-43be-b796-92cd3f592e32.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/54095aef-f5c6-4dfa-b2e3-00fa8bb8d86a.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/544c6998-8d55-4c59-bd18-18c81a3a8b37.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/560a125a-9dd4-4fae-b58a-f24c932c5dd9.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/587acfff-2fb3-46eb-8511-8a1cd2e65ad4.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/58f6d3e6-aedd-479f-b2f5-9026fac2011c.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/595f2363-dd4a-4184-a75a-c8b0fb62e3d1.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/5ae914f7-a02e-4f08-8bf5-45023b1a23d9.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/5dac55f7-6650-4d24-b8c0-bbb9672ac819.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/5e07340f-a505-4272-a688-de9e104de2d6.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/60034ae4-27a7-46f3-a5aa-668eba808b6f.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/609942ad-2a18-4567-a9b7-8bf126cd1732.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/61ee7a9e-216b-4119-93fa-740fe41a8a0a.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/63319798-c980-4fd6-866c-46d9fc1f6d28.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/64f05ce7-291c-487e-9b00-498a2279291d.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/6918480f-892a-42bf-a5cd-5e988f6e46b9.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/6a65d707-2c28-4d47-8b77-12f8dd3d66e2.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/6be7d5fc-9024-46a9-84aa-26a230ac6733.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/6cc6a9b9-d53a-4b25-9b3f-d1f00e092d85.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/702d58ff-08f2-48ef-85b7-6132e77efdc4.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/705b76b8-68a5-44fb-89ef-fb5273d2ec88.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/717b249c-46e3-43b5-9b3e-93bbdf879874.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/73ec94b8-e1c8-4de8-966a-8dea2842b068.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/744be8ae-ddd2-4822-9537-50030b340bef.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/74903ae9-7470-4795-9508-057a058b9447.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/777952cd-2f82-408b-8890-f084f5825d90.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/7d5e92ed-87fa-4e85-831c-0b98479f3ec6.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/80869ae5-15a7-4ddc-9c2e-4f40dffb2aeb.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/81d55237-e3df-4212-84f8-5ed7a1b5b62e.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/81eb9dd8-2b33-4ff5-aa3f-a8842b68ddca.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/821fa877-c2b1-488f-bc12-606e804f6f4b.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/8268fa76-4996-4a21-b687-ad67c5dc383d.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/82a043bf-b6c0-4746-9d69-39437796282e.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/82faf671-658a-4c88-8a7d-618fc7f68fad.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/83b8522d-f362-4aca-8c64-2dfb125b87e1.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/88bacb21-c9d7-4d59-a1d9-ac71d75628b3.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/8faf8f5a-284a-4b2f-b8fe-4a71cb38a79a.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/9993afca-cfb9-4ae9-851b-07528edd8b20.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/9b42ebb8-5ebe-4707-bb75-7d64a5fdcafb.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/9f0e0ca6-43ed-4e52-9d85-93cbe24346a5.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/9f90a216-3fac-44ff-b0ca-7b77cf53ef07.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/a1446790-c439-4a23-904d-488028e4d34c.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/a4581a49-fe69-4039-97dd-a2c54e676159.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/a497b47b-c4a2-42fe-a7a4-8abc8aed4ec5.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/a561b8a5-9c26-4b52-bb0b-dca989c432cd.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/a737721b-e311-40da-9835-fc60d991be9a.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/a7f64bb1-6198-406f-ae78-ddb884633937.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/ab10decf-4e42-44ac-bb45-660771526f96.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/ad40f328-75a3-4b5e-8212-308b7d734d45.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/ae98b1bf-fd73-49a0-9732-41f74da1832b.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/aeb99282-b851-469d-bb77-4c550ae71b37.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/b18522ea-2a30-4f9d-b5c1-aa93a9f5677d.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/b38e94df-9801-4cf1-a8e2-8b39f25f56b4.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/b47045e2-d8ad-4c72-9412-aa4824f532d3.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/b893efbd-c660-404d-9055-6717b7eba280.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/b9ecd819-1a5b-4e8e-9f2d-833b1891af37.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/bc0c001e-5c7f-43ef-9003-40f2e3015ff7.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/bfbe13d3-d6b8-4fd9-aeb7-c35e80219e1d.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/c2b0f135-3723-4351-83e5-c4eef19401f4.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/c821776d-a9fd-4a9b-b0ef-65bee87c7dbc.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/cb5f81ff-4676-4ead-be89-e7da582ddd94.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/cc1379b7-5d6e-4944-85ab-6b3ddb602730.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/ccef089c-a215-4607-9617-8e00f40ece67.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/cf701447-cfdd-40fd-b8fe-76d181dad7f9.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/d693ce29-f45e-4871-83e5-c60c001c190d.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/d8b0c448-6d8c-4286-aa8b-55372af3ad1a.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/dcf1e7b7-6e47-4052-a096-2b2ef8deafce.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/ddf86877-360c-44d0-af09-e6645bd0432a.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/de350331-df0e-4b8d-88dc-0bc12c4ca845.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/df9fb19c-3e91-484a-bee6-6db14d649e05.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/e0763860-958c-4f2c-928e-9625f7a37a39.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/e1669dcb-672e-4bca-bf68-6ff242618aa0.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/e683f70e-10b0-4189-ae3f-7007d32ca57a.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/e9f575c0-bf54-4252-9551-1d4c69eda1bf.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/f143d458-e4d0-4b44-9e25-d13e8578c9a6.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/f146e689-f045-4b3a-999d-ab0b287391bb.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/f867c94f-c15b-4e40-9ffe-b0c598b90881.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Siletti et al. (2023) Science; Publication: https://doi.org/10.1126/science.add7046 Dataset Version: https://datasets.cellxgene.cziscience.com/fdda2f51-9ed9-4959-9897-9581595c1bfb.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/283d65eb-dd53-496d-adb7-7570c7caa443</li> <li>Publication Reference: Smillie et al. (2019) Cell; Publication: https://doi.org/10.1016/j.cell.2019.06.029 Dataset Version: https://datasets.cellxgene.cziscience.com/6c483976-30de-4835-97f0-2b9bc93614e7.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/33d19f34-87f5-455b-8ca5-9023a2e5453d</li> <li>Publication Reference: Smith et al. (2021) Proc. Natl. Acad. Sci. U.S.A.; Publication: https://doi.org/10.1073/pnas.2023333118 Dataset Version: https://datasets.cellxgene.cziscience.com/bf50dbfb-9ca0-4f0d-8deb-a1a810a0e313.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/e02201d7-f49f-401f-baf0-1eb1406546c0</li> <li>Publication Reference: Smith et al. (2021) Proc. Natl. Acad. Sci. U.S.A.; Publication: https://doi.org/10.1073/pnas.2023333118 Dataset Version: https://datasets.cellxgene.cziscience.com/ff7778bf-7a65-4d23-a9f4-b26c47926c28.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/e02201d7-f49f-401f-baf0-1eb1406546c0</li> <li>Publication Reference: Sol\u00e9-Boldo et al. (2020) Commun Biol; Publication: https://doi.org/10.1038/s42003-020-0922-4 Dataset Version: https://datasets.cellxgene.cziscience.com/bc8d7152-3b69-4153-9314-7342ae58fbde.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/c353707f-09a4-4f12-92a0-cb741e57e5f0</li> <li>Publication Reference: Stephenson et al. (2021) Nat Med; Publication: https://doi.org/10.1038/s41591-021-01329-2 Dataset Version: https://datasets.cellxgene.cziscience.com/46586a98-b75d-4557-9cc4-839fc28e67d5.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/ddfad306-714d-4cc0-9985-d9072820c530</li> <li>Publication Reference: Stewart et al. (2019) Science; Publication: https://doi.org/10.1126/science.aat5031 Dataset Version: https://datasets.cellxgene.cziscience.com/40ebb8e4-1a25-4a33-b8ff-02d1156e4e9b.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/120e86b4-1195-48c5-845b-b98054105eec</li> <li>Publication Reference: Stewart et al. (2019) Science; Publication: https://doi.org/10.1126/science.aat5031 Dataset Version: https://datasets.cellxgene.cziscience.com/fe7e4408-7390-4f93-95aa-ffe472843421.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/120e86b4-1195-48c5-845b-b98054105eec</li> <li>Publication Reference: Strati et al. (2023) Cell Reports Medicine; Publication: https://doi.org/10.1016/j.xcrm.2023.101158 Dataset Version: https://datasets.cellxgene.cziscience.com/21d11474-fe9a-420d-9661-5b88ba407bc1.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/26b5b4f6-828c-4791-b4a3-abb19e3b1952</li> <li>Publication Reference: Suo et al. (2022) Science; Publication: https://doi.org/10.1126/science.abo0510 Dataset Version: https://datasets.cellxgene.cziscience.com/fe340fe0-f2e8-4e7b-8879-0161248129d3.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/b1a879f6-5638-48d3-8f64-f6592c1b1561</li> <li>Publication Reference: Szabo et al. (2019) Nat Commun; Publication: https://doi.org/10.1038/s41467-019-12464-3 Dataset Version: https://datasets.cellxgene.cziscience.com/71c5026d-9567-4d0f-a808-edf29440df43.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/24d42e5e-ce6d-45ff-a66b-a3b3b715deaf</li> <li>Publication Reference: The Tabula Sapiens Consortium* et al. (2022) Science; Publication: https://doi.org/10.1126/science.abl4896 Dataset Version: https://datasets.cellxgene.cziscience.com/981bcf57-30cb-4a85-b905-e04373432fef.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/e5f58829-1a66-40b5-a624-9046778e74f5</li> <li>Publication Reference: Travaglini et al. (2020) Nature; Publication: https://doi.org/10.1038/s41586-020-2922-4 Dataset Version: https://datasets.cellxgene.cziscience.com/0fd9c007-8ba2-4d87-8568-c938d2631fba.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/5d445965-6f1a-4b68-ba3a-b8f765155d3a</li> <li>Publication Reference: Travaglini et al. (2020) Nature; Publication: https://doi.org/10.1038/s41586-020-2922-4 Dataset Version: https://datasets.cellxgene.cziscience.com/6dde7580-6b89-4cf9-83b4-c778f06eda7c.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/5d445965-6f1a-4b68-ba3a-b8f765155d3a</li> <li>Publication Reference: Triana et al. (2021) Nat Immunol; Publication: https://doi.org/10.1038/s41590-021-01059-0 Dataset Version: https://datasets.cellxgene.cziscience.com/3967ab0f-a63c-4318-809e-73329341ba5e.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/93eebe82-d8c3-41bc-a906-63b5b5f24a9d</li> <li>Publication Reference: Triana et al. (2021) Nat Immunol; Publication: https://doi.org/10.1038/s41590-021-01059-0 Dataset Version: https://datasets.cellxgene.cziscience.com/61f15353-e598-43b5-bb5a-80ac44a0cf0b.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/93eebe82-d8c3-41bc-a906-63b5b5f24a9d</li> <li>Publication Reference: Triana et al. (2021) Nat Immunol; Publication: https://doi.org/10.1038/s41590-021-01059-0 Dataset Version: https://datasets.cellxgene.cziscience.com/9397b7fa-a9b5-4b56-8570-c30cb09d9df8.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/93eebe82-d8c3-41bc-a906-63b5b5f24a9d</li> <li>Publication Reference: Tritschler et al. (2022) Molecular Metabolism; Publication: https://doi.org/10.1016/j.molmet.2022.101595 Dataset Version: https://datasets.cellxgene.cziscience.com/9abfdde4-1d63-4c9a-8ec5-2fff1bd6f387.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/0a77d4c0-d5d0-40f0-aa1a-5e1429bcbd7e</li> <li>Publication Reference: Ulrich et al. (2021) bioRxiv; Publication: https://doi.org/10.1101/2021.09.16.460628 Dataset Version: https://datasets.cellxgene.cziscience.com/7fa27624-7eda-454a-a066-4de49d5788bd.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/fc77d2ae-247d-44d7-aa24-3f4859254c2c</li> <li>Publication Reference: Velmeshev et al. (2023) Science; Publication: https://doi.org/10.1126/science.adf0834 Dataset Version: https://datasets.cellxgene.cziscience.com/b126d3e9-a1a2-419a-a049-b4a27d3ce3ab.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/bacccb91-066d-4453-b70e-59de0b4598cd</li> <li>Publication Reference: Vento-Tormo et al. (2018) Nature; Publication: https://doi.org/10.1038/s41586-018-0698-6 Dataset Version: https://datasets.cellxgene.cziscience.com/7a3bdf11-fbb1-4966-8742-38b574c47317.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/a9254216-6cd8-4186-b32c-349363777584</li> <li>Publication Reference: Wang et al. (2020) eLife; Publication: https://doi.org/10.7554/eLife.62522 Dataset Version: https://datasets.cellxgene.cziscience.com/b0afc679-2ec0-4c8d-9e3e-19cd693f8462.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/625f6bf4-2f33-4942-962e-35243d284837</li> <li>Publication Reference: Wang et al. (2023) Immunity; Publication: https://doi.org/10.1016/j.immuni.2023.01.032 Dataset Version: https://datasets.cellxgene.cziscience.com/07d4feab-33de-4bb2-8a5d-452044bc066d.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/03cdc7f4-bd08-49d0-a395-4487c0e5a168</li> <li>Publication Reference: Wang et al. (2023) Immunity; Publication: https://doi.org/10.1016/j.immuni.2023.01.032 Dataset Version: https://datasets.cellxgene.cziscience.com/20f29b78-5b74-4e6d-bc88-679116733988.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/03cdc7f4-bd08-49d0-a395-4487c0e5a168</li> <li>Publication Reference: Wiedemann et al. (2023) Cell Reports; Publication: https://doi.org/10.1016/j.celrep.2023.111994 Dataset Version: https://datasets.cellxgene.cziscience.com/1ffe8f40-d258-4c05-885e-46375c483fc7.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/6d203948-a779-4b69-9b3f-1ee1dadc3980</li> <li>Publication Reference: Wilk et al. (2020) Nat Med; Publication: https://doi.org/10.1038/s41591-020-0944-y Dataset Version: https://datasets.cellxgene.cziscience.com/419da3c2-9141-4654-817f-ee6472df4be3.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/a72afd53-ab92-4511-88da-252fb0e26b9a</li> <li>Publication Reference: Wilson et al. (2022) Nat Commun; Publication: https://doi.org/10.1038/s41467-022-32972-z Dataset Version: https://datasets.cellxgene.cziscience.com/14e77ad6-38ce-4aad-8385-68b21aff0737.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/b3e2c6e3-9b05-4da9-8f42-da38a664b45b</li> <li>Publication Reference: Xiang et al. (2020) Front. Cardiovasc. Med.; Publication: https://doi.org/10.3389/fcvm.2020.00052 Dataset Version: https://datasets.cellxgene.cziscience.com/4dc06a70-6d39-4da6-aa8d-2f3fcdbbc1ff.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/9c8808ce-1138-4dbe-818c-171cff10e650</li> <li>Publication Reference: Yan et al. (2020) Sci Rep; Publication: https://doi.org/10.1038/s41598-020-66092-9 Dataset Version: https://datasets.cellxgene.cziscience.com/60eec096-34b9-45c2-b433-3caffb84f955.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/1d1c7275-476a-49e2-9022-ad1b1c793594</li> <li>Publication Reference: Yan et al. (2020) Sci Rep; Publication: https://doi.org/10.1038/s41598-020-66092-9 Dataset Version: https://datasets.cellxgene.cziscience.com/6d75c1db-1fe2-4a0e-b55f-680c6df9c99e.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/1d1c7275-476a-49e2-9022-ad1b1c793594</li> <li>Publication Reference: Yan et al. (2020) Sci Rep; Publication: https://doi.org/10.1038/s41598-020-66092-9 Dataset Version: https://datasets.cellxgene.cziscience.com/8de7d30b-caeb-4def-aad2-592c39cb3f3c.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/1d1c7275-476a-49e2-9022-ad1b1c793594</li> <li>Publication Reference: Yan et al. (2020) Sci Rep; Publication: https://doi.org/10.1038/s41598-020-66092-9 Dataset Version: https://datasets.cellxgene.cziscience.com/96c7866c-7111-4687-b2c4-fbd445842a30.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/1d1c7275-476a-49e2-9022-ad1b1c793594</li> <li>Publication Reference: Yan et al. (2020) Sci Rep; Publication: https://doi.org/10.1038/s41598-020-66092-9 Dataset Version: https://datasets.cellxgene.cziscience.com/a9d71d53-66a1-4681-ba97-9671c05dff6d.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/1d1c7275-476a-49e2-9022-ad1b1c793594</li> <li>Publication Reference: Yan et al. (2020) Sci Rep; Publication: https://doi.org/10.1038/s41598-020-66092-9 Dataset Version: https://datasets.cellxgene.cziscience.com/b67dcfb1-ccae-404c-b0d4-d681ac227858.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/1d1c7275-476a-49e2-9022-ad1b1c793594</li> <li>Publication Reference: Yazar et al. (2022) Science; Publication: https://doi.org/10.1126/science.abf3041 Dataset Version: https://datasets.cellxgene.cziscience.com/b3e8792e-a31b-404b-a866-250c43bc06d5.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/dde06e0f-ab3b-46be-96a2-a8082383c4a1</li> <li>Publication Reference: Yoshida et al. (2022) Nature; Publication: https://doi.org/10.1038/s41586-021-04345-x Dataset Version: https://datasets.cellxgene.cziscience.com/69be948c-03f4-46e8-896e-530c79080808.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/03f821b4-87be-4ff4-b65a-b5fc00061da7</li> <li>Publication Reference: Yoshida et al. (2022) Nature; Publication: https://doi.org/10.1038/s41586-021-04345-x Dataset Version: https://datasets.cellxgene.cziscience.com/d911082e-b5e2-40e6-8f08-fb53c7894622.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/03f821b4-87be-4ff4-b65a-b5fc00061da7</li> <li>Publication Reference: Yu et al. (2021) Cell; Publication: https://doi.org/10.1016/j.cell.2021.04.028 Dataset Version: https://datasets.cellxgene.cziscience.com/c7bec699-47c3-44ee-a311-ae8507adf6bb.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/dfc09a93-bce0-4c77-893d-e153d1b7f9fa</li> <li>Publication Reference: Yu et al. (2021) Cell; Publication: https://doi.org/10.1016/j.cell.2021.04.028 Dataset Version: https://datasets.cellxgene.cziscience.com/da7ca6a3-079c-428f-8453-9b21ecce87a7.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/dfc09a93-bce0-4c77-893d-e153d1b7f9fa</li> <li>Publication Reference: Zhang et al. (2021) Proc. Natl. Acad. Sci. U.S.A.; Publication: https://doi.org/10.1073/pnas.2103240118 Dataset Version: https://datasets.cellxgene.cziscience.com/b6a3566e-a7bf-4fb3-b20c-858c6330e380.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/1df8c90d-d299-4b2e-a54d-a5a80f36e780</li> <li>Publication Reference: van Zyl et al. (2022) Proc. Natl. Acad. Sci. U.S.A.; Publication: https://doi.org/10.1073/pnas.2200914119 Dataset Version: https://datasets.cellxgene.cziscience.com/47573dc2-1dfc-4ca8-8c6e-b705a6656159.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/63d03351-06be-478e-a0db-f7a653b6b19b</li> <li>Publication Reference: van Zyl et al. (2022) Proc. Natl. Acad. Sci. U.S.A.; Publication: https://doi.org/10.1073/pnas.2200914119 Dataset Version: https://datasets.cellxgene.cziscience.com/9fa63ab8-6316-4460-8283-af290fec1654.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/63d03351-06be-478e-a0db-f7a653b6b19b</li> <li>Publication Reference: van Zyl et al. (2022) Proc. Natl. Acad. Sci. U.S.A.; Publication: https://doi.org/10.1073/pnas.2200914119 Dataset Version: https://datasets.cellxgene.cziscience.com/a76ab167-d254-4128-b5ca-86960560074a.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/63d03351-06be-478e-a0db-f7a653b6b19b</li> <li>Publication Reference: van Zyl et al. (2022) Proc. Natl. Acad. Sci. U.S.A.; Publication: https://doi.org/10.1073/pnas.2200914119 Dataset Version: https://datasets.cellxgene.cziscience.com/e999edf8-f5e6-4af7-975c-1d8f0a5e8d3e.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/63d03351-06be-478e-a0db-f7a653b6b19b</li> <li>Publication Reference: van Zyl et al. (2022) Proc. Natl. Acad. Sci. U.S.A.; Publication: https://doi.org/10.1073/pnas.2200914119 Dataset Version: https://datasets.cellxgene.cziscience.com/f5f99f11-5a99-4a72-bd0d-0a87c5b6b406.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/63d03351-06be-478e-a0db-f7a653b6b19b</li> <li>Publication Reference: van der Wijst et al. (2021) Sci. Transl. Med.; Publication: https://doi.org/10.1126/scitranslmed.abh2624 Dataset Version: https://datasets.cellxgene.cziscience.com/02a1eee1-e290-47d1-8d9d-bc7f51c13670.h5ad curated and distributed by CZ CELLxGENE Discover in Collection: https://cellxgene.cziscience.com/collections/7d7cabfd-1d1f-40af-96b7-26a0825a306d</li> </ul>"},{"location":"main/datasets/uniprot/","title":"UniProt Dataset","text":"<p>The UniProt Knowledgebase (UniProtKB) is an open database of protein sequences curated from translated genomic data [1]. The UniProt Reference Cluster (UniRef) databases provide clustered sets of sequences from UniProtKB [2], which have been used in previous large language model training studies to improve diversity in protein training data. UniRef clusters proteins hierarchically. At the highest level, UniRef100 groups proteins with identical primary sequences from the UniProt Archive (UniParc). UniRef90 clusters these unique sequences into buckets with 90% sequence similarity, selecting a single sequence from within each cluster as the representative sequence. UniRef50 is then built by clustering these UniRef90 representative sequences into groups with 50% sequence similarity.</p>"},{"location":"main/datasets/uniprot/#data-used-for-esm-2-pre-training","title":"Data Used for ESM-2 Pre-training","text":"<p>Since the original train/test splits from ESM-2 were not available [3], we replicated the ESM-2 pre-training experiments with UniProt's 2024_03 release. Following the approach described by the ESM-2 authors, we removed artificial sequences and reserved 0.5% of UniRef50 clusters for validation. From the 65,672,139 UniRef50 clusters, this resulted in 328,360 validation sequences. We then ran MMSeqs to further ensure no contamination of the training set with sequences similar to the validation set. This resulted in 65,182,365 training UniRef50 clusters comprising 187,382,018 UniRef90 sequences.</p> <p>Pretraining batches were formed by uniformly sampling each UniRef50 cluster from the training database, taking a randomly chosen UniRef90 sequence from each.</p>"},{"location":"main/datasets/uniprot/#data-availability","title":"Data Availability","text":"<p>Two versions of the dataset are distributed, a full training dataset (~80GB) and a 10,000 UniRef50 cluster random slice (~150MB). To load and use the sanity dataset, use the [bionemo.core.data.load][bionemo.core.data.load.load] function to materialize the sanity dataset in the BioNeMo2 cache directory:</p> <pre><code>from bionemo.core.data.load import load\n\nsanity_data_dir = load(\"esm2/testdata_esm2_pretrain:2.0\")\n</code></pre>"},{"location":"main/datasets/uniprot/#ngc-resource-links","title":"NGC Resource Links","text":"<ul> <li>Sanity Dataset</li> <li>[Full Dataset]</li> </ul>"},{"location":"main/datasets/uniprot/#references","title":"References","text":"<ol> <li> <p>UniProt Consortium. (2023). UniProt: The universal protein knowledgebase in 2023. Nucleic Acids Research, 51(D1),    D523\u2013D531. doi:10.1093/nar/gkac1052</p> </li> <li> <p>Suzek, B. E., Wang, Y., Huang, H., McGarvey, P. B., Wu, C. H., &amp; UniProt Consortium. (2015). UniRef clusters: a    comprehensive and scalable alternative for improving sequence similarity searches. Bioinformatics (Oxford, England),    31(6), 926\u2013932. doi:10.1093/bioinformatics/btu739</p> </li> <li> <p>Lin, Z., Akin, H., Rao, R., Hie, B., Zhu, Z., Lu, W., \u2026 Rives, A. (2023). Evolutionary-scale prediction of    atomic-level protein structure with a language model. Science (New York, N.Y.), 379(6637), 1123\u20131130.    doi:10.1126/science.ade2574</p> </li> </ol>"},{"location":"main/developer-guide/SUMMARY/","title":"BioNeMo Framework: Available Models","text":"<p>State-of-the-art models are continually integrated into the BioNeMo Framework. The BioNeMo Framework currently offers the following pre-trained models:</p> <p>For more information about the models included in BioNeMo Framework, refer to the Model Cards linked in the table above or the original publications referenced in the respective model descriptions.</p>"},{"location":"models/","title":"BioNeMo Framework: Available Models","text":"<p>State-of-the-art models are continually integrated into the BioNeMo Framework. The BioNeMo Framework currently offers the following pre-trained models:</p> <p>For more information about the models included in BioNeMo Framework, refer to the Model Cards linked in the table above or the original publications referenced in the respective model descriptions.</p>"},{"location":"settings/vc-jupyter/","title":"VS Code+Conda\u73af\u5883+jupyter \u5982\u4f55\u8bbe\u7f6e\uff1f","text":"<ol> <li>\u4e0b\u8f7d\u5e76\u5b89\u88c5anaconda\u3001VS Code\uff0c\u540e\u7eed\u6b65\u9aa4\u6700\u597d\u5728\u90fdVS Code\u5f97\u7ec8\u7aef\uff08\u6700\u4e0a\u9762<code>...</code>-&gt;<code>\u7ec8\u7aef</code>-&gt;<code>\u65b0\u5efa\u7ec8\u7aef</code>\uff09\u4e2d\u8fdb\u884c</li> <li>\u4f7f\u7528conda\u65b0\u5efa\u865a\u62df\u73af\u5883\uff0c\u9700\u8981\u540c\u65f6\u5b89\u88c5\u6709Python\uff0c\u6bd4\u5982 <pre><code>conda create --name myenv python=3.12\n</code></pre></li> <li>\u8fdb\u5165\u8be5\u865a\u62df\u73af\u5883\u5e76\u5728\u8be5\u865a\u62df\u73af\u5883\u4e2d\u5b89\u88c5ipykernel\uff08\u5982\u679c\u4f60\u662f\u65b0\u5efa\u5f97\u73af\u5883\uff0c\u4e0a\u4e00\u6b65\u53ef\u4ee5\u540c\u65f6\u5b89\u88c5\u4e0a\uff09 <pre><code>conda activate \u73af\u5883\u540d\u79f0 # \u6bd4\u5982\u4e0a\u9762\u6211\u7528\u7684myenv\nconda install ipykernel\n</code></pre></li> <li>\u5728\u8be5\u865a\u62df\u73af\u5883\u4e2d\u8f93\u5165 <pre><code>python -m ipykernel install --user --name \u73af\u5883\u540d\u79f0 --display-name \u73af\u5883\u540d\u79f0\n</code></pre></li> <li>\u5237\u65b0\uff1a\u5173\u95edVS Code\uff0c\u518d\u91cd\u65b0\u6253\u5f00\u5305\u542b\u9879\u76ee\u6587\u4ef6\u7684\u5de5\u4f5c\u533a</li> <li>\u5728VS Code\u4e2d<code>CTRL+P</code>\u641c\u7d22\u8f93\u5165\uff1aselect interpreter\uff1b\u4e5f\u53ef\u4ee5\u5728<code>ipynb</code>\u6587\u4ef6\u7684\u53f3\u4e0a\u89d2\u627e\u5230<code>\u9009\u62e9\u5185\u6838</code>\uff0c\u70b9\u51fb\u540e\u9009\u62e9<code>Python\u73af\u5883</code>-&gt;<code>myenv</code>\uff08\u4f60\u7684\u73af\u5883\u540d\u79f0\uff09</li> </ol>"},{"location":"start/SUMMARY/","title":"SUMMARY","text":"<ul> <li>\u524d\u8a00</li> <li>\u56db\u8db3\u673a\u5668\u4eba</li> </ul>"},{"location":"start/shouye/","title":"\u5feb\u901f\u4e0a\u624b\u673a\u5668\u4eba","text":"<p>\u5982\u679c\u4f60\u524d\u9762\u4ec0\u4e48\u90fd\u6ca1\u770b\u4e5f\u6ca1\u6709\u5173\u7cfb\uff0c\u540e\u9762\u8be5\u8865\u7684\u8bfe\u6162\u6162\u8865\uff0c\u90fd\u4f1a\u7ed9\u51fa\u8df3\u8f6c\u94fe\u63a5\u3002</p> <p>\u597d\u4e86\uff0c\u4e8b\u4e0d\u5b9c\u8fdf\uff0c\u8ba9\u6211\u4eec\u7acb\u523b\u5f00\u59cb\u5427\uff01</p>"},{"location":"start/quadbot/SUMMARY/","title":"SUMMARY","text":"<ul> <li>\u4ecb\u7ecd</li> <li>Legged Gym\u89e3\u8bfb\u548c\u4f7f\u7528</li> </ul>"},{"location":"start/quadbot/leggedgym/","title":"Legged Gym \u89e3\u8bfb","text":""},{"location":"start/quadbot/leggedgym/#\u6982\u89c8","title":"\u6982\u89c8","text":"<p>\u9996\u5148\u5bf9\u6574\u4e2a\u4ed3\u5e93\u7c97\u7565\u770b\u4e00\u4e0b\uff0c\u6807\u8bb0\u51e0\u4e2a\u6bd4\u8f83\u6838\u5fc3\u7684\u6587\u4ef6</p> <ul> <li>legged_gym</li> <li>envs<ul> <li>\u5404\u7c7brobots\u7684Config</li> <li>init.py</li> </ul> </li> <li>scripts</li> <li>tests</li> <li>utils</li> <li>init.py</li> <li>licenses</li> <li>resources</li> <li>actuator_nets</li> <li>robots</li> </ul> <p>init.py\u7684\u4f5c\u7528</p> <p>\u8be5\u6587\u4ef6\u7528\u4e8e\u544a\u8bc9Python\uff0c\u8fd9\u4e2a\u6587\u4ef6\u5939\u662f\u4e2a\u5305\u800c\u4e0d\u662f\u4e00\u4e2a\u5355\u7eaf\u7684\u6587\u4ef6\u5939\uff0c\u8fd9\u5c31\u610f\u5473\u7740\u4f60\u53ef\u4ee5\u4f7f\u7528\u8bf8\u5982\u4ee5\u4e0b\u8bed\u53e5\u53bb\u5728\u5176\u4ed6\u5730\u65b9\u5bfc\u5165\uff1a <pre><code>import envs\n</code></pre></p>"},{"location":"start/quadbot/leggedgym/#legged_gym","title":"legged_gym","text":""},{"location":"start/quadbot/leggedgym/#envs","title":"envs","text":""},{"location":"start/quadbot/leggedgym/#scripts","title":"scripts","text":""},{"location":"start/quadbot/leggedgym/#utils","title":"utils","text":""},{"location":"start/quadbot/leggedgym/#_1","title":"Legged Gym\u89e3\u8bfb","text":""},{"location":"start/quadbot/leggedgym/#resources","title":"Resources","text":"<p><code>resources</code>\u91cc\u9762\u7684<code>actuator_nets</code>\u8c8c\u4f3c\u7528\u6765sim-2-real\u7684\uff0c\u6ca1\u5565\u7528\uff08\u641c\u90fd\u641c\u4e0d\u5230\u54ea\u91cc\u7528\u4e86\uff09\uff0c<code>robots</code>\u91cc\u9762\u662f\u4f60\u81ea\u5df1\u673a\u5668\u4eba\u7684\u6a21\u578b\u6587\u4ef6\uff08<code>meshes</code>\u662f\u5177\u4f53\u673a\u5668\u4eba\u90e8\u5206\u7684\u6a21\u578b\uff0c<code>urdf</code>\u6587\u4ef6\u89e3\u91ca\u673a\u5668\u4eba\u5404\u4e2a\u6a21\u5757\u600e\u4e48\u8fde\u63a5\u7684\uff09\u3002</p>"},{"location":"start/quadbot/shouye/","title":"\u56db\u8db3\u673a\u5668\u4eba\u9879\u76ee","text":"<p>\u672c\u9879\u76ee\u57fa\u4e8eLeggedGym(2021)\u548cRSL RL(2021)\u3002</p> <p>\u524d\u8005\u76ee\u524d\u7531\u4e8eNVIDIA\u4eceGym\u8fc1\u79fb\u5230Lab\uff0c\u56e0\u6b64ETH\u4e5f\u76f8\u5e94\u8fdb\u884c\u4e86\u8fc1\u79fb\uff0c\u4e0d\u518d\u6d3b\u8dc3\u3002\u540e\u8005\u76ee\u524d\u4ecd\u5904\u4e8e\u6d3b\u8dc3\u66f4\u65b0\u3002</p>"},{"location":"start/quadbot/shouye/#\u4e3b\u8981\u5185\u5bb9","title":"\u4e3b\u8981\u5185\u5bb9","text":"<p>\u672c\u9879\u76ee\u5c06\u4e3b\u8981\u5305\u542b\u4ee5\u4e0b\u5185\u5bb9\uff1a</p> <ul> <li>\u5173\u4e8e\u8fd9\u4e24\u4e2a\u4ed3\u5e93\u7684\u4ee3\u7801\u89e3\u8bfb\uff08\u53ef\u80fd\u6d89\u53ca\u90e8\u5206\u539f\u59cb\u4ee3\u7801\u6ca1\u6709\u7684\u6539\u52a8\uff09</li> <li>\u8bad\u7ec3\u7f51\u7edc\u8bbe\u8ba1\u7684\u57fa\u672c\u8ba4\u8bc6 \u2026\u2026</li> </ul>"},{"location":"theory/SUMMARY/","title":"SUMMARY","text":"<ul> <li>\u6982\u7387\u4e0e\u7edf\u8ba1</li> </ul>"},{"location":"theory/prob/bayes/","title":"\u8d1d\u53f6\u65af\u5b9a\u7406","text":""},{"location":"theory/prob/bayes/#beta\u5206\u5e03\u7684\u63a8\u5bfc","title":"Beta\u5206\u5e03\u7684\u63a8\u5bfc","text":"<p>Beta\u5206\u5e03\u548c\u4e8c\u9879\u5206\u5e03\u4e00\u6837\uff0c\u90fd\u662f\u9488\u5bf9n\u6b21\u72ec\u7acb\u91cd\u590d\u7684\u4f2f\u52aa\u5229\u8bd5\u9a8c\u7684\u5206\u5e03\uff0c\u4f46\u662f\u6982\u5ff5\u6709\u6240\u533a\u522b\u3002</p> <ul> <li>\u4e8c\u9879\u5206\u5e03\uff1a\u5df2\u77e5\u629b\u786c\u5e01\u6b63\u9762\u671d\u4e0a\u6982\u7387\u4e3ap\uff0c\u90a3\u4e48\u629bn\u6b21\uff0c\u6b63\u9762\u671d\u4e0ax\u6b21\u6570\uff08\u6a2a\u8f74\u503c\uff09\u7684\u6982\u7387P\uff08\u7eb5\u8f74\u503c\uff09\u5206\u5e03\u56fe</li> <li>Beta\u5206\u5e03\uff1a\u5df2\u77e5\u629b\u4e86n\u6b21\uff0c\u6b63\u9762\u671d\u4e0a\u7684\u6b21\u6570\u4e3ax\u6b21\uff0c\u8be5\u786c\u5e01\u5b9e\u9645\u6b63\u9762\u671d\u4e0a\u7684\u6982\u7387p\uff08\u6a2a\u8f74\u503c\uff09\u7684\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\uff0c\u56e0\u6b64\u540e\u7eed\u63a8\u5bfc\u6211\u4eec\u9ed8\u8ba4n\u548cx\u4e3a\u5e38\u6570</li> </ul> <p>\u6982\u7387\u5bc6\u5ea6\u51fd\u6570</p> <p>\u4e0d\u540c\u7684p\u90fd\u6709\u4e00\u4e2a\u6743\u91cd\uff0c\u6743\u91cd\u8d8a\u5927\uff0c\u90a3\u4e48\u53d6\u5230\u8fd9\u4e2ap\u7684\u6982\u7387\u5c31\u8d8a\u5927\u3002\u60f3\u8c61\u628a\u5b83\u5207\u6210\u4e00\u6761\u6761\u7684\uff0cp\u53d6\u52300-1\u4e2d\u67d0\u4e2a\u503c\u7684\u6982\u7387\u5c31\u662f=\u8fd9\u4e2a\u503c\u8fd9\u4e00\u6761\u7684\u9762\u79ef/\u6240\u6709\u7684\u9762\u79ef\uff08\u5c31\u662f1\uff09\u3002</p> <p>\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\uff08Probability density function\uff09\uff0c\u7b80\u5199\u4f5cPDF\u3002\u767e\u5ea6 | wiki</p> \\[ \\begin{align} P(p | x) &amp;= \\frac{P(x | p) \\times P(p)}{P(x)} \\\\[10pt] &amp;= \\frac{\\left[\\binom{n}{x} p^x (1-p)^{n-x}\\right] \\times 1}{\\int_0^1 \\binom{n}{x} p^x (1-p)^{n-x} dp} \\\\[10pt] &amp;= \\frac{\\binom{n}{x} p^x (1-p)^{n-x}}{\\binom{n}{x} \\int_0^1 p^x (1-p)^{n-x} dp} \\\\[10pt] &amp;= \\frac{p^x (1-p)^{n-x}}{\\int_0^1 p^x (1-p)^{n-x} dp} \\\\[10pt] &amp;= \\frac{p^x (1-p)^{n-x}}{B(x+1, n-x+1)} \\\\[10pt] &amp;= \\text{Beta}(x+1, n-x+1) \\end{align} \\] <ol> <li>\u7b2c1-2\u884c\uff1a\\(P(p)\\)\u5c31\u662f\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\uff0c\u4e0d\u8fc7\u662f\u5148\u9a8c\u7684\uff1b\\(P(x)\\)\u5728\u4e0d\u540c\u7684\u6982\u7387\u4e0bP\u4e0d\u540c\uff0c\u6240\u4ee5\u5bf9\u6240\u6709\u53ef\u80fd\u7684p\u505a\u79ef\u5206</li> <li>\u7b2c3-4\u884c\uff1a\u5e38\u89c4\u64cd\u4f5c\uff0c\u4e0a\u4e0b\u6d88\u6389\u5e38\u6570</li> <li>\u7b2c5\u884c\uff1a\u7528B\u51fd\u6570\u66ff\u6362\uff0c\u6ce8\u610fB\u51fd\u6570\u4e5f\u662f\u5e38\u6570\uff0c\u8fd9\u4e2a\u4e5f\u5bb9\u6613\u7406\u89e3\uff0c\u56e0\u4e3a\u5bf9p\u79ef\u5206\u7684\u7ed3\u679c\u4e0d\u4f1a\u5305\u542bp</li> </ol> \u4e3a\u4ec0\u4e48\u4e00\u6b21\u6027\u66f4\u65b0\u548c\u5206\u6b65\u66f4\u65b0\u7ed3\u679c\u76f8\u540c\uff1f <p>\u9996\u5148\u9700\u8981\u77e5\u9053\u51b3\u5b9a\u662f\u5426\u76f8\u540c\u7684\u53ea\u6709\u5e26\u6709\u53d8\u91cf\u7684\u90e8\u5206\uff08\u8be5\u95ee\u9898\u4e2d\u662f\u5206\u5b50\uff09\uff0c\u56e0\u4e3a\u7ed3\u679c\u4e00\u5b9a\u662f\u4e00\u4e2a\u6982\u7387\u5bc6\u5ea6\u56fe\uff0c\u5e38\u6570\u90e8\u5206\u4ec5\u4ec5\u53ea\u662f\u7528\u4f5c\u5f52\u4e00\u5316\u3002</p> <p>\u56e0\u4e3a\u662f\u72ec\u7acb\u8bd5\u9a8c\uff0c\u4e0d\u5b58\u5728\u5206\u6b65\u4e4b\u95f4\u7684\u5e72\u6270\uff0c\u7406\u8bba\u4e0a\u5c31\u6ca1\u6709\u5173\u7cfb\u3002\u4e3a\u4e86\u66f4\u76f4\u89c2\u5730\u7406\u89e3\uff0c\u4e3e\u4e2a\u4f8b\u5b50\uff1a\u7b2c\u4e00\u6b65\u662f\\(x_1=1,n_1=1\\)\uff08\u4e00\u6b21\u6b63\uff09\uff0c\u5f97\u5230\u7684\\(Beta(2,1)\\)\u5206\u5b50\u662f\\(p^1\\)\uff1b\u7b2c\u4e8c\u6b65\u53c8\u505a\u4e86\u4e2a\\(x_2=1,n_2=2\\)\uff08\u4e00\u6b63\u4e00\u53cd\uff09\uff0c\u5206\u5b50\u662f\\(p(1-p)\\)\uff0c\u76f8\u4e58\u5c31\u662f\\(p^2(1-p)\\)\u3002\u5982\u679c\u6211\u662f\u4e00\u6b21\u6027\u505a\u81ea\u7136\u5c31\u662f\\(x=x_1+x_2=2,n=3\\)\uff0c\u5206\u5b50\u4e5f\u662f\\(p^2(1-p)\\)\u3002</p>"}]}